# Aspects théoriques {#sec-theorie}

Pour modéliser les trajets entre des lieux de résidence et des lieux d'emploi, on procède usuellement par la méthode à 4 étapes [@patrickbonnel2001; @de2011modelling]. Cette méthode consiste dans un premier temps à déterminer d'un côté le nombre de trajets en partance d'un lieu de résidence et, d'un autre côté, le nombre de trajets arrivant au total dans un lieu d'activité. C'est l'étape 1 de génération des trajets. La seconde étape consiste à distribuer les trajets de l'étape 1 entre chaque paire origine-destination. C'est l'étape de distribution. La troisième étape est celle du choix modal où un mode de transport adéquat est associé à chaque trajet. Enfin la quatrième étape du modèle est celle qui spécifie le trajet et permet d'en connaître les caractéristiques précises, comme le chemin emprunté ou les dénivelés effectués, pour en déduire notamment des prévisions de congestion. Cette décomposition est quelque peu arbitraire et ne rend pas justice de l'état de l'art sur les bonnes pratiques pour articuler ces 4 moments. Par exemple, le nombre de trajets effectué dépend des possibilités ouvertes par la géographie, qui sont définies par les caractéristiques précises des trajets. L'étape 4 est donc nécessaire pour comprendre l'étape 1, et l'étape 4 demande de connaître les choix modaux pour être utile aux choix fait en 1. L'étape 2 est nécessaire pour explorer les possibilités de trajets. Les imbrications sont nombreuses entre les étapes et la décomposition n'interdit pas d'effectuer des allers et retours entre les diverses étapes.

Le modèle que nous développons porte sur l'étape 2, celui de la distribution des trajets entre les différentes paires origines-destinations, ou encore résidences-emplois . Le modèle gravitaire est largement dominant dans cette deuxième étape pour prendre en compte le rôle de la distance dans l'arbitrage entre différentes destinations.

Nous discutons dans une première partie des insuffisances du modèle gravitaire (@sec-grav). Puis nous présentons le modèle des opportunités intervenantes de @stouffer1940 et le modèle radiatif de @simini2012. Ils font tout deux intervenir le rang de classement des emplois plutôt que la distance (@sec-rad) en s'appuyant sur une analogie plus adéquate aux échelles géographiques que nous considérons (commune, région) que celle de la gravitation. Enfin, dans la continuité de ces approches, nous développons un modèle qui repose sur les deux idées suivantes :

1.  Les individus font leurs arbitrages non pas en fonction directement de la distance, mais en fonction du rang (dans l'ordre des distances) des opportunités qui se présentent à eux. Une autre façon de le voir est de penser que la distance est une métrique moins adéquate que le nombre d'emplois accessibles dans un cercle de rayon donné.

2.  Chaque destination a une capacité d'accueil limitée et il faut donc introduire une notion de saturation qui oblique les individus a aller voir ailleurs. De cette manière, nous donnons un fondement microscopique au respect des contraintes aux marges (tout individu a un emploi, tout emploi est occupé par un individu) (@sec-meaps).

La formulation finale est probabiliste et nous en analysons quelques propriétés par des simulations synthétiques (@sec-synt), en montrant que l'on peut arriver rapidement à simuler un état indépendant des conditions initiales.

## Les insuffisances du modèle gravitaire {#sec-grav}

Le modèle gravitaire développe une analogie avec le modèle de la gravitation universelle d'Isaac Newton dont les succès en physique et en mécanique sont indiscutables. Ce modèle s'impose comme la pierre angulaire de l'étape de distribution des trajets [@de2011modelling; @patrickbonnel2001 p.160]. Il est également utilisé dans d'autres domaines, comme le commerce international ou l'analyse des épidémies, domaines que nous ne discuterons pas ici.

### Les (mauvaises) raisons du succès du modèle gravitaire

Formellement, le modèle gravitaire décrit la force d'une relation entre deux objets en fonction de leur distance et de leur masse respective. Par analogie, le modèle gravitaire consiste ici à évaluer le nombre de trajets professionnels entre deux localisations en prenant pour masses le nombre d'habitants au point de départ et le nombre d'emplois au point d'arrivée et, au dénominateur, une fonction $f$ croissante de la distance. On a ainsi, en indiçant les points de départ par $i$ et les points d'arrivée par $j$ :

$$
T_{i,j} = \frac {N_{hab, i}\times N_{emp, j}} {f(d_{i,j})}
$$ {#eq-gravity}

Les premiers modèles gravitaires ont emprunté la fonction $f$ à la physique newtonienne ($f=d^2$), mais d'autres formulations ont depuis été proposées. Par exemple, la fonction $f=e^{d/\delta}$ intervient dans les modèles de choix discrets proposés par McFadden [@ben-akiva2018]. En remplaçant la distance par la notion de coût généralisé du transport, on peut relier cette forme fonctionnelle à un modèle de choix avec une fonction d'utilité aléatoire (*random utility model*). Il est également possible d'ajuster des formes fonctionnelles plus complexes en ajoutant des paramètres. Le modèle gravitaire arrive alors à reproduire plus ou moins des distributions de distances observées dans des enquêtes de mobilité.

Un raisonnement par minimisation de l'entropie a été proposé par @wilson1967 pour donner un fondement théorique à l'@eq-gravity. Il considère l'état de référence comme étant celui qui est le plus fréquent dans une distribution aléatoire des choix. @wilson1967 montre alors que, si la fonction $f$ est donnée, l'@eq-gravity a bien la forme proposée et que c'est le produit des habitants et des emplois qui doit se trouver au numérateur (et non une puissance de l'un ou l'autre par exemple). Mais rien ne permet de trouver un fondement à la forme fonctionnelle de $f$. Le parallèle avec la physique est simple à faire : l'interaction définit le rôle de la distance, la maximisation de l'entropie permet d'en déduire que l'équation macroscopique dépend des masses agrégées, mais ne permet de dire quoique ce soit de plus sur la nature de l'interaction.

Comme le notent @simini2012, les fondations théoriques et empiriques de la fonction $f$ sont au mieux faibles. La multiplication des paramètres pour améliorer l'ajustement n'ont le plus souvent aucune justification théorique. De fait, on perd souvent toute possibilité de donner une signification aux paramètres estimé ce qui rend l'exercice d'ajustement opaque. Les comportements asymptotiques soulignent également des incohérences : par exemple, en faisant tendre vers l'infini les emplois à l'arrivée, le modèle prédit un nombre infini de trajets, même si le nombre de résidents au départ est limité ! Il est également insatisfaisant que le modèle gravitaire soit déterministe et ne permette ni d'expliquer les fluctuations statistiques du nombre de trajets prédits, ni d'évaluer la vraisemblance de différents cas empirique.

Mais la critique la plus forte du modèle gravitaire vient de ses propriétés fondamentales et des conclusions que l'on peut en tirer. Le nombre de trajets entre une origine (la résidence) et une destination (l'emploi) repose sur un simple arbitrage entre distance et quantité de résidents ou d'emplois. Le comportement du modèle aux limites, à nouveau, suscite la perplexité : un seul emploi à l'origine devrait être infiniment préféré un très grand nombre d'emplois un peu plus loin. C'est tout à fait irréaliste et l'on devine déjà que la distance ne joue pas un rôle si direct dans les comportements de mobilité. On voit également que le poids relatif de cet emploi quasi central par rapport aux "masses" d'emplois éloignés va varier de manière irréaliste selon qu'il est plus ou moins proche de l'origine.

Comme le soulignait déjà @stouffer1940, ce n'est peut-être pas tant la distance aux emplois qui est décisive que le rang de ces emplois selon l'ordre des distances. Dans le modèle gravitaire, il faut faire une grande différence entre le cas où le deuxième emploi le plus proche est à 500 m et le cas où il est à 1 km. Si l'on applique le modèle newtonien, il faudrait croire, par exemple, que l'attractivité de ce dernier emploi est divisée par 4. Qui peut croire que 500 m de différence pèsent d'un si grand poids dans une recherche d'emploi ? L'attractivité de l'emploi dépend avant tout du fait qu'il s'agit du deuxième emploi disponible près de chez soi. Empiriquement, il y a peu de doutes que le modèle gravitaire a de piètres performances : il ne parvient pas à expliquer pourquoi, lorsque la densité des emplois est faible autour d'un résident, celui-ci va envisager des trajets plus long pour atteindre des zones denses en emplois ; c'est pourtant une observation très commune qui devrait se retrouver dans une modélisation adéquate.

Assez peu de publications se risquent à une comparaison systématique du modèle gravitaire avec d'autres formulations qui respecteraient la première loi de Tobler. On peut citer @heanue1966 comme une des rares tentatives de ce genre. Le modèle gravitaire semblait moins bon que le modèle des opportunités intervenantes (voir plus loin) s'il n'était pas ajusté de manière *ad hoc*, comme il est devenu usuel.

@simini2012 donnent quelques exemples pour les Etats-Unis de la difficulté du modèle gravitaire à reproduire les comportements observés en en stylisant quelques régularités. A l'évidence, le modèle gravitaire ne prédit que des destinations proches et néglige complètement les destinations lointaines. Il semble impossible à la forme fonctionnelle $f(d_{ij})$ de rendre compte empiriquement à la fois du nombre de trajets courts et du nombre de trajets distants au travers d'un modèle susceptible de rendre compte des trajets dans différentes régions, dès lors que les densités y sont distribuées différemment.

### Le voile de la contrainte aux marges

Le modèle gravitaire peut être complexifié pour mieux coller aux données qu'il ne le fait spontanément. Il perd alors un lien clair avec les réflexions théoriques le reliant à la maximisation de l'entropie [@wilson1967] ou au modèle de choix discret. L'ajustement du modèle devient un exercice factice dans lequel il est difficile d'avoir confiance en particulier dans l'analyse des scénarios modélisés. L'exercice consiste à ajouter une étape de "normalisation" en incorporant des coefficients correctifs en ligne et en colonne dans la matrice origine-destination, ce qui revient à ajouter des effets fixes à chacun des points de départ et d'arrivée. La formulation du modèle gravitaire est alors modifiée comme suit :

$$
T_{i,j} = a_i \times b_j \times \frac {N_{hab, i}\times N_{emp, j}} {f(d_{i,j})}
$$ {#eq-gravmod}

La détermination des coefficients $a_i$ et $b_j$ pose de nombreux problèmes. Ces coefficients doivent permettre de respecter les contraintes aux marges : la somme des emplois pour une ligne de résidents doit être égale au nombre des résidents employés dans la zone et la somme des résidents employés sur un lieu d'emploi doit, en colonne donc, être égale au nombre d'emplois en ce lieu. On a pour $a_i$ :

$$
\begin{aligned}
a_i &{}= \frac {\Sigma_j T_{i,j}} {\Sigma_j \frac {b_j \times N_{hab, i} \times N_{emp, j}}{f(d_{i,j})}} \\
&{}= \frac{1}{\Sigma_j \frac{ b_j \times N_{emp,j}}{f(d_{i,j})}}
\end{aligned}
$$ {#eq-ai}

$\Sigma_j T_{i,j}$ est généralement directement observé ou estimé lors de l'étape de génération dans les approches dites à 4 étapes. C'est le nombre de départs depuis le point $i$ et il est proportionnel aux nombre d'actifs résidant en $i$. De la même façon on peut écrire pour $b_j$ une expression symétrique de celle de $a_i$, qui fait intervenir $\Sigma_i T_{i,j}$ qui est également observée ou estimé auparavant. C'est le nombre de trajets convergeant vers le point d'arrivée $j$, qui est proportionnel au nombre d'emplois en $j$.

$$
\begin{aligned}
b_j &{}= \frac {\Sigma_i T_{i,j}} {\Sigma_i \frac {a_i \times N_{hab, i} \times N_{emp, j}}{f(d_{i,j})}} \\
&{}= \frac{1}{\Sigma_i \frac{a_i \times N_{hab,i}}{f(d_{i,j})}}
\end{aligned}
$$ {#eq-bj}

La valeur de $a_i$, pour un $i$ donné, dépend de l'évaluation de tous les $b_j$ et réciproquement l'évaluation de chaque $b_j$ dépend de celle de tous les $a_i$. On peut estimer ces coefficients par itérations successives et espérer atteindre de cette manière un point fixe, éventuellement unique à une constante multiplicative près. Des algorithmes de résolution ont donc été proposés dans les principaux manuels. L'application de tels algorithmes (comme celui de Furness, @de2011modelling, p. 192) peut toutefois modifier considérablement le résultat initial proposé par le modèle gravitaire, au risque d'en trahir la logique et les justifications initiales. En outre, la multiplicité des solutions et le choix retenu par l'algorithme demeure un angle mort de ces méthodes.

La procédure de respect des marges aurait pu être formulée différemment, par exemple en utilisant des corrections additives au lieu de corrections multiplicatives ou une combinaison d'additivité et de multiplicativité. Dans tous les cas, rien ne garantit l'existence d'une solution unique et compréhensible. En toute généralité, ces procédures peuvent conduire à des équilibres multiples que l'algorithme de résolution va sélectionner sans que l'on puisse justifier quoi que ce soit. Mais surtout, chacune de ces procédures manque de fondements théoriques : les $a_i$ et $b_j$ ne sont jamais que des "patchs" insignifiants ; ils ne correspondent à aucune caractéristique interprétable de la zone géographique étudiée.

Le succès du modèle gravitaire découle en partie de cette "plasticité" opérationnelle qui permet de l'appliquer à des observations en respectant certaines contraintes observées tout en laissant croire qu'un fondement théorique continue de justifier les opérations. Aussi l'approche gravitaire est-elle largement reprise dans des modèles appliquées (notamment les modèles *Land Use Transport Interaction*) en dépit de ses défauts, peut-être faute de mieux. Mais le décalage avec les données rend urgent de dépasser cette approche qui survit en se transformant en boîte noire.

## Une première alternative : le modèle radiatif {#sec-rad}

Le modèle radiatif est l'une des rares alternatives au modèle gravitaire [@de2011modelling]. Il reprend les intuitions de @stouffer1940 avec son modèle des "*intervening opportunities*", dont la logique est la suivante : un migrant prévoit d'aller dans un endroit distant mais trouve en chemin des opportunités ; il s'interrompt alors en chemin. Cette distraction de son objectif initial est le résultat des opportunités rencontrées en chemins, "intervenantes". La différence avec le modèle gravitaire est que ce n'est pas la distance qui détermine la destination, mais le nombre de rencontres. La distance et la structure géographique continuent de peser indirectement sur le choix des destinations puisque plus le migrant parcourt une grande distance, plus il a de chances de rencontrer des opportunités. La modélisation initiale de Stouffer souffre toutefois de quelques défauts[^theorie-1] et ne résout pas les questions de capacité ou de respect des contraintes sur les marges. Mais elle ouvre une autre perspective, où le rôle de la distance est médiatisé par le nombre d'opportunités rencontré, ce qui répond avec élégance aux insuffisances de l'analogie gravitaire.

[^theorie-1]: Notamment des défauts dans la formalisation qui repose sur une série d'approximation pas toujours explicitées et qui rend le modèle peu manipulable.

Avec Stouffer, c'est ainsi une autre métrique qui est proposée en lieu et place de la simple distance spatiale. Elle est liée à la notion d'accessibilité, c'est-à-dire au nombre d'emplois (et plus généralement d'opportunités) auxquels à accès un individu pour un temps de trajet ou une distance maximaux fixés. Un emploi apparaît ainsi d'autant plus "éloigné" d'un individu qu'il y a d'emplois plus proches de lui. Le modèle gravitaire posait que les individus font une grande différence entre le cas où le deuxième emploi disponible est à 500 m et celui où cet emploi est à 1 km. Dans la nouvelle perspective, il n'y a pas de différence car il s'agit toujours du second emploi rencontré. Autrement dit, la distance est relativisée par la prise en compte du milieu qui est traversé. Plus le milieu est riche en opportunités, moins il est nécessaire d'aller loin et, inversement, plus le milieu est désert, plus il faut se résoudre à aller loin. Ce modèle a connu de nombreuses applications, notamment à Chicago [@ruiter1967].

La proposition de @simini2012 répond à certaines failles de @stouffer1940 en proposant un modèle inspiré de la physique des radiations. Celui-ci décrit l'émission de particules et leur absorption par le milieu qu'elle traverse. L'intuition est la même que celle de @stouffer1940 : tant qu'une particule ne rencontre pas d'obstacle, elle poursuit son chemin. Elle ne s'arrête qu'en rencontrant un site qui peut l'absorber, selon un certaine probabilité. Plus le milieu est dense en obstacles, plus la particule a des chances de s'arrêter. Dans ce modèle, la distribution des distances parcourues dépend du milieu et de la quantité de sites d'absorption rencontrés.

Plus précisément, dans le modèle de radiation, chaque particule -- ou individu -- est tirée aléatoirement d'une distribution de probabilité avec une caractéristique $z$. Chaque point d'absorption, qui représente un lieu possible de travail, possède une masse d'emploi $n_i$ et se voit attribuer une caractéristique $z_i$ qui est aléatoire. Les lieux possibles sont classés par ordre de distance, comme dans le modèle de @stouffer1940 et la particule les rencontre dans cet ordre. Le tirage de $z_i$ est construit en tirant $n_i$ fois des $z$ dans la distribution de probabilité et en prenant le maximum de ces $z$. Plus la masse est grande en $i$, plus le $z_{max}$ sera grand. La particule émise est absorbée si son $z$ est plus petit que $z_i$. Pour représenter que la particule sera émise si elle n'est pas absorbée par son point de départ, son propre $z$ est tiré par la même méthode, c'est-à-dire le maximum de $m_i$ tirages où $m_i$ est la masse d'opportunités en $i$.

Le résultat principal de @simini2012 est particulièrement élégant. La valeur moyenne (notée $\langle T_{i,j}\rangle$ ) des trajets partant de $i$ et allant en $j$ a une expression qui ne dépend pas de la distribution de probabilité des $z$. Elle prend l'expression suivante, où $s_{i,j}=\Sigma_{k \in (i \rightarrow j)^*} n_k$ est la somme des opportunités entre $i$ (non inclus) et $j$ (non inclus) :

$$
\langle T_{i,j}\rangle = T_i \times \frac {m_i \times n_j}{(m_i + s_{i,j}) \times (m_i + n_i +s_{i,j})}
$$ {#eq-rad}

A partir d'hypothèses générales assez simples, on obtient une formulation qui s'apparente au modèle gravitaire en remplaçant la distance par l'accumulation des opportunités entre deux points, dès lors que les opportunités sont classées dans l'ordre des distances. Cette formulation respecte autant que le modèle gravitaire le premier principe de Tobler, mais elle repose sur des hypothèses explicites et permet de mieux représenter les phénomènes déjà évoqués. Un départ dans une zone peu dense produira des trajets plus longs pour trouver un nombre équivalent d'opportunités à des trajets plus courts dans une zone dense. De plus, aucune étape de "normalisation" *ad hoc* n'est requise et le modèle est probabiliste, ce qui permet de produire des marges d'erreurs et des tests empiriques.

Les applications du modèle radiatif à des données diverses (mouvements pendulaires travail-domicile, appels téléphoniques, migrations, logistique) produisent des distributions de trajets plus proches des données que le modèle gravitaire, mettant à mal la croyance selon lequel le modèle gravitaire serait un "bon" modèle, validé par les données.

On notera que le modèle de @simini2012 admet comme cas limite, sous certaines hypothèses de densité des emplois, le modèle gravitaire. En effet, lorsque la densité d'emplois est uniforme, l'accumulation des opportunités est proportionnelle à la surface et la moyenne de trajets entre $i$ et $j$ est une fonction en $1/r^4$ (voir aussi @ruiter1967). Ce cas limite montre sous quelle condition (très particulière) le modèle gravitaire peut être valide. Ce cas limite montre également que la forme fonctionnelle employée dans le modèle gravitaire dépend fortement de la distribution de la densité des opportunités. Et c'est bien là un des éléments qui manque au modèle gravitaire.

::: {.callout-tip}
## Le modèle des opportunités concurrentes de Fotheringham

Le modèle des opportinuté concurrentes de @fotheringham1983 conduit à une critique proche du modèle gravitaire. L'argument est que le modèle gravitaire ne permet pas de distinguer entre différentes configurations spatiales, si ce n'est lorsqu'il est contraint en ligne (chaque individu occupe un emploi et un seul) ou en ligne et en colonne (chaque emploi est occupé par un individu et un seul). Fotheringham [@fotheringham1983, @fotheringham1984] conclut que l'estimation habituelle du modèle gravitaire est biaisée d'une variable omise qui représente la structure spatiale. Le modèle des opportunités concurrentes est basé sur un index d'accessibilité (différent de celui que nous utiliserons ensuite) qui mesure pour chaque individu et chaque opportunité $j$ en quoi elle est accessible pour les autres individus ($k \neq i$) par l'expression $A_{ij}=\sum_{p \neq i,j}M_p/d_{pj}$. Ce terme introduit la structure spatiale, parce qu'une opportunité entourée d'individus a un index d'accessibilité plus élevé. Il découle de l'interprétation de la procédure de contrainte du modèle gravitaire. Ajouté au modèle gravitaire avec un paramètre ( $f_{ij} = I_i M_j^\beta d_{ij}^\delta A_{ij}^\phi \mu_{ij}$ où $I_i$ est le nombre d'individus à l'origine, $M_j$ l'attraction de la destination, $d_{ij}$ la distance entre $i$ et $j$ et $\mu_{ij}$ est un bruit) il permet d'introduire explicitement la structure dans le modèle gravitaire sans la faire intervenir dans une deuxièe étape lorsque de la simple ou double contrainte. Fotheringham interprète le paramètre $\phi$ comme indiquant soit des effets d'agglomération ($\phi>0$) soit des effets de concurrences entre sites d'attraction ($\phi<0$).

[@fik1990] intègrent à ce modèle celui des opportunités intervenantes pour en proposer une version plus riche dans la prise en compte de la structure. Si le constat sur les insuffisances du modèle gravitaire est le même et bien que l'analyse proposée par Fotheringham est particulièrement éclairante sur le biais de variable omise, nous verrons que notre proposition dans al lignée de @simini2012 diffère de celles-ci par l'explicitation de la façon dont la structure spatiale est prise en compte, ce qui permet aussi plus de finesse dans l'articulation des questions d'agglomération ou de concurrence ou encore de saturation.
:::

Il subsiste deux défauts au modèle radiatif de @simini2012. Le premier est le pendant de son élégance : il n'y a pas de paramètres pour l'ajuster, ce qui limite les capacités du modèle à rendre compte de la richesses des données. L'élégant calcul de la moyenne des trajets n'est valide que lorsque le processus sous-jacent suit parfaitement l'hypothèse des auteurs. Or, si l'on veut un modèle de base simple et clair sur le plan conceptuel, on veut aussi pouvoir enrichir le modèle avec des paramètres qui auraient du sens en regard de la richesse des données. Or la seule proposition qu'ils font dans ce sens consiste à introduire un $\varepsilon$ pour modifier le poids du point de départ dans le choix des trajets. Ceci ne répond que très partiellement à ce que l'on souhaiterait. A cet égard, le modèle gravitaire et encore plus le modèle de Fotheringham sont richement dotés en paramètres, ce qui permet de les ajuster sur les données, au risque toutefois d'un biais lié à la mauvaise définition des paramètres du modèle qui peuvent "attraper" tout ce qui n'a pas été explicité.

Le second défaut est que le modèle ne respecte pas les contraintes aux marges pour les destinations. Dans l'@eq-rad le terme $T_i$ permet de caler le modèle sur le nombre de départs de $i$. En revanche, il n'existe pas de pendant pour se caler sur les destinations $j$ et il n'est donc pas possible au modèle de tenir compte d'une contrainte capacitaire : un nombre de particules supérieur au nombre d'emplois peuvent être absorbées en $j$. Là aussi, le modèle gravitaire peut passer par dessus ce problème par l'applicaiton de procédure de contrainte, qui pourrait aussi bien être appliquées au modèle de @simini2012. Mais ici aussi on perd en route la possibilité d'interpréter ce que produit cette procédure de respect des contraintes.

## MEAPS : un Modèle Ergodique d'Absorption avec Priorité et Saturation {#sec-meaps}

Nous proposons maintenant une version étendue et remaniée de l'approche de @stouffer1940 qui répond aux critiques que nous faisons au modèle de @simini2012. Dans cette section, nous présentons le modèle dans sa forme plus simple avant d'en exposer les extensions les plus directes. Des simulations synthétiques permettent alors d'apprécier les grandes lignes du fonctionnement de ce modèle. Nous discutons ensuite des procédures d'estimation envisageables ainsi que du développement de mesures issues de ce modèle.

### Rang, choix des destinations et absorption

On considère $I$ individus et $J$ emplois[^theorie-2] localisés sur un territoire. Ces localisations sont fixes et exogènes, ce qui signifie que l'on ne s'intéresse pas au problème de choix de localisation. Non que ce choix ne soit pas important, mais nous nous intéressons à la distribution des trajets, une fois fixées les localisations. L'idée est que pour déterminer le choix de localisation, il faudra prendre en compte ce que la distribution des trajets, leur longueur ou leur coût généralisé nous apprend.

[^theorie-2]: Dans ce qui suit on regarde la relation entre résident et emploi ce qui suggère les mobilités domicile travail. C'est principalement pour fixer les idées, mais la relation entre résident et tout type d'aménités peut être abordée de la même façon. Il est également possible de décliner les résident selon des caractéristiques observables et d'indexer le modèle par ces catégories.

On suppose que toutes les localisations sont séparées et qu'il n'y a donc qu'un individu ou qu'un emploi par localisation (les emplois et les individus peuvent être au même endroit, ça ne change rien). Chaque individu $i$ classe par ordre de distance croissante les $J$ emplois et les examine dans cet ordre. Il a une probabilité $p_a$ de prendre un emploi (tous les emplois sont similaires et ont la même probabilité d'être pris). Tant qu'il ne prend pas d'emplois, l'individu continue sa recherche en passant à l'emploi suivant le plus proche (de son point de départ). La probabilité d'occuper l'emploi $j$ est donc égale à la probabilité de ne pas occuper les emplois plus proches multipliée par la probabilité $p_a$ d'occuper le poste $j$. En notant $r_{i}(j)$ le rang de l'emploi $j$ dans le classement des distances depuis $i$, on peut écrire $\bar F(j)$ la probabilité de dépasser le $j^{ème}$ élément :

$$
\bar F(j)=(1-p_a)^{r_i(j)}
$$ {#eq-fbar}

On définit également la probabilité de fuite de la zone considérée. Cette probabilité est celle qu'un individu ne trouve pas parmi les $J$ emplois celui qui lui convient et donc qu'il renonce ou cherche plus loin. En supposant pour le moment que cette probabilité est la même pour tous les individus, $p_f$, on peut déterminer $p_a$ :

$$
p_a = 1-(p_f)^{1/J}
$$ {#eq-pa}

La probabilité $P_i(j)$ de $i$ de s'arrêter en $j$ est :

$$
P_i(j) = (1-p_a)^{r_i(j)-1} \times p_a = {p_f}^{\frac {r_i(j)-1} {J}} \times (1-{p_f}^{1/J})
$$ {#eq-pij}

Cette expression définit donc la probabilité pour un individu $i$ d'occuper l'emploi $j$ comme une fonction de la probabilité de fuite, le rang de l'emploi et le nombre total d'emploi. La rang de $j$ n'est autre que le nombre d'opportunités cumulées du point de départ de $i$ jusqu'à $j$ et remplace la distance, comme dans les expressions de @stouffer1940 ou de @simini2012. Ce nombre n'est autre que l'accessibilité aux emplois de l'individu $i$ dans un cercle de rayon $[ij]$, que ce rayon soit défini en utilisant une distance euclidienne ou d'autres mesures comme le temps de parcours. On notera que l'on considère ici que les emplois sont identiques ou, du moins, parfaitement substituables pour l'individu.

Chaque emploi a été supposé distinct spatialement des autres. Dans le cas où les emplois ne seraient pas séparés et pourraient s'accumuler en un point ou au sein d'un carreau, la formalisation ne change pas. La probabilité que l'on s'arrête dans le carreau $c_d$ situé à une distance $d$ de $i$ où se trouvent $k$ emplois se déduit de l'@eq-fbar puisque les $k$ emplois ont des rangs successifs. En notant $s_i(d)=\sum _{j/d_{i,j}<d}1$ le cumul de tous les emplois qui sont à une distance strictement inférieure à celle du carreau considéré pour $i$ (et donc à l'exclusion des $k$ emplois du le carreau $c_d$), on a :

$$
P_i(i\in c_d) = {p_f}^{s_i(d)/J}\times(1-{p_f}^{ k/J})
$$ {#eq-picd}

En prenant un développement limité au 1^er^ ordre de cette expression (sous l'hypothèse que $k$ est petit devant le nombre total d'opportunités $J$) , on obtient, en notant $\mu=\frac{-log(p_f)}{J}$ :

$$
P_i(i\in c_d) \approx k\times \mu \times e^{-\mu \times s_i(d)}
$$ {#eq-picddl}

Cette expression fait apparaître clairement le cœur du modèle. La proportion d'emplois venant de $i$ dans le carreau est une fonction des emplois dans le carreau multiplié par l'accessibilité jusqu'à ce carreau de $i$.

Lorsque la densité des emplois est constante sur un plan, $s_i(d)$ est proportionnel à la surface et le modèle devient une fonction de la distance avec un terme en $e^{-r^2/\rho^2}$. Ici aussi, le comportement de notre modèle rejoint, sous cette condition très particulière d'une répartition homogène des opportunités, celui proposé pour un modèle gravitaire, lorsque celui-ci est spécifié avec une fonction de distance en $e^{r/\rho}$. La forme favorite du modèle gravitaire se justifierait pour une répartition homogène des opportunités le long d'une droite[^theorie-3]. Ce résultat diffère de celui de @simini2012, qui trouvaient un comportement asymptotique en $1/r^4$.

[^theorie-3]: La littérature sur le commerce international fait un grand usage du modèle gravitaire et on y trouve des développements très riches. Le problème du commerce international est un peu différent de celui de l'analyse des distribution de déplacement parce qu'on observe les flux bilatéraux par produit de façon répétée entre les pays. On dispose ainsi d'une grande quantité d'informations à relier entre elles par la représentation gravitaire. La question du transport est différente en ce que la distance entre origines et destination est bien connue, mais que les trajets bilatéraux ne le sont pas. On dispose en revanche d'information sur la distribution des trajets en fonction de leur distance, de leur motif et des modes employés.

Tout comme dans le modèle de @simini2012, le résultat est sans paramètre, parce que la probabilité de fuite est entièrement déterminée par la contrainte en ligne (l'individu $i$ a une espérance égale à 1 - $p_f$ de trouver un emploi dans la zone considérée).

### Saturation et priorité {#sec-priorite}

Il reste encore à prendre en compte la contrainte en colonne, c'est-à-dire le fait que chaque emploi peut être pourvu une fois et une seule. Au lieu d'un ajustement *ad hoc* qui tombe de nulle part, nous proposons le mécanisme suivant de remplissage des emplois : chaque individu $i$ est classé selon un ordre de priorité. L'individu au premier rang est confronté à l'ensemble des emplois et nous calculons ses probabilités de prendre un emploi $j$ par la formule précédente (@eq-pij). Les emplois sont alors partiellement remplis à proportion de ces probabilités[^theorie-4]. Le deuxième individu est traité de la même manière, et ainsi de suite, jusqu'à ce qu'un ou plusieurs emplois soient totalement pourvu (lorsque la somme des probabilités dépasse tout juste 1). On retire alors ces emplois de la liste des choix possibles et on continue l'affectation pour les individus suivants sur la liste réduite. A chaque individu ajouté, on peut être amené à retirer d'autres emplois de la liste de recherche.

[^theorie-4]: En toute rigueur, les probabilités ne s'additionnent pas si simplement et un traitement exact exigerait de tenir compte de probabilités conditionnelles au fait que tel emploi a été pris, ou non, auparavant. La procédure décrite ici est une simplification, en subsituant aux probabilités conditionnelles des espérances.

A la fin de ce processus, tous les individus ont des emplois (à $p_f$ près) et tous les emplois sont pourvus dès lors que l'on pose $I \times (1 - p_f) = J$. Cette attribution avec priorité est Pareto-optimale. Il n'est pas possible d'augmenter la satisfaction d'un individu sans dégrader celle d'un autre. A chaque étape, chaque individu réalise ses choix sans contrainte autre que l'éventuelle saturation provoquée par ses prédécesseurs. Pour augmenter sa satisfaction, c'est-à-dire lui permettre d'occuper en probabilité un emploi mieux classé pour lui, il faudrait dégrader la situation d'un prédécesseur en lui attribuant un emploi plus éloigné pour lui. Cette procédure d'affectation avantage les premiers du classement, mais tient compte des choix de chacun.

Formellement, on note $\phi_u(i,j)$ la probabilité de disponibilité ($\phi$ vaut 0 si l'emploi est complètement pris) de l'emploi $j$ pour un ordre de priorité donné $u$ au moment où l'individu $i$ doit choisir. La probabilité de cet individu $i$ de prendre l'emploi $j$ s'écrit alors :

$$
P_{u, i}(j) = \lambda_{u,i}.\phi_u(i,j). p_a \prod_{l=1}^{r_i^{-1}(j)-1}(1-\lambda_{u,i}. \phi_u(i,r^{-1}(l)).p_a)
$$ {#eq-puij}

Cette expression est rendue complexe par la nécessité de parcourir les emplois dans l'ordre qui correspond à chaque individu. La probabilité $p_a$ doit alors être calculée pour que le taux de fuite de $i$ soit inchangé. On suppose que les emplois restants demeurent parfaitement substituables tout au long du processus d'affectation. La probabilité de chacun est donc identique et ajustée d'un facteur multiplicatif $\lambda_{u,i}$. Le terme $\lambda_{u,i}$ découle ainsi de l'indisponibilité potentielle des emplois. Lorsqu'un emploi est indisponible, l'individu $i$, lorsque c'est son tour de choisir, connait ses cibles potentielles. Il ajuste donc sa probabilité d'absorption de façon à respecter la probabilité de fuite. C'est de cette manière que nous respectons la contrainte en ligne, qui s'exprime par l'@eq-lambda ci-dessous. Ceci signifie qu'un individu a d'autant plus de chances d'accepter un emploi qu'il reste peu de choix.

Une autre solution serait de considérer que la probabilité de fuite n'est pas conservée et que les indisponibilités se traduisent par une fuite plus élevée. On peut tout à fait envisager des solutions plus complexes. Nous nous en tenons pour l'instant au cas simple où tous les individus ont la même chance de travailler dans la zone considérée[^theorie-5]. Sous cette hypothèse de conservation de la probabilité de fuite, on a :

[^theorie-5]: En pratique, pour éviter les effets de bord, il faut choisir une zone d'emplois plus grande que la zone des résidents.

$$
\forall i, \prod_{j=1} ^{J} (1-\lambda_{u,i} \times \phi_u(i,j) \times p_{a})= p_f
$$ {#eq-lambda}

La solution de cette équation est celle d'un polynôme en $\lambda_{u,i}$ d'un ordre élevé. Il y a possiblement plusieurs solutions, mais il est nécessaire que $0<\lambda_{u,i}\times p_a<1$, ce qui réduit le nombre de solutions admissibles. Pour un $i$ donné, on peut en produire une solution approchée par un développement limité à l'ordre 1 en prenant le $log$ de l'@eq-lambda :

$$
p_{a} \times \lambda_{u,i} = \frac {-log(p_f)}{\sum_{j=1} ^{J} \phi_u(i,j)}
$$ {#eq-lambdadl}

On peut vérifier que $0<\lambda_{u,i}\times p_a<1$ lorsque $J$ est assez grand et que le nombre d'emplois restant demeure élevé (en probabilité) par rapport à $-log(p_f)$.

### Ergodicité {#sec-erg}

Chaque ordre de priorité $u$ définit une trajectoire possible d'affectation des emplois aux résidents (ou l'inverse). On aboutit à chaque fois à un état possible de l'appariement résidents-emplois d'où l'on déduit les trajets professionnels. Bien entendu, le résultat final dépend de l'ordre de priorité choisi. Pour s'en affranchir, la stratégie usuelle en physique statistique consiste à réitérer la procédure pour tous les ordres possibles de priorité et à considérer la moyenne des résultats obtenus sur les $I!$ ordres de priorité possibles.

L'hypothèse ergodique consiste ici à soutenir que cette moyenne sur tous ces ordres de priorité est proche du régime permanent des trajets professionnels sur la zone considérée.

La première grandeur que nous moyennons sur les ordres $u$ est la variable de disponibilités $\phi_u(i,j)$ de l'emploi $j$ pour le résident $i$. Cette moyenne $\langle\phi\rangle_u(n,j)$ correspond à la probabilité de disponibilité de l'emploi $j$ pour n'importe quel résident après que $n$ résidents occupent d'ores et déjà un emploi ou ont fuit la zone. Cette grandeur ne dépend pas de $i$, mais uniquement du nombre de résidents déjà positionnés.

Une deuxième grandeur nous sera utile. Il s'agit de l'accessibilité moyenne aux emplois disponibles. On peut noter $A_n(i,k)$ le cumul des emplois qui restent disponibles pour $i$ lorsque $n$ résidents se sont d'ores et déjà positionnés, en comptant les emplois depuis le plus proche de $i$ jusqu'au $k^{ième}$ le plus proche. La grandeur qui nous intéresse est la moyenne sur tous les $n$ possibles, soit :

$$
\langle A \rangle_n(i,k) = \langle\sum_{j, r_i(j)\leq k} \langle \phi \rangle_u(n,j) \rangle _n
$$ {#eq-an}

La particularité de cette accessibilité est qu'à mesure que les emplois sont pris (lorsque $n$ s'accroît), l'accessibilité se restreint puisqu'elle ne retient que la part encore disponible des emplois proches.

Comme précédemment, nous considérons que la probabilité de fuite d'un individu est une constante. Dans ce cas, la probabilité d'absorption va augmenter au fur et à mesure que les emplois sont pris : moins il reste d'emplois disponibles, plus un résident est prêt à accepter ceux qui restent. La probabilité $P_a$ va donc dépendre de $n$ et s'écrire ici $P_{a,n}$.

Pour un $n$ donné, on a :

$$
P_f=\prod_{k=1}^J(1-P_{a,n}\times \langle \phi \rangle_u(n, r_i^{-1}(k))
$$ {#eq-pf2}

En passant en $log$ et en effectuant un développement limité, on obtient :

$$
log(P_f)=-P_{a,n}\times\sum_{k=1}^J \langle \phi \rangle_u(n,r_i(k))=-P_{a,n}\times(J-(1-P_f)\times n)
$$ {#eq-logpf}

Nous avons alors tous les éléments pour calculer la probabilité $P_n(i,j)$ que le résident $i$ prenne l'emploi $j$ après que $n$ résidents se sont déjà positionnés (cf. @eq-pij). En passant alors en $log$, on a :

$$
log(P_n(i,j))=log(P_{a,n})+log(\langle\phi \rangle_u(n,j))+\sum_{k=1}^{r_i^{-1}(j)}log(1-P_{a,n}\times \langle \phi \rangle_u(n,r_i(k))
$$ {#eq-logpij}

En faisant un développement limité du dernier terme puis la moyenne sur les $n$, il en découle :

$$
log(P_{ij})\approx\langle log(P_{a,n})\rangle _n+\langle\langle\phi\rangle_u(n,j)\rangle_n + \langle A\rangle_n(i, r_i(j))
$$ {#eq-logpijapprox}

La probabilité $P_{ij}$ s'écrit donc à partir de la probabilité moyenne d'absorption, de l'espérance que l'emploi $j$ est disponible et de l'accessibilité moyenne. Sur le plan conceptuel, c'est tout à fait satisfaisant et compréhensible. Il reste que ces grandeurs ne peuvent pas être calculées directement ; il faut en passer par des simulations.

### Hétérogénéité de la fuite et de l'absorption {#sec-hetero}

Nous avons considéré jusqu'à présent le cas où les individus et les emplois étaient parfaitement substituables. Cela simplifie le modèle et permet une résolution explicite. Il est cependant possible de complexifier le modèle en introduisant des paramètres interprétables qui permettent une meilleure prédiction et l'extraction d'informations des données.

Tout d'abord, le paramètre de fuite peut être spécifique à chaque commune de résidents ou chaque type de résidents. Par exemple, le recensement nous permet de mesurer la proportion d'individu, par commune, qui ont un emploi à plus de 100km de leur domicile. Cette proportion est faible ($<5\%$ pour une région comme celle étudiée dans l'application à la Rochelle @sec-rochelle) mais peut varier d'une commune à l'autre pour diverses raisons : les communes ne sont pas toutes aussi bien desservies ; certaines se trouvent à la périphérie de la zone d'étude ; les caractéristiques moyennes des résidents varient d'une commune à l'autre... Le modèle peut sans difficulté prendre en compte une probabilité de fuite $p_{f,i}$ pour chaque individu.

Ensuite, le paramètre d'absorption était jusqu'à maintenant identique pour tous les emplois et tous les individus. On peut le rendre dépendant des emplois, $p_{a,j}$, pour marquer un effet fixe spécifique à des emplois, de manière à souligner l'attractivité de telle ou telle zone d'emplois. Le recensement nous donne quelques informations sur les trajets professionnels de commune à commune et, donc, sur l'attractivité différentielle entre communes. D'autres données pourraient nous informer à un niveau infra-communal. On pourrait aussi vouloir faire dépendre la probabilité d'absorption de caractéristiques observables des emplois. Des emplois dans une zone dense en emploi peuvent, au-delà de l'effet masse déjà pris en compte, être plus attractifs que des emplois isolés. Dans ce cas, l'absorption dépend de caractéristiques $X$ observées et en spécifiant la forme fonctionnelle de $p_a(X)$ on peut l'estimer de façon à mieux reproduire l'information sur la distribution des déplacements.

Le modèle présenté est suffisamment flexible pour pouvoir rendre compte de phénomènes plus complexes afin de, à la fois, pouvoir exploiter des données riches et modéliser des comportements (de fuite, d'absorption) qui semblent avoir un sens. Si au lieu d'apparier les individus et les emplois, on s'intéresse au cas du choix des écoles, on peut imaginer que l'absorption de l'école la plus proche est élevée tandis que celles de rang supérieur s'effondrent rapidement. Si l'individu est indifférent aux caractéristiques des écoles, hors leur emplacement, il prend l'école la plus proche. Le refus de cette première école peut s'expliquer par une exigence parentale non observable, qui se traduit par une distance parcourue plus élevée. Mais le modèle de base rendant compte d'une baisse de l'absorption au-delà du premier rang sera vraisemblablement assez bon[^theorie-6]. Il est possible aussi d'augmenter ou de diminuer l'absorption de certaines paires résidents-écoles, ce qui est une manière d'introduire par exemple les informations sur la carte scolaire.

[^theorie-6]: De façon plus générale, on peut spécifier une loi de la probabilité d'absorption quelconque qui doit vérifier que $\sum_{k=1,J} p_{i,r_i(k)} = p_{f,i}$ pour tout $i$. Toute paramétrisation de cette loi de probabilité peut alors être simulée et ajustée sur des données. Si les paramètres ont une interprétation théorique, on peut alors les identifier.

On peut ainsi modifier les probabilités d'absorption en donnant à un groupe particulier de paires individus emplois plus ou moins de chances d'être absorbé. En jouant sur les groupes qui partionnent les paires individus $\times$ emplois on peut augmenter ou réduire le nombre de degré de liberté du système. Lorsque seule la probabilité d'absorption est un paramètre, le nombre de degré de liberté est diminué de 1 et le paramètre $p$ est déterminé par la condition d'égalité entre le nombre d'emplois pourvus et d'individus. Si on dispose d'une information sur la probabilité de fuite par individu ou par groupe d'individus, le nombre de degré de liberté peut être accru par une probabilité de fuite différenciée selon ces groupes. On peut encore accroître le nombre de degré de liberté en croisant une probabilité d'absorption par groupes d'emplois et groupes d'individus. Le choix de la spécification dépendra de ce que l'on souhaite réaliser et du problème considéré. On verra dans la @sec-rochelle une application en recourant à un grand nombre de degrés de liberté afin d'ajuster le modèle sur des données détaillées (donnant pour des paires commune de résidence $\times$ commune d'emploi une observation des flux de mobilité professionnels). Dans une publication ultérieure, nous montrerons une détermination parcimonieuse des coefficients correcteurs afin de pouvoir extraire une information pertinente des données de flux entre communes et de pouvoir comparer le pouvoir prédictif de *MEAPS* à celui d'un modèle gravitaire, à degré de liberté égal.

En indexant par $i$ les probabilités de fuite $p_{f,i}$ et par $i,j$ les coefficients correcteurs $\lambda_{i,j}$, les équations principales du modèle deviennent :

$$
P_{i, u}(j) = \lambda_{i,j} . p_{a} \prod _{l=1} ^{r_{u(i)}(j)-1} {[1-\lambda_{i,r_{u(i)}(l)}. p_{a}.\phi_u(i,r_{u(i)}^{-1}(l))]}
$$ {#eq-comp1}

$$
\prod _{l=1} ^{J} {[1-\lambda_{i,r_{u(i)}(l)}.p_{a}.\phi_u(i,r_{u(i)}^{-1}(l))]}= p_{f,i}
$$ {#eq-lambdacomp}

Il n'est pas possible de donner une forme réduite de cette dernière expression. En revanche, elle est calculable numériquement pour chaque $u$, $i$ et $j$ en fonction des hypothèses du modèle ($p_{f,i}$, $p_{a,j}$, la structure spatiale des résidents et des emplois) et sert de base à l'algorithme de calcul employé dans les simulations présentées dans la section @sec-synt[^theorie-7].

[^theorie-7]: L'implémentation de cette expression est implémentée dans le package R `{rmeaps}` disponible dasn le dépôt github [github.com/maxime2506/rmeaps](https://github.com/maxime2506/rmeaps) et s'installe par `devtools::install_github("maxime2506/rmeaps")`. L'implémentation est faite en C++ et repose sur la parallélisation pour traiter le parcours des ordres de priorités.

Le modèle ainsi construit est flexible puisqu'on peut spécifier des processus de fuite (contrainte en ligne équivalente à la contrainte [-@eq-ai]) et des processus d'absorption qui respecte la contrainte de saturation des emplois (contrainte en ligne équivalente à la contrainte [-@eq-bj]) par le processus de priorité décrit en @sec-priorite. Le parcours de toutes les permutations possibles permet de s'affranchir d'un ordre de priorité particulier et de définir une solution moyenne au processus. Lorsqu'on analyse le problème avec une grille de taille finie (ou de taille inférieure au nombre $J$ d'opportunités), on peut conjecturer un comportement ergodique des quantités moyennes prédites par le modèle. On résout de cette façon explicitement le problème de contrainte aux marges du modèle gravitaire ou du modèle radiatif.
