[
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Références",
    "section": "",
    "text": "Références\n\n\nAgresti, A. (2002), « Categorical Data Analysis », Wiley Series in Probability and Statistics. https://doi.org/10.1002/0471249688\n\n\nAitchison, J. & Ho, C.H. (1989), « The multivariate Poisson-log normal distribution », Biometrika, vol. 76, n°4, pp. 643‑653. https://doi.org/10.1093/biomet/76.4.643\n\n\nBatty, M. (2013), The New Science of Cities, The MIT Press. https://doi.org/10.7551/mitpress/9399.001.0001\n\n\nBaude, M. (2022), « La décomposition de l’empreinte carbone de la demande finale de la France par postes de consommation : transport, alimentation, habitat, équipements et services », document de travail, n°59, Ministère de la transition écologique et de la cohésion des territoires.\n\n\nBen-Akiva, M. & Lerman, S.R. (2018), Discrete choice analysis: theory and application to travel demand, MIT Press (Transportation Series).\n\n\nBettencourt, L. (2021), Introduction to Urban Science: Evidence and Theory of Cities as Complex Systems. https://doi.org/10.7551/mitpress/13909.001.0001\n\n\nBlaudin de Thé, C., Carantino, B. & Lafourcade, M. (2021), « The carbon ‘carprint’ of urbanization: New evidence from French cities », Regional Science and Urban Economics, vol. 89, pp. 103693. https://doi.org/10.1016/j.regsciurbeco.2021.103693\n\n\nBrownstone, D. & Golob, T.F. (2009), « The impact of residential density on vehicle usage and energy consumption », Journal of Urban Economics, vol. 65, n°1, pp. 91‑98. https://doi.org/10.1016/j.jue.2008.09.002\n\n\nC200 (2022), « Revenus, pauvreté et niveau de vie en 2017 - Données carroyées. Dispositif Fichier localisé social et fiscal (Filosofi) »,.\n\n\nCervero, R. (1989), « Jobs-Housing Balancing and Regional Mobility », Journal of the American Planning Association, vol. 55, n°2, pp. 136‑150. https://doi.org/10.1080/01944368908976014\n\n\nCervero, R. & Kockelman, K. (1997), « Travel demand and the 3Ds: Density, diversity, and design », Transportation Research Part D: Transport and Environment, vol. 2, n°3, pp. 199‑219. https://doi.org/10.1016/S1361-9209(97)00009-6\n\n\nColin Cameron, A. & Windmeijer, F.A.G. (1997), « An R-squared measure of goodness of fit for some common nonlinear regression models », Journal of Econometrics, vol. 77, n°2, pp. 329‑342. https://doi.org/10.1016/s0304-4076(96)01818-0\n\n\nConway, M.W., Byrd, A. & Linden, M. van der (2017), « Evidence-Based Transit and Land Use Sketch Planning Using Interactive Accessibility Methods on Combined Schedule and Headway-Based Networks », Transportation Research Record: Journal of the Transportation Research Board, vol. 2653, n°1, pp. 45‑53. https://doi.org/10.3141/2653-06\n\n\nConway, M.W., Byrd, A. & Van Eggermond, M. (2018), « Accounting for uncertainty and variation in accessibility metrics for public transport sketch planning », Journal of Transport and Land Use, vol. 11, n°1. https://doi.org/10.5198/jtlu.2018.1074\n\n\nConway, M.W. & Stewart, A.F. (2019), « Getting Charlie off the MTA: a multiobjective optimization method to account for cost constraints in public transit accessibility metrics », International Journal of Geographical Information Science, vol. 33, n°9, pp. 1759‑1787. https://doi.org/10.1080/13658816.2019.1605075\n\n\nConway, R.W. & Maxwell, W.L. (1962), « A queuing model with state dependent service rates », Journal of Industrial Engineering, vol. 12, n°2, pp. 132‑136.\n\n\nDantzig, G.B., Dantzig, G.B. & Saaty, T.L. (1973), Compact City: A Plan for a Liveable Urban Environment, W. H. Freeman.\n\n\nDios Ortúzar, J. de & Willumsen, L.G. (2011), Modelling transport, John wiley & sons.\n\n\nDuranton, G., Henderson, J.V. & Strange, W. (dir.) (2015a), Handbook of Regional and Urban Economics, 1ʳᵉ édition, Elsevier.\n\n\nDuranton, G., Henderson, V. & Strange, W. (2015b), « Foreword », in Elsevier, pp. xv‑xvi. https://doi.org/10.1016/b978-0-444-59517-1.09998-0\n\n\nDuranton, G. & Turner, M.A. (2018), « Urban form and driving: Evidence from US cities », Journal of Urban Economics, vol. 108, pp. 170‑191. https://doi.org/10.1016/j.jue.2018.10.003\n\n\nEwing, R. (1997), « Is Los Angeles-Style Sprawl Desirable? », Journal of the American Planning Association, vol. 63, n°1, pp. 107‑126. https://doi.org/10.1080/01944369708975728\n\n\nEwing, R. & Cervero, R. (2010), « Travel and the Built Environment », Journal of the American Planning Association, vol. 76, n°3, pp. 265‑294. https://doi.org/10.1080/01944361003766766\n\n\nEwing, R. & Hamidi, S. (2015a), « Compactness versus Sprawl: A Review of Recent Evidence from the United States », Journal of Planning Literature, vol. 30, n°4, pp. 413‑432. https://doi.org/10.1177/0885412215595439\n\n\nEwing, R. & Hamidi, S. (2015b), « Compactness versus Sprawl: A Review of Recent Evidence from the United States », Journal of Planning Literature, vol. 30, n°4, pp. 413‑432. https://doi.org/10.1177/0885412215595439\n\n\nEwing, R., Hamidi, S., Tian, G., Proffitt, D., Tonin, S. & Fregolent, L. (2017), « Testing Newman and Kenworthy’s Theory of Density and Automobile Dependence », Journal of Planning Education and Research, vol. 38, pp. 0739456X1668876. https://doi.org/10.1177/0739456X16688767\n\n\nFik, T.J. & Mulligan, G.F. (1990), « Spatial Flows and Competing Central Places: Towards a General Theory of Hierarchical Interaction », Environment and Planning A: Economy and Space, vol. 22, n°4, pp. 527‑549. https://doi.org/10.1068/a220527\n\n\nFlowerdew, R. & Aitkin, M. (1982), « A Method of Fitting the Gravity Model Based on the Poisson Distribution* », Journal of Regional Science, vol. 22, n°2, pp. 191‑202. https://doi.org/10.1111/j.1467-9787.1982.tb00744.x\n\n\nFotheringham, A.S. (1983b), « A New Set of Spatial-Interaction Models: The Theory of Competing Destinations », Environment and Planning A: Economy and Space, vol. 15, n°1, pp. 15‑36. https://doi.org/10.1177/0308518X8301500103\n\n\nFotheringham, A.S. (1983a), « A New Set of Spatial-Interaction Models: The Theory of Competing Destinations », Environment and Planning A: Economy and Space, vol. 15, n°1, pp. 15‑36. https://doi.org/10.1177/0308518X8301500103\n\n\nFotheringham, A.S. (1984), « Spatial Flows and Spatial Patterns », Environment and Planning A: Economy and Space, vol. 16, n°4, pp. 529‑543. https://doi.org/10.1068/a160529\n\n\nGaigné, C., Riou, S. & Thisse, J.-F. (2012), « Are compact cities environmentally friendly? », Journal of Urban Economics, vol. 72, n°2-3, pp. 123‑136. https://doi.org/10.1016/j.jue.2012.04.001\n\n\nGordon, P. & Richardson, H.W. (1997), « Are Compact Cities a Desirable Planning Goal? », Journal of the American Planning Association, vol. 63, n°1, pp. 95‑106. https://doi.org/10.1080/01944369708975727\n\n\nGrazi, F., Bergh, J.C.J.M.V.D. & Ommeren, J.N.V. (2008), « An Empirical Analysis of Urban Form, Transport, and Global Warming », The Energy Journal, vol. 29, n°4. https://doi.org/10.5547/ISSN0195-6574-EJ-Vol29-No4-5\n\n\nHeanue, K.E. & Pyers, C.E. (1966), « A Comparative Evaluation of Trip Distribution Procedures », Highway Reserach Record, n°114, pp. 20‑50.\n\n\nHensher, D.A. & Button, K.J. (dir.) (2007), « Handbook of Transport Modelling », Handbooks in Transport. https://doi.org/10.1108/9780857245670\n\n\nHirt, S. (2012), « Mixed Use by Default: How the Europeans (Don’t) Zone », Journal of Planning Literature, vol. 27, n°4, pp. 375‑393. https://doi.org/10.1177/0885412212451029\n\n\nHolden, E. & Norland, I.T. (2005), « Three Challenges for the Compact City as a Sustainable Urban Form: Household Consumption of Energy and Transport in Eight Residential Areas in the Greater Oslo Region », Urban Studies, vol. 42, n°12, pp. 2145‑2166. https://doi.org/10.1080/00420980500332064\n\n\nHolian, M.J. (2020), « The impact of urban form on vehicle ownership », Economics Letters, vol. 186, pp. 108763. https://doi.org/10.1016/j.econlet.2019.108763\n\n\nHsu, D., Andrews, C.J., T. Han, A., G. Loh, C., C. Osland, A. & P. Zegras, C. (2023), « Planning the Built Environment and Land Use Towards Deep Decarbonization of the United States », Journal of Planning Literature, vol. 38, n°3, pp. 426‑441. https://doi.org/10.1177/08854122221097977\n\n\nJacobs, J. (1961), The Death and Life of Great American Cities, Vintage Books (A Vintage livre).\n\n\nJaramillo, P., Ribeiro, S.K., Newman, P., Dhar, S., Diemuodeke, O.E., Kajino, T., Lee, D.S., Nugroho, S.B., Ou, X., Strømman, A.H. & Whitehead, J. (2023), « 10. Transport », in Cambridge University Press, pp. 1049‑1160. https://doi.org/10.1017/9781009157926.012\n\n\nJenks, M., Williams, K. & Burton, E. (1996), « A Sustainable Future through the Compact City? Urban Intensification in the United Kingdom », Environments by Design, vol. 1, pp. 5‑20.\n\n\nJenks, M., Williams, K. & Burton, E. (dir.) (2003), « The Compact City: A Successful, Desirable and Achievable Urban Form? », in Routledge, pp. 54‑65. https://doi.org/10.4324/9780203362372-12\n\n\nJosselin, D., Carpentier-Postel, S., Audard, F., Amarouch, S., Durand, J.-B., Brachet, N., Coulon, M. & Garcin, L. (2020), « Estimer des flux de navetteurs avec un modèle gravitaire : application géomatique en région Provence-Alpes-Côte d’Azur (France)1 », Geomatica, vol. 74, n°3, pp. 104‑130. https://doi.org/10.1139/geomat-2020-0009\n\n\nKoenig, G. (1974), « Theorie economique de l’accessibilite urbaine », Revue économique, vol. 25, n°2, pp. 275. https://doi.org/10.2307/3500570\n\n\nKoenig, J.G. (1980), « Indicators of urban accessibility: Theory and application », Transportation, vol. 9, n°2, pp. 145‑172. https://doi.org/10.1007/bf00167128\n\n\nKullback, S. & Leibler, R.A. (1951), « On Information and Sufficiency », The Annals of Mathematical Statistics, vol. 22, n°1, pp. 79‑86. https://doi.org/10.1214/aoms/1177729694\n\n\nLasser, J. (2020), « Creating an executable paper is a journey through Open Science », Communications Physics, vol. 3, n°1. https://doi.org/10.1038/s42005-020-00403-4\n\n\nLee, S. & Lee, B. (2020), « Comparing the impacts of local land use and urban spatial structure on household VMT and GHG emissions », Journal of Transport Geography, vol. 84, pp. 102694. https://doi.org/10.1016/j.jtrangeo.2020.102694\n\n\nLenormand, M., Bassolas, A. & Ramasco, J.J. (2016), « Systematic comparison of trip distribution laws and models », Journal of Transport Geography, vol. 51, pp. 158‑169. https://doi.org/10.1016/j.jtrangeo.2015.12.008\n\n\nLevine, J. (2010), Zoned Out: Regulation, Markets, and Choices in Transportation and Metropolitan Land Use, Taylor & Francis.\n\n\nLwasa, S., Seto, K.C., Bai, X., Blanco, H., Gurney, K.R., Kılkış, Ş., Lucon, O., Murakami, J., Pan, J., Sharifi, A. & Yamagata, Y. (2022), « Urban Systems and Other Settlements », in Cambridge, UK; New York, NY, USA, Cambridge University Press.\n\n\nMasson, V., Marchadier, C., Adolphe, L., Aguejdad, R., Avner, P., Bonhomme, M., Bretagne, G., Briottet, X., Bueno, B., Munck, C. de, Doukari, O., Hallegatte, S., Hidalgo, J., Houet, T., Le Bras, J., Lemonsu, A., Long, N., Moine, M.-P., Morel, T., Nolorgues, L., Pigeon, G., Salagnac, J.-L., Viguié, V. & Zibouche, K. (2014), « Adapting cities to climate change: A systemic modelling approach », Urban Climate, vol. 10, pp. 407‑429. https://doi.org/10.1016/j.uclim.2014.03.004\n\n\nMassot, M.-H. & Orfeuil, J.-P. (2007), « La contrainte énergétique doit-elle réguler la ville ou les véhicules ? Mobilités urbaines et réalisme écologique », Les Annales de la Recherche Urbaine, vol. 103, n°1, pp. 18‑29. https://doi.org/10.3406/aru.2007.2710\n\n\nMcFadden, D. (1974), « The measurement of urban travel demand », Journal of Public Economics, vol. 3, n°4, pp. 303‑328. https://doi.org/10.1016/0047-2727(74)90003-6\n\n\nMOBPERS (2021), « EMP 2019 Résultats détaillés de l’enquête mobilité des personnes de 2019 »,.\n\n\nMOBPRO (2022), « Mobilités professionnelles en 2019 : déplacements domicile - lieu de travail Recensement de la population - Base flux de mobilité »,.\n\n\nMunafò, S. (2017), « Forme urbaine et mobilités de loisirs : l’« effet barbecue » sur le grill », Cybergeo: European Journal of Geography. https://doi.org/10.4000/cybergeo.28634\n\n\nMuñiz, I., Calatayud, D. & Dobaño, R. (2013), « The compensation hypothesis in Barcelona measured through the ecological footprint of mobility and housing », Landscape and Urban Planning, vol. 113, pp. 113‑119. https://doi.org/10.1016/j.landurbplan.2013.02.004\n\n\nNewman, P. & Kenworthy, J. (1989b), Cities and Automobile Dependence, Brookfield, Gower Technical.\n\n\nNewman, P. & Kenworthy, J. (1989a), « Gasoline Consumption and Cities », Journal of the Amrican Planning Association, vol. Winter 1989, pp. 24‑37. https://doi.org/10.1080/01944368908975398\n\n\nNewman, P. & Kenworthy, J. (1999), Sustainability and Cities: Overcoming Automobile Dependence, Island Press.\n\n\nOpenStreetMap contributors (2017), « Planet dump retrieved from https://planet.osm.org »,.\n\n\nOrfeuil, J.-P. & Soleyret, D. (2002), « Quelles interactions entre les marchés de la mobilité à courte et à longue distance ? », Recherche - Transports - Sécurité, vol. 76, pp. 208‑221. https://doi.org/10.1016/S0761-8980(02)00013-4\n\n\nPan, H., Shen, Q. & Zhang, M. (2009), « Influence of Urban Form on Travel Behaviour in Four Neighbourhoods of Shanghai », Urban Studies, vol. 46, n°2, pp. 275‑294. https://doi.org/10.1177/0042098008099355\n\n\nParodi, M. & Timbeau, X. (2023), « MEAPS : modéliser les flux de navetteurs », Document de travail de l’OFCE, n°11-2023.\n\n\nParodi, M. & Timbeau, X. (2024a), « La ville compacte : une solution pour réduire les émissions de gaz à effet de serre ? », Document de travail de l’OFCE, n°5-2024.\n\n\nParodi, M. & Timbeau, X. (2024b), « MEAPS&Gravitaire : Estimations à la Rochelle », Document de travail de l’OFCE, n°4-2024.\n\n\nPatrick Bonnel (2001), Prévision de la demande de transport, thèse de doctorat, Lyon, France.\n\n\nPereira, R.H.M., Marcus Saraiva, Daniel Herszenhut, Carlos Kaue Vieira Braga & Matthew Wigginton Conway (2021), « r5r: Rapid Realistic Routing on Multimodal Transport Networks with R5 in R »,. https://doi.org/10.32866/001c.21262\n\n\nRodier, C. (2009), « Review of International Modeling Literature: Transit, Land Use, and Auto Pricing Strategies to Reduce Vehicle Miles Traveled and Greenhouse Gas Emissions », Transportation Research Record, vol. 2132, n°1, pp. 1‑12. https://doi.org/10.3141/2132-01\n\n\nRuiter, E.R. (1967), « Toward a better understanding of the intervening opportunities model », Transportation Research, vol. 1, n°1, pp. 47‑56. https://doi.org/https://doi.org/10.1016/0041-1647(67)90094-9\n\n\nSavini, F., Ferreira, A. & von Schönfeld, K.C. (2022), Post-Growth Planning, Routledge. https://doi.org/10.4324/9781003160984\n\n\nSDES (2023), « Le quart des ménages les plus aisés à l’origine de 35 ».\n\n\nSeto, K.C., Dhakal, S., Bigio, A., Blanco, H., Delgado, G.C., Dewar, D., Huang, L., Inaba, A., Kansal, A., Lwasa, S., McMahon, J., Müller, D.B., Murakami, J., Nagendra, H., Ramaswami, A., Bento, A., Betsill, M., Bulkeley, H., Chavez, A., Christensen, P., Creutzig, F., Fragkias, M., Güneralp, B., Jiang, L., Marcotullio, P., McCollum, D., Millard-Ball, A., Pichler, P., Salat, S., Tacoli, C., Weisz, H., Zwickel, T., Cervero, R. & Martinez, J.T. (2014), « 12 Human Settlements, Infrastructure, and Spatial Planning », in Cambridge, United Kingdom; New York, NY, USA, Cambridge University Press.\n\n\nSimini, F., González, M.C., Maritan, A. & Barabási, A.-L. (2012), « A universal model for mobility and migration patterns », Nature, vol. 484, n°7392, pp. 96‑100. https://doi.org/10.1038/nature10856\n\n\nSimini, F., Maritan, A. & Néda, Z. (2013), « Human Mobility in a Continuum Approach », PLOS ONE, vol. 8, n°3, pp. e60069. https://doi.org/10.1371/journal.pone.0060069\n\n\nStevens, M.R. (2017), « Does Compact Development Make People Drive Less? », Journal of the American Planning Association, vol. 38, n°1, pp. 7‑17.\n\n\nStouffer, S.A. (1940), « Intervening Opportunities: A Theory Relating Mobility and Distance », American Sociological Review, vol. 5, n°6, pp. 845. https://doi.org/10.2307/2084520\n\n\nThurner, S., Klimek, P. & Hanel, R. (2018), Introduction to the Theory of Complex Systems, Oxford University Press. https://doi.org/10.1093/oso/9780198821939.001.0001\n\n\nTukey, J.W. (1977), Exploratory Data Analysis, Addison-Wesley.\n\n\nWilson, A.G. (1967), « A statistical theory of spatial distribution models », Transportation Research, vol. 1, n°3, pp. 253‑269. https://doi.org/10.1016/0041-1647(67)90035-4\n\n\nYang, Y., Herrera, C., Eagle, N. & González, M.C. (2014), « Limits of Predictability in Commuting Flows in the Absence of Data for Calibration », Scientific Reports, vol. 4, n°1, pp. 5662. https://doi.org/10.1038/srep05662"
  },
  {
    "objectID": "larochelle.html",
    "href": "larochelle.html",
    "title": "MEAPS & gravitaire : estimations à La Rochelle",
    "section": "",
    "text": "La confrontation d’un modèle aux données est une étape cruciale pour la compréhension de son fonctionnement et l’appréciation de sa pertinence. Nous explorons ici la capacité du modèle MEAPS à reproduire les flux de mobilités en le comparant au modèle gravitaire. La question est de savoir quel modèle est le mieux à même de reproduire les données observées de flux, à savoir les données MOBPRO tout en introduisant un minimum de paramètres, par souci de parcimonie et de généralité. De plus, cette capacité a expliquer les données doit reposer sur un fondement théorique le plus explicite possible, ce qui est la condition pour pouvoir interpréter les paramètres estimés.\nLa paramétrisation du modèle, le choix du modèle statistique, ou de la métrique à minimiser pour la détermination des paramètres sont autant de points à clarifier qui dépendent de la nature des données dont on dispose, mais aussi de ce qu’on pense être le processus qui les a générées. Cette discussion est cruciale puisqu’elle peut conduire à des estimations très différentes et qu’il faut expliciter ce qui en fait préférer l’une à l’autre. Elle est également importante pour diagnostiquer la qualité de la modélisation révélée par les données que l’on emploi et nourrir à la fois le processus de modélisation, et la compréhension des données.\nLe point de départ est l’estimation d’un modèle gravitaire par les moindres carrés ordinaires (MCO). C’est habituellement ce qui est fait dans la littérature (Josselin et al., 2020 pour la région PACA en France par exemple). Mais cette approche mérite d’être approfondie."
  },
  {
    "objectID": "larochelle.html#spécifications-des-modèles-à-estimer",
    "href": "larochelle.html#spécifications-des-modèles-à-estimer",
    "title": "MEAPS & gravitaire : estimations à La Rochelle",
    "section": "1 Spécifications des modèles à estimer",
    "text": "1 Spécifications des modèles à estimer\nNous proposons d’utiliser l’entropie relative (ou critère d’information ou log vraisemblance d’une distribution multinomiale) comme fonction objectif à minimiser. Une régression par les moindres carrés ordinaires pondérée par les flux (c’est-à-dire la variable expliquée) donne un résultat plus proche de l’entropie relative que l’erreur quadratique moyenne non pondérée. Nous procédons ensuite à des estimations non-linéaires en utilisant principalement l’entropie relative comme fonction objectif (d’autres fonctions objectifs sont présentées pour comparer). Cette approche permet d’estimer des modèles gravitaires à simple contrainte (la constante c de l’équation 1 n’est plus estimée et est remplacée par un vecteur c_i qui assure le respect de la contrainte en ligne1) et à double contrainte (à la fois la contrainte en ligne et en colonne sont respectées en utilisant par exemple la procédure de Furness). En utilisant la même procédure d’estimation non-linéaire avec comme fonction objectif l’entropie relative, nous estimons également MEAPS étendu afin de permettre une paramétrisation.\n1 INfrastructure for SPatial InfoRmation in Europe est depuis 2007 une directive pour la production de données spatialisées. Inspire définit une grille de carroyage et son système de projection harmonisée. C’est ce qui suit l’INSEE dans la diffusion des données carroyées. Voir https://inspire-geoportal.ec.europa.eu pour la définition de la grille et des jeux de données.Nous déclinons enfin ces estimations en utilisant l’information infra-communale pour montrer que cette information peut accroître le pouvoir explicatif des modèles, en particulier de MEAPS. L’intuition est que l’information infra-communale permet une paramétrisation plus fine que sur la base de l’information communale. Bien que la variable expliquée (les flux) soit connue à l’échelle communale, l’injection d’une information infra-communale permet d’augmenter le pouvoir explicatif des modèles utilisés, particulièrement pour MEAPS.\n\n1.1 Le modèle gravitaire standard : erreurs log-normales\nL’estimation de modèle gravitaire est habituellement faite par une régression linéaire Josselin et al. (2020), par les moindres carrés ordinaires. Le modèle suivant est celui estimé, où les flux observés f_{ij} sont la variable expliquée et les emplois e repartis dans J unités spatiales, les actifs n répartis dans I unités spatiales et la matrice de distance2 [d_{ij}] sont les facteurs explicatifs :\n2 Nous avons pour simplifier l’exposition choisi une fonction « distance » particulière, paramétrée par \\delta, appelée fonction puissance avec la forme 1/d^\\delta. Des alternatives sont possibles comme la fonction exponentielle, écrite comme e^{-d/\\delta}, ou tout autre fonction de la distance, éventuellement paramétrée par plus d’un paramètre.\nDifférentes métriques peuvent être utilisées pour analyser les distances. Cela peut être la distance à vol d’oiseau, la distance de parcours par les réseaux routiers ou le temps de parcours – qui permet d’intégrer les transports en commun. On peut également inclure un coût généralisé de transport, qui découle par exemple d’un modèle de choix discret et qui permet de prendre en compte des notions comme les préférences individuelles pour tel ou tel mode de transport (impliquant des vitesses et donc des temps différents) ou le confort ressenti par un mode de transport, que ce soit pendant le voyage ou par la sécurité qu’il procure dans la faible incertitude de sa réalisation. Nous utiliserons pour l’analyse communale la distance euclidienne à vol d’oiseau. Pour les analyses infracommunales, nous utiliserons des distances et des temps de parcours par les réseaux routiers ou de transport en commune suivant différents modes.\nlog(f_{ij}) = \\alpha \\times log(n_i) + \\beta \\times log(e_j) - \\delta \\times d_{ij} + c + \\varepsilon_{ij}\n\\tag{1}\n\n\\varepsilon_{ij} \\sim \\mathcal{N}(0,\\sigma^2)\n\nAinsi écrit le modèle gravitaire ne respecte la propriété d’additivité que si les cœfficients \\alpha et \\beta sont égaux à 1. Lorsque \\alpha est différent de 1, séparer un groupe de n_i en deux sous groupes, pour lesquels les distances sont inchangées, conduit à projeter des flux dont la somme s’écarte du flux que l’on calcule pour les deux sous-groupes réunis. De façon symétrique, \\beta différent de 1 implique la même non additivité lors de la séparation d’un groupe e_j en deux. Or cette propriété d’additivité est nécessaire pour l’utilisation du modèle. Par exemple, la granularité de l’agrégation spatiale ne doit pas trop modifier les flux prévus surtout lorsque cette agrgégation est assez fine pour les distances relatives ne changent pas trop. La séparation des emplois en emplois par secteur, ou des individus suivant des caractéristiques socio-économiques ou suivant leurs préférences est un autre exemple de transformation à laquelle le modèle doit être robuste. Si on sépare les emplois en deux secteurs et que les comportements ne sont pas modifiés le long de cette séparation, il faut que les flux s’additionnent si on suit la cohérence de la modélisation.\nSi l’estimation conduit à \\alpha\\approx\\beta\\approx1, la propriété d’additivité sera (approximativement) respectée. Comme nous le verrons dans les estimations, et comme il ressort généralement de la littérature (par exemple Josselin et al., 2020 pour la région PACA), les estimations, en règle générale, du modèle gravitaire par les MCO (i.e. avec des erreurs log-normales) donnent des \\alpha et des \\beta significativement inférieurs à 1. Le non-respect de cette propriété d’additivité obère la portée du modèle et sa vraisemblance.\n\n\n1.2 Quel processus générateur : gaussien ou poisson ?\nLe modèle gravitaire log-linéaire estimé par les MCO suppose un bruit multiplicatif et un processus générateur dont les erreurs se compensent. Or les flux s’apparentent plus au résultat d’un comptage qu’au processus implicite du modèle MCO. Les flux ne sont donc plus à considérer comme des erreurs qui se compensent autour d’un modèle déterministe mais comme résultant d’une table de contingence et d’évènements independants mais dont on observe l’accumulation.\nPlusieurs représentations sont possibles. Une première approche est de considérer le résultat comme celui d’un tirage avec remise de n boules de différentes couleurs (la dimension i) et placées dans j coupoles aléatoirement. C’est alors une loi multinomiale où chaque cellule de la table a une probabilité \\pi_{ij} et les fréquences sont f_{ij} = n \\times \\pi_{ij} et où n=\\sum f_{ij}.\nUne alternative, très souvent employée en particulier dans les modèles linéaires généralisés, est de considérer la table de contingence comme produite par des processus de Poisson mulitvariés Agresti (2002).\nUne des propriétés qui différencie ces deux grandes catégories de modèles (multinomial et Poisson versus log normal) se trouve au voisinage des valeurs faibles. Intuitivement, un processus de Poisson a pour variance l’espérance de ce processus. Pour un processus log-normal, la variance est une fonction de l’écart-type et de la moyenne du log du bruit et tend vers une valeur strictement postive lorsque la moyenne du log du bruit tend vers 03. Cette propriété implique que les erreurs relatives pour de petites valeurs dans une représentation log normale ont une variance plus importante que celle d’un processus de Poisson4.\n3 Si log(\\varepsilon) \\sim \\mathcal N ( \\mu, \\sigma^2), alors Var(\\varepsilon) = (e^{\\sigma^2}-1)e^{2\\mu+\\sigma^2}.4 De façon plus générale, la famille quasi, dans l’estimation par glm, permet de spécifier un lien entre variance et moyenne et ainsi de définir des comportements au voisinage de 0 non pas constant (log linéaire), en lien avec la moyenne (Poisson) mais en carré de la moyenne (Bernouilli) ou en cube de la moyenne. Plus la dépendance est d’un ordre important, plus la variance tend rapidement vers 0.Une autre façon d’apprécier la différence d’approche entre le modèle log-normal et la table de contingence est à travers la log-vraisemblance. A une constante (indépendante des paramètres à estimer) près la log-vraisemblance pour le modèle log-linéaire est l’erreur quadratique moyenne (msre), en notant \\hat f le flux prédit par le modèle et f l’observation :\n\nmsre = \\sum_i {({log(f}_{ij}) - log(\\hat f_{ij}))^2 }\n\\tag{2}\nPour le processus de Poisson, en gardant les mêmes notations, la probabilité des observations connaissant le modèle est :\n P(\\hat f_{ij}= f_{ij}) = \\frac{e^{-\\hat f_{ij}}\\times \\hat f_{ij}^{f_{ij}}}{f_{ij}!}  \\tag{3}\nLa matrice de paramètres de Poisson [\\hat f_{ij}] peut alors être estimée à partir d’un modèle log-linéaire, qui peut être implémenté facilement par glm. C’est cette approche que Flowerdew & Aitkin (1982) applique à des flux de mobilité. On peut alors écrire le modèle gravitaire simplement :\n log(\\hat f_{ij}) = \\alpha \\times log(n_i) + \\beta \\times log(e_j) - \\delta \\times d_{ij} +c  \\tag{4}\nOn en déduit la log-vraisemblance, en notant n=\\sum f_{ij} et en approximant la factorielle par la formule de Stirling (Agresti, 2002) :\n \\mathcal{L} = -\\hat n + \\sum_{ij}{f_{ij} log(\\hat f_{ij})} - \\sum_{ij}{f_{ij}log(f_{ij})} \\tag{5}\nDans cette expression, lorsque n est connu (et donc \\hat n = n), le processus de Poisson est une loi multinomiale la log-vraisemblance se simplifie par l’élimination de \\hat n. Ainsi, la log-vraisemblance pour un processus multinomial est :\n\n\\mathcal L = \\sum_{ij} f_{ij} log(\\hat f_{ij} /n)\n\\tag{6}\nL’expression de la log vraisemblance est alors (à une constante indépendante des paramètres près) égale au critère de gain d’information ou d’entropie relative (Kullback & Leibler, 1951) :\n I(f_{ij}, \\hat f_{ij}) = \\frac 1 n \\sum_i {f_{ij} \\times (log(\\hat f_{ij}) - log(f_{ij}))}  \\tag{7}\nComme l’avaient noté Flowerdew & Aitkin (1982), les moindres carrés ordinaires reposent sur la minimisation de l’erreur quadratique moyenne, mais les flux de mobilités entre paire de commune ne suivent pas cette distribution (même corrigés par la partie déterministe) et l’estimation est biaisée. Ainsi, quelques paires origine-distribution concentrent la grande majorité des flux alors qu’un grand nombre de paires origine-destination représentent des flux petits et une part cumulée très faible des flux totaux. Dans le cas de la Rochelle et de ses environs, les flux La Rochelle-La Rochelle pèsent presque 20% des flux totaux et les 40 flux les plus importants (sur 2 125) représentent plus de 50% de l’ensemble des flux. L’hypothèse d’un processus générateur multinomial ou Poisson conduit à prendre en compte correctement la possibilité de flux faibles, associés à des paramètres de Poisson petits. Le modèle log-normal donne une trop grande importance aux petits flux, ce qui est d’autant plus problématique que les petits flux sont, de part la nature du problème, très nombreux. Ainsi, la différence entre les métriques (erreur quadratique moyenne versus entropie relative) sera d’autant plus importante que les données que l’on utilise sont très éloignées d’une distribution uniforme ou normale. Cette intuition sera illustrée par la comparaison des écarts observés/prévus des différents modèles que nous aurons estimés. Comme expliqué par (Agresti, 2002, pp. 146‑148), une alternative à l’erreur quadratique moyenne est de procéder à une régression log-linéaire du type équation 1 mais pondérée par les flux (i.e. l’anti log de la variable expliquée). Dans ce cas la fonction objectif à minimiser est :\n msre_w = \\sum_i {  f_{ij} \\times (log(f_{ij}) - log(\\hat f_{ij}))^2 }  \\tag{8}\nNous verrons qu’il existe, outre le carré, une différence entre ce critère et le critère d’entropie relative et qui a trait à la connaissance ou non de la somme totale des flux ou des sommes en ligne ou en colonne. Comme illustré dans la suite pour la Rochelle, le critère pondéré permet des résultats proches de ceux obtenus par glm et Poisson.\n\n\n1.3 Contraintes en ligne et en colonne\nLa différence entre le modèle multinomial et le modèle de Poisson tient à la nature de l’information dont on dispose. Pour le modèle multinomial, le nombre total d’individus est fixé, alors qu’il est aléatoire dans le modèle de Poisson. Lorsqu’on passe, dans le modèle de Poisson, des comptes dans chaque case de la table de contingence aux probabilités, ces probabilités suivent une loi multinomiale. Si on connait non seulement le nombre d’individus, mais aussi les marges de la table de contingence (c’est-dire le nombre d’individus pour chaque ligne, ce qui revient à dire que chaque individu occupe un emploi et le nombre d’emplois pour chaque colonne, ce qui revient à dire que chaque emploi est occupé), alors la distribution sous-jacente est hypergéométrique multivariée5. Elle est malheureusement utilisable que pour des dimensions très faibles, par exemple dans le test exact de Fisher (Agresti, 2002).\n5 $f(f_{ij}La formulation simple du modèle gravitaire n’est contrainte ni en ligne, ni en colonne. L’espérance de la somme \\sum_j \\hat f_{ij} est différente de la \\sum_j {f_{ij}}, généralement inférieure du fait de la convexité de la fonction log. Pour approcher ces contraintes, il faut introduire des paramètres supplémentaires, sous la forme d’effets fixes ou aléatoires. Les I contraintes en ligne (appelées aussi simples contraintes, ou contraintes de production des flux) sont représentées en remplaçant la constante c par un vecteur a_i (de taille I) :\n\n\\begin{aligned}\nlog(f_{ij}) = & \\alpha \\times log(n_i) + \\beta \\times log(e_j) - \\delta \\times log(d_{ij}) \\\\ & + log(a_i) + \\varepsilon_{ij}\n\\end{aligned}\n\\tag{9}\n\n\\varepsilon_{ij} \\sim \\mathcal{N}(0,\\sigma^2)\n\nOn peut également le définir comme respectant explicitement les I contraintes en ligne, et donc en tenant compte de la convexité de la fonction log comme écrit dans l’équation 10. L’estimation en peut plus se faire directement par une régression linéaire, puisque le vecteur a_i dépend à la fois de l’estimation de \\alpha et de celle de \\beta. On peut les estimer par une procédure itérative ou une minimisation non linéaire, dont la fonction objectif pourra être la msre par analogie avec les MCO, l’entropie relative par analogie avec un glm poisson ou la msre_w pour approcher la précédente.\n\na_i = \\frac{n_i}{\\sum_j {\\frac{n_i ^ \\alpha \\times e_j ^ \\beta} { d_{ij}^{\\delta} }}} = \\frac{n_i ^ {1-\\alpha}}{\\sum_j { e_j ^ \\beta / d_{ij}^{\\delta} }}\n\\tag{10}\nQue cela soit par un effet fixe ou aléatoire, dès que l’on introduit le vecteur a_i dans le modèle, il n’est plus possible d’identifier \\alpha et on peut supposer pour \\alpha n’importe quelle valeur, les a_i étant fonction de \\alpha. Le respect de la propriété d’additivité oblige cependant à choisir \\alpha=1. Par l’expression équation 10, le respect des contraintes en ligne induit nécessairement \\alpha=1. En effet, log(a_i) peut s’écrire comme la somme de (1-\\alpha)log(n_i) et d’un autre terme qui ne dépend que de \\beta, e_j, d_{ij} et \\delta. L’equation initiale se réduit alors à un terme en log(n_i). Dans le cas du respect des contraintes en ligne, l’élasticité des flux aux actifs est nécessairement unitaire.\nLe respect des J contraintes en colonne (appelées aussi contraintes d’attraction) est fait de manière similaire, en introduisant un vecteur b_j. Par le même raisonnement, on ne peut plus estimer \\beta et on le fixera à 1, pour respecter la contrainte d’additivité. Le double respect des contraintes en ligne et en colonne peut se faire par la procédure de Furness (Dios Ortúzar & Willumsen, 2011) en définissant a_i et b_j comme suit : \na_i = \\frac{n_i}{\\sum_j {{b_j n_i ^ \\alpha e_j ^ \\beta} / { d_{ij}^{\\delta} }}} = \\frac{n_i ^ {1-\\alpha}}{\\sum_j { b_j e_j ^ \\beta / d_{ij}^{\\delta} }}\n\\tag{11} \nb_j = \\frac{e_j}{\\sum_i { {a_i n_i ^ \\alpha e_j ^ \\beta} / { d_{ij}^{\\delta} }}} = \\frac{e_j ^ {1-\\beta}}{\\sum_i {a_i n_i ^ \\alpha / d_{ij}^{\\delta} }}\n\\tag{12}\nCe dernier modèle, par Furness, peut être estimé par un optimisation non linéaire sans grande difficulté, la procédure de Furness convergeant rapidement. En notant \\hat a_i = a_i/n_i^{1-\\alpha} et \\hat b_j= b_j/e_j^{1-\\beta} on a :\n\n\\hat a_i = \\frac{1}{\\sum_j { \\hat b_j e_j/ d_{ij}^{\\delta} }}\n\\tag{13}\n\n\\hat b_j = \\frac{1}{\\sum_i { \\hat a_i n_i/ d_{ij}^{\\delta} }}\n\\tag{14}\nCes deux dernières équations montrent que dans le cas de la double contrainte, les paramètres \\alpha et \\beta disparaissent et le modèle gravitaire se résume à l’équation suivante :\n\nlog(f_{ij}) = log(n_i) + log(e_j) - \\delta \\times d_{ij} + log(\\hat a_i) + log(\\hat b_j) + \\varepsilon_{ij}\n\\tag{15}\nL’élasticité de chaque flux f_{ij} aux emplois ou aux résidents est nécessairement unitaire. Cette propriété introduit une différence subtile avec la formulation en effets fixes ou aléatoires dans laquelle les paramètres \\alpha et \\beta peuvent être fixés à n’importe quelle valeur, les a_i et b_j s’ajustant en fonction. Ceci signifie que dans la formulation effets fixes/aléatoires, le modèle est agnostique quant à la valeur des dérivées à l’augmentation de la masse « actif » ou de la masse « emploi ». L’estimation de \\delta est faite en déterminant pour chaque valeur de \\delta les flux, auxquels on applique Furness, et donc en calculant les a_i(\\delta) et b_j(\\delta). On calcule alors la fonction objectif \\mathcal{L} pour ces flux (\\mathcal{L} étant l’erreur quadratique moyenne ou les autres fonctions objectif) :\n\n\\hat \\delta = \\underset{\\delta}{\\mathrm{argmax}} \\, \\mathcal{L}(f_{ij}(\\delta))  \n\\tag{16}\nQue l’on considère le modèle contraint par Furness ou le modèle augmenté d’effets fixes ou aléatoires, on est face à une difficulté d’interprétation. Indépendamment de leur mode de calcul, les cœfficients a_i et b_j agissent comme des modificateurs des masses à l’origine ou à la destination. La partie déterministe du modèle gravitaire peu s’écrire comme l’équation 17 qui fait apparaître à quoi correspondent ces deux cœfficients. Pour fonctionner le modèle gravitaire demande de « tricher » sur les masses, ce qui l’écarte de l’interprétation « gravitaire ».\n\n\\hat f_{ij} = f_0\\frac{(a_i n_i)\\times (b_j e_j)}{d_{ij}^\\delta}\n\\tag{17}\nLa solution et l’interprétation proposées par Fotheringham (1983) sont plus intéressantes. Son point est de noter qu’il manque une variable au modèle gravitaire, décrivant le voisinage ou l’environnement de chaque leiu d’intérêt. Suivant son interprétation, les concentrations (des emplois réunis près les uns des autres) pourraient accroître l’attractivité, s’il y a un effet d’agglomération ou au contraire la diminuer s’il y a un effet de congestion ou de recherche de la solitude. Cependant, son approche ne résout pas la questions des contraintes en ligne et en colonne et fait simplement le pari que le problème sera moindre, une fois tenu compte de la concurrence entre opportunité.\n\n\n\n\n\n\nEncadré 1. Déviance et entropie relative de Kullback-Leibler\n\n\n\n\n\nLa déviance est permet de définir la qualité d’ajustement d’un modèle M en généralisant la somme des erreurs au carré. Elle consiste à soustraire à la log vraisemblance du modèle saturé (i.e. avec autant de paramètres que d’observations) la log vraisemblance du modèle estimé, où y sont les observations et \\hat y_M sont les prédictions à partir du modèle M :\n\nD(y, \\hat y_M) = 2(log(P(y|M_{saturé}) - log(P(y|M))\n\nLa déviance n’est pas une distance, parce qu’elle n’est pas symétrique et qu’elle ne vérifie pas l’inégalité triangulaire.\nOn peut normer cette déviance en utilisant le modèle dit nul, c’est à dire avec un seul paramètre pour la constante. On a alors :\n\nR^2_{dev} = 1 - D(y, \\hat y_M)/D(y, \\hat y _{null})\n\nPour un modèle linéaire, la déviance est la somme des erreurs au carré ( \\sum(y-\\hat y)^2) ), et R^2_{dev} = R^2, ce qui justifie la notation.\nDans le cas de distributions ( \\sum p = 1, \\sum q=1 ), on peut définir un critère proche à partir de l’entropie relative de Kullback-Leibler (Kullback & Leibler, 1951). L’entropie relative est définie pour deux distributions de probabilités p et q comme suit dans le cas discret :\n\nKL(p,q) = \\sum_{i}p_i \\times log(p_i/q_i)\n\nElle s’interprète dans le cadre de la théorie de l’information comme la quantité relative d’information supplémentaire nécessaire pour exprimer q à partir de p. En suivant Colin Cameron & Windmeijer (1997) on peut construire une mesure de la qualité de l’ajustement R_{KL}^2 de la façon suivante, où \\hat{q} et q_0 sont deux distributions, respectivement celles estimée et de référence, que l’on compare à p :\n\nR_{KL}^2 = 1 - \\frac{KL(p,\\hat{q})}{KL(p, q_0)}\n\nSi la distribution de référence est choisie comme une distribution uniforme, par analogie avec le calcul de la variance dans un R^2 habituel où l’on régresse sur une constante. On écrit :\n\n\\begin{aligned}\nKL_u(p,q_{ref}) &{}= \\sum_{i}p_i \\times log(p_i/unif) \\\\&{}= \\sum_i p_i \\times log(p_i) - log(N)\n\\end{aligned}\n\nCeci n’est autre que l’entropie de la distribution p à une constante près (N est le nombre total de résidents actifs ou d’emplois). Le cœfficient d’ajustement ainsi défini peut avoir pour des distributions très particulières des valeurs négatives ou supérieures à 1.\nSi on connait les marges de la table de contingence (nombre d’actifs dans les origines i et nombre d’emplois dans les destinations j), on peut utiliser comme référence non pas la distribution uniforme mais une distribution indépendante.\n\nKL_i(p,q_{ref}) = \\sum_{ij}p_{ij} \\times [log(p_{ij}) -log( \\frac{n_i \\times e_j}{N^2})]\n\nOn construit à partir de ces deux références R^2_{KLu} et R^2_{KLi}. Les 2 R^2_{KL} ne nécessitent pas de connaître la vraisemblance et donc le modèle sous-jacent. Ils coïncident avec la déviance lorsque le modèle est une distribution multinomiale.\n\n\n\n\n\n1.4 Extension de MEAPS avec des odds-ratios\nPour permettre une spécification plus fine, c’est-à-dire en ajoutant des paramètres, de MEAPS, nous introduisons pour chaque paire (i, j) un paramètre qui modifie la probabilité d’absorption de l’individu i par l’emploi j. On définit c_{abs} comme la chance d’absorption, définie comme c_{abs} = p_{abs}/(1-p_{abs}) . Dans le MEAPS de référence, présenté plus haut, cette chance d’absorption est identique pour tous les emplois considérés par un individu et elle ne dépend que de la probabilité de fuite. Un moyen simple d’injecter de l’information dans le modèle consiste alors à modifier cette chance d’absorption selon les individus et les emplois qu’ils considèrent. Les modifications des probabilités d’absorption peuvent alors être paramétrées par des odds-ratios (des ratios de chances relatives) \\omicron_{ij} de telle manière que la nouvelle chance d’absorption de i en j soit égale à \\tilde{c}_{abs,ij} = \\omicron_{ij} \\times c_{abs}. L’odds-ratio \\omicron_{ij} est un paramètre entre 0 et +\\infty et i et j indexent les communes de départ et d’arrivée. La nouvelle probabilité d’absorption s’écrit alors à partir de la chance d’absorption de référence et de l’odds-ratio comme suit :\n \\tilde{p}_{abs,ij} = \\frac{c_{abs} \\times \\omicron_{ij}} {1+c_{abs} \\times \\omicron_{ij}}  \nUne première stratégie de calage de MEAPS consiste à calculer autant d’odds-ratios qu’il y a de paires communes résidentes - communes d’emplois de manière à reproduire le plus fidèlement possible les flux agrégés de MOBPRO (2022). Cette méthode conduit à saturer le modèle puisque l’on estime un nombre de paramètres proche ou égal au nombre de degrés de liberté imposé par MOBPRO (2022). Cette stratégie d’apprentissage est analogue à ce qui se fait en machine learning du fait de la démultiplication du nombre de paramètres à estimer. La limite de cette approche est le sur-ajustement (overfitting) qu’elle induit. Celle-ci est habituellement corrigée en ajoutant une pénalité à la complexité du modèle au sein de la fonction d’optimisation. Cela peut également se faire par pruning, en éliminant a posteriori les paramètres dont la contribution à l’explication des données est inférieure à un seuil.\nLes paramètres issues de cette approche contiennent une information qui peut ensuite être exploitée. Les odds-ratios s’interprètent alors relativement simplement : ceux qui sont supérieurs à 1 indiquent que le flux de mobilités professionnelles correspondant sont plus fréquents que ce que prévoit le modèle de référence ; et inversement pour les odds-ratios inférieurs à 1.\nUne seconde stratégie est une estimation non linéaire. On choisit une structure pour les odds-ratios, en les paramétrisant par une des données disponibles (par exemple \\omicron_{ij)} = O(d_{ij}), la fonction O étant paramétrisée par un ou plusieurs paramètres \\theta. En définissant une fonction objectif (par exemple, l’entropie relative de Kullback Leibler), on peut estimer \\theta :\n\n\\hat \\theta = \\underset{\\theta}{\\mathrm{argmin}} \\, \\mathcal{L}(f^{meaps}_{ij}(O(d_{ij},\\theta)))"
  },
  {
    "objectID": "larochelle.html#données-au-niveau-communal",
    "href": "larochelle.html#données-au-niveau-communal",
    "title": "MEAPS & gravitaire : estimations à La Rochelle",
    "section": "2 Données au niveau communal",
    "text": "2 Données au niveau communal\n\n2.1 Mobilités professionnelles\nLa donnée principale que nous utilisons est issue du fichier détail du recensement. Nous partons de données individuelles, avec une information de localisation à la commune/arrondissement pour la résidence et l’emploi. Les données que nous employons sont issues du fichier détail des mobilités professionnelles de 20206 accessible sur le site de l’INSEE. Nous sélectionnons les individus appartenant à notre territoire d’intérêt : le SCoT de la Rochelle-Aunis pour l’estimation, une sélection d’autres SCoT pour le test, comme illustré sur la graphique 1.\n6 2020 a été marquée par le COVID. Outre les difficultés à suivre le plan de sondage, on peut estimer que l’analyse des flux de mobilité n’est pas perturbée au premier ordre. En effet, le recensement s’attache à identifier le lieu habituel de travail et de résidence. Les confinements ont probablement limité les changements d’emplois, mais le report d’une partie des relevés de terrain peut en partie compenser cet effet de fixation des emplois.\n\n\n\n\nGraphique 1. carte des SCoT\n\n\n\n\n\n\n\n\nLe tableau 1 donne quelques statistiques descriptives pour les différents échantillons. La colonne QQ plot indique en particulier que les log des flux ne sont pas normalement distribués avec une masse importante en fin de distribution, ce qui est comptatible avec une distribution de Poisson des flux.\n\n\n\nTableau 1. Description des échantillons d’estimation et de test\n\n\n\n\n\n\n\n\n\n\n\n\nNombre\ndistances (km)\nfij\nlog10(fij)\nQQ plot de log10(fij)\n\n\nactifs\nflux\norigines\ndestinations\nmoyenne1\nécart type1\nmoyenne\nécart type\npart 1%\nmoyenne\nécart type\n\n\n\n\nLa Rochelle-Aunis\n86k\n2195\n72\n261\n11.6\n11.9\n39.3\n203\n33%\n1.11\n0.499\n\n\n\nMétropole Aix-Marseille\n699k\n9775\n107\n1310\n17.6\n66.9\n71.5\n601\n48%\n1.00\n0.670\n\n\n\nPays Basque et Seignanx\n132k\n4015\n166\n729\n21.5\n84.6\n32.8\n240\n45%\n0.923\n0.510\n\n\n\nNiortais\n50k\n1286\n40\n404\n15.0\n45.0\n38.7\n489\n53%\n0.922\n0.494\n\n\n\nCaro (Rochefort)\n23k\n793\n25\n259\n20.5\n63.9\n29.3\n192\n41%\n0.939\n0.471\n\n\n\nQuimperlé\n21k\n692\n16\n210\n21.0\n62.7\n30.6\n104\n26%\n1.03\n0.510\n\n\n\nPays des Olonnes\n17k\n326\n5\n227\n19.0\n71.0\n52.7\n537\n66%\n0.788\n0.589\n\n\n\n\n1 pondéré par les flux\n\n\n\n\n\n\n\n\n\n\n\n\nAfin de produire des intervalles de confiance, nous rééchantillonons les données d’estimation (bootstrap). Nous utilisons le fichier détail du recensement, en tirant avec remise les individus du territoire concerné, avec comme probabilité leur poids dans l’échantillon divisé par la somme des poids. Pour les individus ayant des poids proche de 5, lié au plan de sondage du recensement pour les communes de moins de 10 000 habitants, nous les décomposons en 5 individus de poids divisé par 5. Cela permet d’éviter des accumulations autour des multiples de 5 dans la distribution ré-échantillonnée.\nChaque échantillon « boostrapé » a le même nombre d’individus, avec la même distribution, et des individus peuvent être répétés, conformément au principe du boostrap (tirages avec remise).\nNous associons ensuite à chaque paire commune d’origine commune de destination une distance à vol d’oiseau euclidienne entre les centroïdes des communes. Pour les mouvements de la même commune vers la même commune, nous définissons la distance comme la moitié de la racine carrée de la surface. Ceci est une approximation de la valeur moyenne de la distance pour des points répartis aléatoirement sur un cercle de même surface. Dans la partie infra-communale, cette approximation est explicitement levée en localisant au carreau 200m résidents et emplois et en calculant les distances entre toutes les paires origine et destination. Toutes les distances sont exprimées en kilomètres.\nLe fichier détail du recensement contient beaucoup de 0 implicites, c’est-à-dire des paires de communes pour lesquelles il n’y a aucun flux. Lorsque les communes sont très distantes, cela se comprend facilement. Mais lorsque l’on analyse un territoire (comme le SCoT de La Rochelle-Aunis), il existe des flux entre communes dont la distance est plus grande que d’autres qui ne sont pas reliées par un flux. Nous avons choisit de traiter comme 0 structurel ces absences de flux, même si l’hypothèse alternative qui voudrait modéliser ces flux presque nuls peut être défendue."
  },
  {
    "objectID": "larochelle.html#sec-ajustcom",
    "href": "larochelle.html#sec-ajustcom",
    "title": "MEAPS & gravitaire : estimations à La Rochelle",
    "section": "3 Ajustements « communaux » de modèles gravitaires et de MEAPS",
    "text": "3 Ajustements « communaux » de modèles gravitaires et de MEAPS\n\n3.1 Modèles gravitaires par MCO ou glm\nLe tableau 2 donne les résultats d’estimations de différents modèles gravitaires non contraints (i.e \\alpha et \\beta sont estimés), contraints (i.e \\alpha=1 et \\beta=1), non pondérés (métrique standard) ou pondérés par les flux en niveau, estimés par glm avec les familles Poisson ou quasi Poisson, avec effets fixes ou aléatoire ou sans. la forme estimée est l’équation 1 ou l’équation 4, en ajoutant les cœfficients a_i et fb_j lorsque des effets fixes ou aléatoires sont ajoutés. Les régressions sont effectuées soit par stat::lm, soit par stat::glm dans R, soit par le package R lme4 pour les effets fixes ou aléatoires. Le tableau présente différentes métriques (voir encadré 1 pour les définitions), ainsi que les degrés de liberté des résidus associés à chaque régression.\nDans l’ensemble des régressions, les paramètres estimés sont largement significatifs. La régression par les MCO non contrainte (ligne 1 du tableau 2) fait apparaître des cœfficients \\alpha et \\beta inférieurs à 1, marquant une franche non additivité. Contraindre ces 2 paramètres dégrade fortement la qualité de l’estimation (ligne 2), sans pour autant modifier le cœfficient associé à la distance. Josselin et al. (2020) estiment pour la région PACA des régressions proches de celle de la ligne 1, avec des R^2 comparables à ceux pour le périmètre de La Rochelle. Le cœfficient de la distance qu’ils estiment est entre 0.9 et 1.4, soit nettement au-dessus de celui estimé pour La Rochelle. Ceci suggère que ce cœfficient incorpore plus d’information que le simple effet de la distance et résume en partie l’information géographique qui n’est introduite dans cette régression par aucune variable.\n\n\n\n\nTableau 2. Estimations communales, modèles gravitaires\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModèle\nParamètres\nMétriques\n\n\nméthode\np\nDL\nδ1\nα1\nβ1\nR2KLu2\nR2KLi3\nR2dev4\n\n\n\n\n1\nGravitaire5\nmco\n4\n2003\n0.478***(0.0099)(0.023)\n0.297***(0.014)(0.02)\n0.399***(0.0035)(0.01)\n62.3%\n−42.9%\n44.6%\n\n\n2\nGravitaire (contraint)6\nmco\n2\n2005\n0.5***(0.011)(0.041)\n1(cont.)\n1(cont.)\n79.0%\n20.5%\n6.3%\n\n\n3\nGravitaire (FE)7\nmco\n255\n1752\n0.974***(0.015)(0.025)\n1(cont.)\n1(cont.)\n88.7%\n57.1%\n79.0%\n\n\n4\nGravitaire (pondéré)5,8\nmco\n4\n2003\n0.933***(0.0051)(0.019)\n0.688***(0.012)(0.02)\n0.638***(0.0022)(0.0091)\n86.0%\n46.8%\n91.3%\n\n\n5\nGravitaire (pondéré contraint)6,8\nmco\n2\n2005\n0.647***(0.013)(0.028)\n1(cont.)\n1(cont.)\n79.0%\n20.3%\n20.0%\n\n\n6\nGravitaire (pondéré, FE)7,8\nmco\n255\n1752\n1.32***(0.0078)(0.018)\n1(cont.)\n1(cont.)\n94.1%\n77.6%\n89.4%\n\n\n7\nGravitaire (poisson)5\nglm poisson\n4\n2003\n0.93***(0.0054)(0.0046)\n0.688***(0.014)(0.0042)\n0.761***(0.0014)(0.0021)\n87.1%\n51.2%\n87.1%\n\n\n8\nGravitaire (poisson contraint)6\nglm poisson\n2\n2005\n0.558***(0.0095)(0.0042)\n1(cont.)\n1(cont.)\n79.1%\n20.7%\n20.4%\n\n\n9\nGravitaire (poisson, FE)7\nglm poisson\n255\n1752\n1.36***(0.0081)(0.0062)\n1(cont.)\n1(cont.)\n94.5%\n79.4%\n79.3%\n\n\n\n1 estimation du cœfficient, entre paranthèse et en italique, erreur standard, entre paranthèse erreur standard calculée par boostrap (128 rééchantillonages avec remise)\n\n\n2 Entropie relative de Kullback Leibler, normalisé par une distribution uniforme (voir encadré)\n\n\n3 Entropie relative de Kullback Leibler, normalisé par une distribution indépendante (voir encadré\n\n\n4 % de la déviance expliquée (voir encadré)\n\n\n5 log(fij)=αxlog(nij)+βxlog(eij)-δxlog(dij)\n\n\n6 log(fij)=1xlog(nij)+1xlog(empij)-δxlog(dij)\n\n\n7 log(fij)=αxlog(actij)+βxlog(eij)-δxlog(dij)+ai+bj\n\n\n8 Régression pondérée par les flux\n\n\n\n\n\n\n\n\n\n\n\n\nComme évoqué plus haut, un des aspects problématique des régression par MCO sont le traitement des flux importants. Cet aspect est illustré par le graphique 2 où sont représentés les flux observés versus les flux estimés. Les régressions par MCO peinent à estimer le flux le plus important (de la commune de La Rochelle vers La Rochelle). En utilisant la méthode des modèles linéaires généralisés (glm) avec des processus de Poisson résout cette question. La régression de la ligne 7 du tableau 2 illustre ce point. Les graphiques observés versus estimés permettent une appréciation graphique de l’amélioration de l’ajustement. Le biais pour les flux importants est plus faible, la dispersion générale également.\nLes cœfficients \\alpha et \\beta sont plus proches de 1, mais pour autant, la propriété d’additivité n’est pas respectée comme l’illustre la régression contrainte de la ligne 8, pour laquelle la qualité d’ajustement est plus faible. Des estimations par des modèles « quasiPoisson », afin de prendre en compte une éventuelle sur-dispersion par rapport au modèle de Poisson produisent des résultats identiques à ceux par le modèle de Poisson.\nLes régressions pondérées par les flux (lignes 4 à 6), dont la fonction objectif est proche du critère de gain d’information ou d’entropie relative, conduisent à des estimations très proches des modèles de des cœfficients \\alpha et \\beta plus élevés. Ils restent néanmoins inférieurs à 1 et lorsqu’ils sont contraints à 1 (ligne 5), l’ajustement, tel que mesuré par le R^2_{dev}, se dégrade nettement. Le cœfficient estimé pour la distance dépend assez largement de cette hypothèse, sauf pour l’estimation par les MCO.\n\n\n\n\n\nGraphique 2. Modèles gravitaires, Observés versus estimés\n\n\n\n\n\n\n\n\nEn ajoutant des effets fixes ou aléatoires7 pour chaque origine et chaque destination (lignes 6 et 9), et donc un nombre important de paramètres, on améliore la qualité de l’estimation et on force le respect de la propriété d’additivité en fixant les cœfficients \\alpha et \\beta à 1. Le cœfficient de la distance (lignes 3, 6 et 9) est plus élevé et significativement différent de ceux estimés sans effet fixe (autour de 1.3 au lieu d’autour de 1 dans les régressions non contraintes (lignes 1, 4 ou 7)). Comme noté plus haut, si les effets fixes améliorent la qualité de l’estimation, c’est au détriment de l’esprit initial du modèle gravitaire, puisque les effets fixes estimés viennent modifier les masses (actifs et emplois) dans chaque commune pour en assurer l’ajustement. L’utilisation d’effets fixes empêche par ailleurs l’estimation des cœfficients \\alpha et \\beta et oblige à fixer a priori des valeurs. Ainsi, il ets possible d’estimer un modèle à effets fixes avec \\alpha et \\beta nuls, c’est-à-dire neutralisant l’effet des masses d’origine ou de destination et ne faisant dépendre les flux que des distances entre communes.\n7 Seuls les résultats des régressions à effet fixe (communes d’origine et communes de destination) sont reportés dans les tableaux ou des graphiques, les effets aléatoires donnent des résultats très proches. En revanche, pour les prédictions hors échantillon (out of the bag), nous utilisons les régressions à effets aléatoires, les effets fixes n’étant pas connus hors échantillon.Dans le tableau 2, les écarts type des cœfficients estimés sont reportés. Ils sont calculés de deux façons. La première ligne (en italique) est l’écart standard déduit du modèle. Par exemple, pour la ligne 1, il s’agit de l’écart standard pour chaque cœfficient pour les MCO, c’est-à-dire en considérant que les résidus sont normaux. En dessous, l’écart type estimé par rééchantillonage (boostrap) est calculé directement sur l’échantillon des cœfficients estimés sur les observations rééchantillonées. Pour les estimations par MCO, ces deux écarts type diffèrent fortement, ce qui remet en cause l’hypothèse de normalité des résidus et le modèle choisi. En revanche, pour les modèles estimés par glm et avec un processus générateur suivant une distribution de Poisson, on a bien proximité des écarts type par les deux méthodes.\nLe tableau 3 présente les biais d’agrégation pour chacun des modèles estimés. Le biais d’agrégation du modèle gravitaire provient de ce que e^{E(log(\\hat f_{ij}))} \\neq E(\\hat f_{ij}) \\neq E(f_{ij}). Or le modèle gravitaire, dans sa forme log-linéaire, ne garantit que l’égalité des espérance des log. Il s’en suit, du fait de la convexité de la fonction log, un biais. La colonne « biais total » illustre l’ampleur de l’écart entre la somme des flux prédits et la somme des flux observés. Cet écart dépasse 60% pour le modèle gravitaire simple et 150% pour le modèle contraint. La pondération par les flux dans les régressions réduit le problème, mais seul la formulation en glm avec un processus de Poisson ramène ce biais à 0. En effet, par cette modélisation E(\\hat f_{ij}) = \\hat f_{ij} ce qui assure la bonne agrégation des flux prédits.\n\n\n\n\nTableau 3. Modèles gravitaires, biais agrégé total, en ligne ou en colonne\n\n\n\n\n\n\n\n\n\n\n\n\nR2dev\nNo\nNe\n|No-Ne|/No\nLigne1\ncolonne2\n\n\nsse/No\nsse(1%)/No3\nsse/No\nsse(1%)/No3\n\n\n\n\n1\nGravitaire\n45%\n84 953\n31 778\n63%\n40%\n26%\n40%\n40%\n\n\n2\nGravitaire (contraint)\n6%\n84 953\n214 622\n153%\n100%\n74%\n100%\n99%\n\n\n3\nGravitaire (FE)\n79%\n84 953\n51 271\n40%\n22%\n20%\n22%\n22%\n\n\n4\nGravitaire (pondéré)\n91%\n84 953\n114 610\n35%\n13%\n3%\n13%\n8%\n\n\n5\nGravitaire (pondéré contraint)\n20%\n84 953\n133 313\n57%\n47%\n40%\n47%\n46%\n\n\n6\nGravitaire (pondéré, FE)\n89%\n84 953\n96 414\n13%\n2%\n2%\n2%\n1%\n\n\n7\nGravitaire (poisson)\n87%\n84 953\n84 968\n0%\n9%\n3%\n9%\n7%\n\n\n8\nGravitaire (poisson contraint)\n20%\n84 953\n84 968\n0%\n13%\n13%\n13%\n12%\n\n\n9\nGravitaire (poisson, FE)\n79%\n84 953\n84 968\n0%\n0%\n0%\n0%\n0%\n\n\n\n1 Le biais agrégé en ligne est (Σi(Σjfo-Σjfe)2)/No\n\n\n2 Le biais agrégé en colonne est (Σj(Σifo-Σife)2)/No\n\n\n3 Biais agrégé pour les 1% plus grands flux observés relatif à No\n\n\n\n\n\n\n\n\n\n\n\n\nDe la même façon qu’on analyse le biais agrégé total, on peut analyser ce qu’il se passe en ligne ou en colonne. En agrégeant pour chaque commune de résidence les flux prédits partants, on obtient une quantité que l’on peut comparer le nombre d’actifs observés. La mesure proposée est de ramener la somme des écarts pour chaque ligne au carré rapportée au nombre total d’actifs. On procède de même en colonne. Les modèles contraints impliquent un biais agrégé en colonne comme en ligne important, en lien avec le biais agrégé total. L’utilisation d’effets fixes réduit les biais d’agrégation très proche de 0, au total, en ligne et en colonne, comme attendu.\n\n\n3.2 Estimations non linéaires\nL’approche non linéaire permet d’estimer les paramètres de modèles plus complexes que ceux dont la formulation est linéaire. Dans les estimations non linéaires on cherche les paramètres qui minimisent une fonction objectif qui sera soit la somme pondéré des écarts entre les flux observés et les flux prédits équation 8, soit l’entropie relative de Kullback Leibler équation 6.\nPar cette approche, on estime deux types de modèles gravitaires : un modèle contraint en ligne et un modèle doublement contraint en ligne et en colonne, spécifiés en suivant équation 15. Pour chaque valeur \\delta du paramètre de la distance, on calcule par itération les \\hat a_i ou les \\hat a_i et \\hat b_j.\nPour MEAPS, on définit une structure des odds-ratios, par exemple o_{ij} = O(d_{ij}), et pour chaque valeur des paramètres, on calcule les flux par l’algorithme MEAPS. On cherche alors les paramètres qui minimisent l’entropie relative.\nQue ce soit pour les modèles gravitaires ou MEAPS, les estimations sont répétées sur les observations rééchantillonées afin de pouvoir calculer une distribution de l’ensemble des statistiques et cœfficients déterminés à chaque étape. Ceci permet ainsi de calculer des écarts type pour les cœfficients estimés.\nLes résultats de ces estimations pour les modèles gravitaires sont reportés dans le tableau 4 et dans le tableau 5 pour les différentes structures d’odds-ratios de MEAPS. La structure de ces tableaux est légèrement différente de ceux reportant les résultats par MCO ou glm, puisque, par exemple, on ne peut pas calculer la part de la déviance expliquée.\n\n\n\n\nTableau 4. Estimations non linéaires commune à commune, modèles gravitaires\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModèle\nParamètres\nMétriques\n\n\nobjectif\np\nDL\nδ\nα\nβ\nR2KLu\nR2KLi\n\n\n\n\n1\nGrav. (ligne)1\nKL\n3\n1932\n1.16***(0.0062)\n1(cont.)\n0.784***(0.0023)\n90.0%\n62.1%\n\n\n2\nGrav. (ligne)1\nR2w\n3\n1932\n1.05***(0.0054)\n1(cont.)\n0.685***(0.0021)\n89.2%\n59.2%\n\n\n3\nGrav. (furness, l&c)2\nKL\n1\n1752\n1.36***(0.0072)\n1(cont.)\n1(cont.)\n94.5%\n79.3%\n\n\n4\nGrav. (furness, l&c)2\nR2w\n1\n1752\n1.34***(0.0064)\n1(cont.)\n1(cont.)\n94.5%\n79.3%\n\n\n\n1 log(fij)=αxlog(nij)+βxlog(eij)-δxlog(dij)+ai ; simple contrainte (en ligne)\n\n\n2 log(fij)=αxlog(nij)+βxlog(eij)-δxlog(dij)+ai+bj ; double contrainte (lignes et colonnes)\n\n\n\n\n\n\n\n\n\n\n\n\nL’utilisation de la métrique entropie relative de Kullback Leibler (KL) ou les erreurs au carré pondérées donnent des estimations proches. Le modèle gravitaire avec Furness donne les meilleurs résultats d’estimation et conduit à un paramètre de distance très proche de celui obtenu pour le modèle gravitaire à effet fixe estimé par glm et un processus de Poisson. Une nuance importante est que les \\hat a_i et \\hat b_j sont déterminés à partir des observations du nombre d’actifs et d’emploi par commune et donc peuvent être projetés hors échantillon, dès lors qu’on observe ces marges.\nLes estimations de MEAPS sont uniquement réalisées à partir de la métrique KL. A titre de référence, les flux issus d’un MEAPS sans paramètre, et donc calibré uniquement à partir des marges en ligne et en colonne. La capacité prédictive de ce modèle (ligne 1) est moins bonne que des modèles à paramètre (lignes 2 à 5), mais du même ordre de grandeur que les modèles gravitaires sans effet fixe ou aléatoire tableau 2. Une différence importante avec ces modèles est que à la fois la propriété d’additivité et l’absence de biais d’agrégation (total, en ligne et en colonne) sont assurés par construction de MEAPS.\nDifférentes formes fonctionnelles sont envisagées :\nLigne 2 : un paramètre pour tous les termes diagonaux, c’est-à-dire les flux allant d’une commune de résidence vers cette même commune pour l’emploi. Formellement, \\omicron_{i \\neq j}=1 et \\omicron_{ii} = o. Le paramètre estimé est de 1.06 avec une erreur standard de 0.05.\nLigne 3 : Un paramètre pour toutes les flux de commune à même commune (diagonales) dont la densité est supérieure à un seuil et 1 partout ailleurs. Cette forme comprend donc deux paramètres et le seuil estimé est que l’odds-ratio spécifique est supérieur à 1 (1.17) pour un peu plus de 35% de la population (le seuil s’applique aux communes classées par densité croissante qui comptabilisent plus de 65% avec une erreur standard de 4 points. L’odds-ratio estimé est ainsi supérieur à celui du modèle de la ligne 2.\nLigne 4 : Un paramètre pour la diagonale d’une part et les communes limitrophes de la diagonale d’autre part (soit 2 paramètres). Formellement, \\omicron_{ii} = o_d; \\omicron_{ij\\in \\mathcal{V}(i)} = o_v et \\omicron_{i, j \\neq i, j \\notin \\mathcal{V}(i)} = 1. Cette spécification n’ajoute pas beaucoup à la ligne 1.\nLignes 5 et 6 : dans ces deux spécifications, les odds-ratios dépendent de la distance entre la commune d’origine et celle de destination, ce qui permet de combiner MEAPS, où c’est le rang pour chaque individu qui différencie les opportunités et une approche à partir de la distance. Ces spécifications ont deux paramètres et la dépendance à la distance est soit linéaire (ligne 6) soit exponentielle (ligne 5). Ces deux spécifications produisent les meilleurs ajustements.\n\n\n\n\nTableau 5. Estimations non linéaires commune à commune, MEAPS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModèle\nParamètres\nMétriques\n\n\nobjectif\np\nDL\np1\np2\nR2KLu\nR2KLi\n\n\n\n\n1\nMEAPS 0p.1\n-\n0\n1753\n-\n-\n82.0%\n51.6%\n\n\n2\nMEAPS (diag)2\nKL\n1\n1752\n1.06***(0.053)\n-\n88.4%\n56.0%\n\n\n3\nMEAPS (diag&densité)3\nKL\n2\n1751\n1.17***(0.066)\n0.649***(0.043)\n88.4%\n56.0%\n\n\n4\nMEAPS (diag&voisin)4\nKL\n2\n1751\n1.06***(0.052)\n0.962***(0.057)\n88.4%\n56.0%\n\n\n5\nMEAPS (exp. decay)5\nKL\n2\n1751\n3.37***(0.077)\n0.0567***(0.0021)\n91.4%\n67.4%\n\n\n6\nMEAPS (lin. decay)6\nKL\n2\n1751\n14***(0.33)\n2.75***(0.0054)\n91.9%\n69.4%\n\n\n\n1 oij=1\n\n\n2 oii=p1 ; oij=1\n\n\n3 oii= [q(dens)&gt;p2] p1 ; [q(dens)&lt;p2] 1\n\n\n4 oii=p1 ; oiv(i)=p2 ; oij=1\n\n\n5 oij=1/dijp1 + p2\n\n\n6 oij= [dij&gt;p2] 1 ; [dij&lt;p2] p~1 - (p1-1)/p2 dij\n\n\n\n\n\n\n\n\n\n\n\n\nL’examen des graphiques observés estimés confirme ce que les métriques indiquent graphique 3. Il est à noter, qu’à part le modèle gravitaire contraint en ligne seulement, chacun des modèles estimé par la procédure non linéaire conduit à une prédiction proche de l’observé pour les plus grands flux. La différenciation se fait ensuite sur la capacité en prendre en compte les flux inférieurs à 1 000.\nRappelons que le modèle gravitaire modifié par Furness s’il possède une bonne capacité prédictive (voir également la performance hors échantillon, c’est au détriment de la portée explicative de ce modèle. MEAPS présente l’immense avantage de comprendre la mécanique à l’œuvre, celle qui conduit à ce que les contraintes soient respectées en ligne comme en colonne.\n\n\n\n\n\nGraphique 3. Estimations non linéaires, Observés versus estimés\n\n\n\n\n\n\n\n\n\n\n3.3 Performance hors échantillon\nLe test de modèles prédictifs hors échantillon est une discipline forte qui révèle de nombreuses propriétés des modèles. Le tableau 6 reporte la métrique R^2_{KLi} du modèle estimé à La Rochelle-Aunis simulé pour les distances et les masses (actifs et emplois) observés sur d’autres SCoT. Sur la plupart des SCoT, les modèles gravitaires font moins bien qu’une distribution indépendante – qui utilise l’information sur les marges. Les modèles estimés par la procédure non linéaire font en revanche systématiquement mieux que la distribution indépendante et obtiennent des scores comparables à celui sur l’échantillon d’estimation. L’information des marges (le nombre d’actifs et d’emplois par commune) assure une bonne capacité prédictive, améliorée par la modélisation puisque la hiérarchie entre les modèles est conservée.\n\n\n\n\nTableau 6. Prédictions hors édhantillon (out of the bag)\n\n\n\n\n\n\n\n\n\n\n\nLa Rochelle (estimation)\nMétropole Aix-Marseille\nPays Basque et Seignanx\nNiortais\nCaro (Rochefort)\nQuimperlé\nPays des Olonnes\n\n\n\n\nEstimations linéaires\n\n\nGravitaire\n−42.9%\n10.9%\n13.1%\n−211.8%\n−56.7%\n−3.3%\n−800.8%\n\n\nGravitaire (poisson)\n51.2%\n53.1%\n67.2%\n21.4%\n30.5%\n35.9%\n−113.6%\n\n\nGravitaire (poisson, RE)\n79.4%\n49.0%\n33.3%\n−166.5%\n−190.4%\n−9.9%\n−207.9%\n\n\nEstimations non linéaires\n\n\nMEAPS (diag&densité)\n56.0%\n58.1%\n71.1%\n57.0%\n52.9%\n56.3%\n34.9%\n\n\nMEAPS (lin. decay)\n69.4%\n74.1%\n81.0%\n57.0%\n75.5%\n62.8%\n46.6%\n\n\nGrav. (furness, l&c)\n79.3%\n81.4%\n88.5%\n81.5%\n75.8%\n73.6%\n50.2%\n\n\n\nLa métrique reportée est le R2KLi, l’entropie relative KL ou gain d’information ; référence indépendante (ni et ej connus) pour les flux prédits à partir des distances de chaque territoire"
  },
  {
    "objectID": "larochelle.html#a-justements-en-utilisant-une-information-infra-communale",
    "href": "larochelle.html#a-justements-en-utilisant-une-information-infra-communale",
    "title": "MEAPS & gravitaire : estimations à La Rochelle",
    "section": "4 A justements en utilisant une information infra-communale",
    "text": "4 A justements en utilisant une information infra-communale\nOn dispose d’une information au carreau 200m qui peut être est pertinente pour reproduire les données de MOBPRO (2022), bien que celles-ci sont connues entre commune. En effet, on peut localiser les emplois et les résidents plus finement, au carreau, calculer les temps de parcours entre les paires de carreau et injecter cette information géographique dans le modèle. On peut en attendre une meilleure prise en compte des configurations notamment pour les communes voisines. La distance entre les centroïdes peut masquer une densité d’habitation importante à la frontière entre deux communes, on inversement négliger la structure bi-polaire d’une commune et donc des flux qui se répartissent entre deux voisins proches. En utilisant cette représentation géographique à une échelle plus fine, on peut proposer des paramètrisations plus robustes et dont la signification est plus grande.\nCette approche pose généralement un problème difficile d’optimisation algorithmique. Une approche brutale, qui consiste à minimiser une fonction de perte mesurant l’écart entre les flux estimés et les flux observés, se heurte à la grande dimension de l’espace des paramètres. En outre, comme toujours dans ce type d’exercice statistique, l’enjeu consiste à extraire des données disponibles des enseignements généraux en délaissant ce qui relève de la particularité d’un jeu de données. C’est toute la difficulté du surapprentissage (overfitting) que nous avons évoquée.\nUne seconde approche, plus parcimonieuse, consiste à définir une forme fonctionnelle pour les odds-ratios ou encore à regrouper les odds-ratios en quelques clusters pour ensuite n’évaluer qu’un petit nombre de paramètres. Ceci suppose de modéliser la structuration des odds-ratios à partir d’a priori sur les dimensions pertinentes.\n\n4.1 Données infracommunales\n\nEmplois, résidents au carreau Inspire 200m\nLa carte de la zone considérée est représentée sur la graphique 4. L’analyse est limitée aux résidents du périmètre du Schéma de COhérence Territoriale (SCOT) et considère les emplois dans un rayon 33 kilomètres autour des lieux de résidence. Cette carte est construite à partir des données carroyées de C200 (2022) à la résolution du carreau 200m Inspire8. Nous ajoutons à ces données la localisation de l’emploi sur la même grille en utilisant les fichiers fonciers et les données d’emplois localisés de MOBPRO (2022). La méthode consiste à imputer par code NAF les emplois de chaque commune selon MOBPRO (2022) aux surfaces professionnelles à la parcelle issues des fichiers fonciers. Cela permet ensuite de localiser au carreau 200m les emplois. Cette méthode est assez grossière, puisqu’en particulier la ratio personne/surface n’est pas constant d’une entreprise à l’autre, mais elle fournit une bonne première approximation d’autant que l’extrapolation ne dépasse pas l’échelle de la commune. Elle est en tout cas très supérieure à une imputation uniforme.\n8 INfrastructure for SPatial InfoRmation in Europe est depuis 2007 une directive pour la production de données spatialisées. Inspire définit une grille de carroyage et son système de projection harmonisée. C’est ce qui suit l’INSEE dans la diffusion des données carroyées. Voir https://inspire-geoportal.ec.europa.eu pour la définition de la grille et des jeux de données.\n\n\n\n\nGraphique 4. Localisation des emplois et des résidents, zones de la Rochelle. Le périmètre de du SCOT de la Rochelle est indiqué ainsi que les limites administratives des communes et des EPCI le composant.Sources : OSM, Mapbox, IGN, carroyage INSEE 2017, Flores et fichiers fonciers 2018\n\n\n\n\n\n\n\n\n\n\nCalcul des distances par mode\nUn ingrédient important de l’analyse du territoire est la prise en compte des distances entre chaque paire possible résidence/emploi. Contrairement à l’analyse synthétique, nous ne nous contentons pas de la distance euclidienne.\nPour ce faire nous calculons à partir d’un calculateur d’itinéraire (R5 de Conveyal (Conway, Byrd & Linden, 2017 ; Conway, Byrd & Van Eggermond, 2018 ; Conway & Stewart, 2019) en utilisant le package {r5r} (Pereira et al., 2021) les distances et surtout les temps de transport pour quatre modes (voiture, vélo, transport en commun, marche à pied). Les temps de transport calculés pour chaque paire de carreaux de résidence et d’emploi, en retenant le centre des carreaux, tiennent compte des différentes contraintes de circulation (vitesses limites pour la voiture, sens de circulation, pénalité pour changement de direction, accès autorisé ou restreint suivant le mode, stress à vélo). Concernant les déplacements en voiture, nous ne prenons pas en compte à ce stade la congestion. Concernant les transports en commun, le niveau de détail est assez grand, puisque les fréquences de circulations des véhicules ainsi que les correspondances sont prises en compte. Dans certaines villes, il est possible d’accéder à une information sur les temps de parcours effectifs (mesurant ainsi la congestion ou la disponibilité du réseau) en complément des horaires théoriques. Ces informations ne sont pas disponible pour l’agglomération de la Rochelle et donc cette possibilité n’est pas explorée. L’accès aux données GTFS impose quelques limites, comme par exemple la non prise en compte des réseaux scolaires ou d’autres réseaux locaux ou privés non publiés sous ce format. La modification du réseau de transport comme l’ouverture d’une ligne ou l’accroissement de fréquence est pris en compte en modifiant la matrice des distances et temps par mode entre chaque carreau de résidence et chaque carreau de destination. Dans le cas de l’agglomération de la Rochelle, le nombre de paires calculés est de l’ordre de 16 millions.\nA partir des temps de trajets par mode, nous appliquons un modèle de choix discret, Random Utility Model (RUM) à la McFadden, estimé sur l’enquête mobilité des personnes MOBPERS (2021) en utilisant les données de mobilités professionnelles MOBPRO (2022) pour caler les flux commune à commune. L’estimation de ce modèle est détaillée dans un autre document (référence à insérer).\nLes distances entre chaque paire de cases permettent de calculer un indicateur d’accessibilité qui joue un rôle central dans le modèle radiatif, et donc dans MEAPS, en remplaçant la distance par la somme des opportunités en deçà d’un seuil de temps. Les cartes du graphique 5 représentent les temps pour accéder à un seuil d’emplois en utilisant différents modes de transport.\n\n\n\nGraphique 5. Temps d’accès à l’emploi. Pour chaque carreau de résidence, on détermine le temps minimal pour atteindre au moins 1000, 5000, 10000 ou 20000 emplois suivant l’un des quatre modes considéré.Calcul des auteurs. Source : OSM, Mapbox, IGN, Conveyal R5, carroyage INSEE 2017, Flores et fichiers fonciers 2018\n\n\n\n1 000 emplois5 000 emplois10 000 emplois20 000 emplois\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLes courbes d’accessibilité de la graphique 6 sont construites en prenant la moyenne par commune de résidence des temps d’accès pour les différents seuils d’emplois. C’est cette courbe qui découle du modèle théorique présenté par ailleurs (Aspects théoriques) et qui détermine les choix individuels de déplacement comme de localisation. Ces courbes font apparaître une propriété propre aux villes littorales : si pour des temps courts, l’accès à l’emploi est maximal à la Rochelle, en revanche d’autres communes jouissent d’une position plus « centrale » lorsqu’on accepte des temps de trajets supérieurs à 30 minutes en voiture.\n\n\n\n\n\nGraphique 6. Courbe du temps d’accès aux emplois. Pour chaque commune, on calcule la médianne, pondérée par le nombre d’habitants par carreau, du temps d’accès à différents seuils d’emplois. Cela permet de caractériser les communes par leur accessibilité à l’emploi, une mesure plus pertinente de la ‹distance à l’emploi›.Sources : OSM, Mapbox, IGN, Conveyal R5, carroyage INSEE 2017, Flores et fichiers fonciers 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEncadré 2. Ergodicité\n\n\n\n\n\nLa graphique 7 représente le R^2_{KL} que l’on calcule pour le modèle de référence (MEAPS à la maille carreau 200m) en effectuant des simulations de Monte-Carlo pour différentes tailles de l’échantillon d’ordre de priorité. Sans surprise, plus l’échantillon est grand, plus la distribution des R^2_{KL} est étroite. Pour 256 tirages, l’intervalle de confiance à 95% pour le R^2_{KL} est de l’ordre de 0.017% (contre 0.04% pour 64 tirages et 0.003% pour 1024 tirages) ce qui sera suffisant pour la plupart des applications.\nLa valeur moyenne du R^2_{KL} obtenue pour le MEAPS de référence est de 88.4%.\n\n\n\n\n\nGraphique 7. Densité des R^2_{KL} simulés par bootstrap pour une simulation de Monte-Carlo sur 64 ou 256 ou 1024 tirages.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.2 Modèle saturé : estimation d’autant d’odds-ratios que de paires de commune\nA ce stade, nous utilisons un algorithme naïf pour trouver une solution au problème posé. Nous calculons les odds-ratios \\omicron^k_{ij} qui permettraient de combler l’écart entre les prévisions de MEAPS effectuées avec un ensemble d’odds-ratios \\omicron^{k-1}_{ij} et les données observées de MOBPRO (2022) en utilisant la formule suivante où \\beta est un paramètre d’amortissement inférieur à 1 et positif et où k indexe les itérations :\n\n\\omicron^k_{ij} = \\biggl(\\frac{\\tilde{c}^k_{abs}}{\nc^{mobpro}_{abs}}\\biggr)^\\beta \\times \\omicron^{k-1}_{ij}\n\\tag{18}\nNous modifions alors les \\omicron_{ij} en fonction des écarts observés. Cela conduit à chercher un point fixe.\nL’algorithme naïf est relativement efficace. Il converge en quelques dizaines d’itérations, s’avère stable et fait diminuer l’entropie relative. Il devra être affiné dans le futur afin de permettre une descente de gradient qui permet de minimiser explicitement l’entropie relative. L’algorithme naïf permet de réduire cette entropie relative sans assurer qu’elle est minimale.\nCet algorithme a été utilisé avec différentes contraintes sur les paramètres. Le tableau 7 indique la qualité de l’ajustement obtenu dans ces différentes configurations. La première est celle où les probabilités d’absorption sont déterminées uniquement par les fuites par commune de résidence. C’est la configuration la plus parcimonieuse en termes de paramètres et qui sert de référence. Le R^2_{KL} vaut 88% ce qui est un ajustement élevé. La seconde configuration est celle où l’on ajuste des \\omicron_{ij} uniquement pour les termes diagonaux (i=j). Cette configuration ajuste donc un odd-ratio pour les résidents qui travaillent dans leur commune de résidence. Dans un certain nombre de communes, cet ajustement conduit à augmenter la probabilité d’absorption interne (graphique 11), ce qui indique que le choix de résidence n’est pas indépendant de celui d’activité. Pour la commune la plus importante (La Rochelle), en revanche, l’odd-ratio \\omicron_{17300, 17300} est proche de 1. Les deux configurations suivantes laissent beaucoup plus de degrés de liberté en estimant des \\omicron_{ij} librement. La première de ces deux configurations limite les \\omicron_{ij} estimés à ceux représentant un total cumulé des flux mesurés par MOBPRO (2022) égal à 99.4%, soit 1 854 \\omicron_{ij} . La seconde configuration estime tous les \\omicron_{ij} sans limite (soit 2 033 paramètres pour 72 communes de résidence et 210 communes d’activité, avec un grand nombre de liaisons non considérées parce que nulles).\n\n\n\n\nTableau 7. Ajustements non paramètriques, mobilités professionelles la Rochelle\n\n\n\n\n\n\n\n\n\n\n\nRKL2\nDegrés de liberté\nodds estimés\n\n\n\n\nRéférence (odds unitiaires)\n88.4%\n1 752\n0\n\n\nDiagonale (résidence égale emploi)\n95.0%\n1 681\n71\n\n\n90% des flux cumulés\n97.4%\n1 027\n725\n\n\n99% des flux cumulés\n99.3%\n0\n1 849\n\n\n100% des flux cumulés\n99.6%\n0\n2 029\n\n\n\nLe nombre de degrés de liberté est le nombre de paires de flux non nuls dans MOBPRO, moins les contraintes en ligne et en colonne, plus un puisqu’elles sont redondantes moins le nombre de paramètres estimés. Le nombre de degré de liberté est nul pour les configurations 99% et 100% arce que le nombre de paramètres estimés est supérieur au produit des linges et des colonnes moins les contraintes. Il y a bien plus de paramètres estimés pour la configuration 100% que pour 99%. En conséquence, l’algorithme conduit à un résultat légèrement différent.\n\n\n\n\n\n\n\n\n\n\n\n\nla graphique 8 représente les flux observés et estimés pour les différentes configurations du tableau 7. Le fait d’estimer uniquement les \\omicron_{ii} diagonaux, en ajustant donc seulement les flux allant d’une commune de résidence vers elle même, donne déjà de très bons résultats en faisant passer le R^2_{KL} de 88% à 95% et en réduisant visiblement les écarts entre flux observé et flux estimé, comme le montrent les deux panneaux supérieurs de la graphique 8. L’ajout de paramètres supplémentaires ne fait pas gagner beaucoup plus, d’autant que les écarts pour les flux marginaux ne sont pas tant réduits que ça. La limite de l’algorithme naïf apparaît ici, puisque le modèle complètement saturé n’ajuste pas totalement la distribution. Différents détails de l’algorithme peuvent l’expliquer, notamment la censure des odd-ratio trop faibles (&lt;0.0001) ou trop importants (&gt;10000) ou la prise en compte des flux nuls. Au-delà de cet argument, il est probable que pour converger vers un ajustement plus strict, il serait nécessaire de calculer la matrice des quasi dérivées des flux par rapport aux \\omicron_{ij}.\nMais le coût peut être très élevé puisque cette matrice (calculée dans la partie synthétique dans un cas simple) est d’une taille considérable (1 755 \\times 1 755 cœfficients), surtout si l’on prend en compte que le calcul de chaque terme prend autour d’une vingtaine de secondes9.\n9 Autour d’une année de vCPU…\n\n\n\n\nGraphique 8. La figure présente pour chaque configuration d’estimation le flux observé (axe des x) et le flux estimé (axe des y) en bleu lorsque oi,j est estimé et en rouge lorsque oi,j n’est pas estimé (les fuites sont toujours utilisées). La valeur de référence est répétée dans chaque panneau en gris clair.\n\n\n\n\n\n\n\n\nNotons que l’échantillon des mobilités donné par MOBPRO (2022) pour l’agglomération de la Rochelle est très particulier. Une commune (La Rochelle, dont le code géographique est 17300) représente presque 29% des flux de mobilité (de La Rochelle lieu de résidence vers La Rochelle lieu d’emploi). C’est donc un schéma monocentrique, où à la fois les résidents et les emplois sont concentrés sur un territoire réduit. La résolution spatiale de MOBPRO (2022) ne nous permet pas d’en détailler la structure plus fine.\nPour les 20 plus grandes communes de l’agglomération de la Rochelle – qui comptent chacune plus de 1 000 résidents en activité – on peut représenter les odds-ratios estimés dans la configuration 100% des flux par rapport aux chances calculées dans le cas où tous les \\omicron_{ij} sont égaux à 1 (des odds-ratios effectifs) en fonction de la distance entre la commune de destination et la commune de résidence10. Ce diagramme, analogue à un spectre, peut aussi être construit par commune de destination, la distance d étant la distance aux différentes communes de résidence graphique 10. L’élément le plus frappant est que les odds-ratios de i à i sont généralement supérieur à 1 (graphique 9), à l’exception de la commune de la Rochelle. Il n’émerge pas de structure particulière par rapport à la distance, si ce n’est des odds-ratios élevés pour des distances importantes\n10 La distance est construite comme la distance moyenne pondérée entre les résidents de la commune de départ et les emplois de la commune d’arrivée. La pondération est le produit des emplois et des résidents pour chaque paire, normalisé à 1.\n\n\n\n\nGraphique 9. La figure représente pour les 20 plus grandes communes de l’agglomération de la Rochelle les odd-ratios estimés (configuration 100% des flux) en fonction de la distance entre cette commune et les communes où travaillent les résidents. Les points marqués d’un petit point blancs sont les emplois situés hors du périmètre du SCoT.\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphique 10. La figure représente pour les 20 plus grandes communes d’emplois du périmètre géographique (33 km autour de l’agglomération de la Rochelle) les odd-ratios estimés (configuration 100% des flux) en fonction de la distance entre cette commune et les communes où résident les travailleurs de la commune.\n\n\n\n\n\n\n\n\nLa graphique 11 permet de préciser la valeur élevée des odds-ratios pour les flux internes. Les communes où sont localisés de nombreux emplois ont un odds-ratio plutôt plus faible alors qu’ils sont estimés plus élevés dans les communes plus petites et moins desservies. Pour les différentes procédure d’estimation et donc différents nombres de paramètres estimés, on observe une structure similaire dans la répartition géographique des odds-ratios, ce qui suggère que les odds-ratios estimés contiennent de l’information.\nUn odds-ratio élevé dans la diagonale indique que les flux internes sont plus importants que dans le scénario de référence. Cela indique probablement un choix de résidence en lien avec l’emploi occupé en privilégiant la commune d’activité pour résidence (ou éventuellement l’inverse). Le spectre résident en fonction de la distance indique que ce phénomène, s’il est une hypothèse à très faible distance, ne persiste pas en dehors de la commune de résidence. En revanche, la graphique 10 suggère que dans certaines communes, notamment Surgères, on observe des odds-ratios supérieurs à 1 pour des distances faibles, ce qui s’interprète comme le fait que les habitants des communes alentours privilégient Surgères comme lieu d’emploi.\nA ce stade, les observations sont limitées par le faible nombre de communes modélisées, mais on peut espérer que l’analyse des odds-ratios estimés pourra servir à caractériser les communes en fonction des choix de résidence et d’emploi. En multipliant cette analyse pour d’autres territoires, l’information apportée par les odds-ratios pourra être inférée. Il sera aussi possible de confronter ces éléments à d’autres variables, comme le prix de l’immobilier, les loyers résidentiels ou commerciaux, la densité d’emploi.\n\n\n\n\n\nGraphique 11. Chaque cercle indique les odd-ratio estimés dans la diagonale (100% des flux). Les diamètres des cercles sont proportionels aux flux internes (de i à i).\n\n\n\n\n\n\n\n\n\n\n4.3 Estimations paramétriques et comparaison avec le modèle gravitaire\nAu lieu d’estimer directement un ensemble d’odds-ratios \\omicron_{ij}, on peut proposer des formes fonctionnelles paramétriques à partir desquelles on calculera les odds-ratios. C’est une stratégie bien plus parcimonieuse. On détermine alors les paramètres de la forme fonctionnelle retenue par un algorithme standard de minimisation de l’entropie relative, qui est le critère que nous avons choisi pour comparer les distributions. Il est également possible de conduire une estimation paramétrique pour le modèle gravitaire.\nNous explorons ici trois formes fonctionnelles pour MEAPS :\n\nUn paramètre pour tous les termes diagonaux, c’est-à-dire les flux allant d’une commune de résidence vers cette même commune pour l’emploi. Cette forme est proche de la forme « diagonale » estimé dans la section 4.2, mais un seul paramètre est estimé – par une minimisation de l’entropie relative – au lieu de 72 par l’algorithme itératif. Formellement, \\omicron_{i \\neq j}=1 et \\omicron_{ii} = o.\nUn paramètre pour tous les termes diagonaux et un paramètre pour les communes voisines d’emploi, c’est-à-dire un terme correctif reliant une commune de résidence aux communes voisines. Une commune est voisine d’une autre si au moins 5% des trajets pondérés par les emplois et les résidents ont une distance kilométrique inférieure à 3 km. Cette définition permet d’exclure des communes limitrophes mais dont les pôles principaux sont distants. Formellement, \\omicron_{ii} = o_d; \\omicron_{ij\\in \\mathcal{V}(i)} = o_v et \\omicron_{i, j \\neq i, j \\notin \\mathcal{V}(i)} = 1.\nUn cœfficient pour la distance et un paramètre pour la distance de « bascule ». Formellement, en dessous d’une distance d_c , on définit un \\omicron_{ij \\in d_{i,j} \\leq d_c} = o et \\omicron_{ij \\in d_{i,j} &gt; d_c} = 1. Cette forme partage la même idée que le premier modèle, mais estime la notion de proximité au lieu de reposer sur le découpage administratif.\n\nChacune de ces options mesure un biais intra-communal qui peut s’expliquer par un choix conjoint de localisation de résidence et d’emploi. MEAPS offre ici la possibilité de mesurer l’intensité de ce phénomène par rapport à l’hypothèse où les emplois sont considérés indépendamment de la localisation et sont tous parfaitement substituables. Il sera intéressant de comparer les territoires de ce point de vue et de repérer et quantifier des spécificités locales, qu’elles concernent la géographie du territoire – sa structure en pôles ou en satellite –, la formation des prix de l’immobilier, le réseau de transport ou la nature de l’activité économique. On pourrait également chercher à exploiter l’information sectorielle – disponible dans MOBPRO (2022) au niveau de 5 secteurs – ou l’information sociale ou démographique – disponible au niveau communal ou de l’IRIS mais qui peut être exploitée également à un niveau plus fin avec Fidéli11.\n11 Fichiers démographiques sur les logements et les individus, INSEE, https://www.insee.fr/fr/metadonnees/source/serie/s1019.A ces formes fonctionnelles pour MEAPS, nous ajoutons deux formes fonctionnelles pour le modèle gravitaire :\n\nun modèle gravitaire suivant la définition équation 1 où f(d)= e^{d/\\delta}. Un seul paramètre \\delta est estimé.\nun modèle gravitaire « équilibré » en utilisant l’algorithme de Furness, tel que décrit plus haut et en estimant \\delta comme dans le point 4.\n\nOn pourrait multiplier les modèles estimés12. Le propos est ici d’illustrer les possibilités de notre modélisation et de les comparer à celles du modèle gravitaire. Deux points émergent :\n12 Par exemple, en faisant dépendre les odd-ratios non pas de la distance et d’une distance critique mais du rang et d’un rang critique.\nMEAPS peut mieux reproduire les données, avec une qualité d’ajustement meilleure,\nMEAPS ouvre des possibilités d’interprétation plus riches que celle du modèle gravitaire, parce que les fondements microscopiques de MEAPS sont explicites.\n\n\n\n\n\n\n\nEncadré 3. Emiettage\n\n\n\n\n\nDans les simulations synthétiques présentées dans le document « Aspects théoriques » les flux sont simulés avec une granularité individuelle. Chaque emploi ou chaque individu est localisé et les distances sont calculées entre ces localisations et les flux par individu sont simulés. L’agrégation spatiale à la maille hexagonale se fait ensuite. Dans le cas des données que nous utilisons pour La Rochelle, les carreaux ne sont pas occupés par un seul résident actif ou un seul emploi. Il y a des paquets pour lesquels il n’est pas nécessaire de refaire les simulations individu par individu ou emploi par emploi. Nous les avons donc regroupés et simuler en conséquences dans MEAPS. Cela pose cependant un problème puisque le choix d’un ordre de priorité s’exerce maintenant sur des individus en paquets de taille différente, un faible nombre de ces paquets étant de taille très supérieure à la médiane des autres. Ainsi, lorsqu’un paquet de taille importante est à son tour de choisir, il peut saturer des emplois en une seule passe. Pour résoudre ce problème, nous procédons à un émiettage dans lesquels les paquets de plus grande taille sont divisés en paquets plus petits. Pour un seuil d’émiettage de 20 individus (le flux le plus important de MOBPRO (2022) pour La Rochelle est de 18 000) , on augmente le nombre de paquets d’environ 50% ce qui permet de conserver un problème de taille globale raisonnable tout en réduisant le problème de granularité des paquets. De plus, les paquets sont tirés au sort dans leur ordre de priorité en tenant compte de leur taille afin d’éviter une sur-représentation des paquets de petite taille dans les ordres de priorité.\n\n\n\nLe tableau tableau 8 résume les résultats des estimations. Le modèle de référence, dans lequel tous les emplois sont substituables pour chaque individu, fait moins bien en termes d’ajustement que les autres modèles, à l’exception notable du modèle gravitaire non équilibré. Comme on avait pu le constater dans les estimations non paramétriques, le modèle de référence a, malgré son hypothèse simplificatrice, une bonne performance, ce qui est confirmé ici par la comparaison au modèle gravitaire simple.\n\n\n\n\nTableau 8. Ajustements paramètriques, mobilités professionelles la Rochelle\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRKL2\nDegrés de liberté\nParamètres\n\n\n\n\nRéférence\n88.4%\n1 752\n\n\n\n1. Commune vers commune\n93.0%\n1 751\nNA\n\n\n2. Commune vers commune et voisines\n93.1%\n1 750\nod≈4.3 ov≈1.3\n\n\n3. Distance carreau 200m\n94.1%\n1 750\ndc≈ 9 min o≈19\n\n\n4. Gravitaire sans Furness\n82.6%\n1 961\nδ≈20 min\n\n\n5. Gravitaire avec Furness\n90.7%\n1 751\nδ≈17 min\n\n\n\nLe nombre de degrés de liberté est le nombre de paires de flux non nuls dans MOBPRO, moins les contraintes en ligne et en colonne, plus un puisqu’elles sont redondantes moins le nombre de paramètres estimés. Les unités sont des minutes de trajet pour les paramètres homogènes à une distance et sans unité pour les odd-ratios.\n\n\n\n\n\n\n\n\n\n\n\n\nLes estimations des modèles 1 à 3, dans lesquelles on explore un terme diagonal sous différentes formes, renforcent le diagnostic de biais communal noté dans les estimations non paramétriques. Il y a en moyenne 4 fois plus de chance de choisir un emploi (tableau 8, lignes 1 et 2) dans la commune de résidence. L’estimation du modèle 2 montre que les communes voisines ne connaissent pas un biais comparable, bien que la chance de choisir un emploi dans celles-ci soit supérieure à 1.\nL’estimation du modèle 3 indique qu’apparemment la distance explique mieux le biais communal que le découpage administratif et il convient plutôt de voir celui-ci comme un biais de proximité. En effet, le cœfficient d’ajustement est supérieur de plus d’un point à celui obtenu avec le premier modèle, en perdant uniquement 1 degré de liberté. La distance de bascule est faible, autour de 9 minutes, ce qui suggère que le périmètre communal est trop large pour capturer cet effet. La chance à plus courte distance est également nettement plus élevée puisqu’au lieu d’être approximativement de 4 elle est approximativement de 19, soit plus de 4 fois plus.\nIl convient à ce stade d’être prudent sur cette estimation, puisque la résolution des données est largement inférieure au seuil qui a été trouvé. La simulation est basée sur des distances et des localisations d’emplois au carreau 200m dont la précision est convaincante. Mais les flux dans MOBPRO (2022) ne sont connus que pour les communes d’origine et de départ et donc avec une résolution spatiale plus faible. La multiplication des observations peut palier à cette faible résolution spatiale, mais cela demandera d’établir une analyse des distances et des localisations sur des territoires plus grands et plus nombreux. Pour avancer, il faudrait recourir à des données de flux plus finement localisées, par exemple à partir de Fidéli13 ou de données issues de traçages numériques.\n13 A partir de Fidéli, on peut préciser la localisation de chaque individu et utiliser l’information sur la commune dans laquelle il travaille. On ne peut pas en revanche localiser plus précisément la localisation de l’emploi occupé.\n\n\n\n\nGraphique 12. La figure présente pour chaque configuration d’estimation le flux observé (axe des x) et le flux estimé (axe des y) en bleu lorsque oi,j est estimé et en rouge lorsque oi,j n’est pas estimé (les fuites sont toujours utilisées). La valeur de référence est répétée dans chaque panneau en gris clair.\n\n\n\n\n\n\n\n\nLes estimations paramétriques indiquent une moins bonne performance du modèle gravitaire. Sans respect des contraintes en colonne, le modèle gravitaire donne une image assez faussée des trajets. Il peine à reproduire le biais de proximité et l’influence de la distance. Le premier tend à produire un paramètre \\delta très élevé alors que le second devrait au contraire imposer un \\delta plus faible pour rendre compte de trajets plus longs. L’application d’une même valeur de la distance suivant des milieux plus ou moins denses handicape cette représentation. La procédure de Furness améliore la capacité du modèle gravitaire à rendre compte des données, mais, comme nous le disions, au prix de la perte du lien avec la distance telle qu’elle est formulée dans le modèle gravitaire, à savoir homogène pour tous.\nLa graphique 13 illustre ce qui est à l’œuvre dans le modèle gravitaire. La minimisation de l’entropie relative dépend beaucoup des flux à l’intérieur de La Rochelle, qui pèsent 29% de l’échantillon. La prise en compte des autres communes diagonales n’est pas bonne, ce qui conduit à un R^2_{KL} moins bons que la référence de MEAPS (tous les emplois sont identiques pour chaque individu et ne diffèrent que par leur localisation). Le respect de la contrainte en colonne par la procédure de Furness permet une meilleure prise en compte des communes diagonales (dont le poids est de 35% dans l’échantillon La Rochelle), mais moins bonne que les modèles MEAPS paramétriques ou non.\n\n\n\n\n\nGraphique 13. La figure présente pour chaque configuration d’estimation le flux observé (axe des x) et le flux estimé (axe des y) en bleu lorsque oi,j est estimé et en rouge lorsque oi,j n’est pas estimé (les fuites sont toujours utilisées). La valeur de référence est répétée dans chaque panneau en gris clair.\n\n\n\n\n\n\n\n\nLa graphique 14 confirme ce diagnostic. On y compare la distrbution cumulée en fonction de la distance kilométrique pondérée entre chaque commune pour différentes estimations, les flux de MOBPRO (2022) étant utilisé comme référence. Les performances des modèles sont comparables pour les courtes distances (i.e la commune de la Rochelle vers elle-même). Le modèle gravitaire avec ou sans Furness pêche sur les distances intermédiaires et donne trop de poids aux distances très longues. Les estimations paramétriques à partir de MEAPS parviennent bien à reproduire la distribution cumulée des distances, notamment le modèle paramétrique 3. qui retient la distance au carreau 200m comme forme fonctionnelle.\n\n\n\n\n\nGraphique 14. Distributions empiriques cumulées des flux selon la distance. MOBPRO est indiqué en trait pointillé noir. La figure du haut est la distribution cumulée, celle du bas la différence entre la distribution et celle de MOBPRO"
  },
  {
    "objectID": "larochelle.html#conclusion",
    "href": "larochelle.html#conclusion",
    "title": "MEAPS & gravitaire : estimations à La Rochelle",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nLes estimations que nous présentons ici aboutissent à plusieurs résultats importants :\n\nune métrique pondérée ou d’entropie relative produit des résultats plus robustes, plus convainquant et une capacité de prédiction bien meilleure que la métrique implicite (non pondérée) des moindres carrés ordinaires ;\nl’utilisation de données supplémentaires sur la géographie du territoire (localisation des individus, des résidents, réseaux de transport) accroît la qualité des estimation et la capacité prédictive ;\nla modélisation des flux par MEAPS a de meilleures propriétés et une plus grande capacité prédictive que le modèle gravitaire, y compris lorsque celui ci est estimé en utilisant une métrique adaptée et une information géographique fine, à partir du moment où l’on introduit des paramètres dans le modèle radiatif. Le modèle radiatif universel et sans paramètre produit un résultat correct, mais l’ajustement est inférieur à ceux de modèles gravitaires paramétrisés ;\nles paramètres du modèle gravitaire sont difficilement interprétables. Ils dépendent en effet de la configuration spatiale spécifique et de l’échelle d’observation. MEAPS permet une approche structurelle aux fondements bien définis qui donne aux paramètres une signification plus générale."
  },
  {
    "objectID": "larochelle.html#références",
    "href": "larochelle.html#références",
    "title": "MEAPS & gravitaire : estimations à La Rochelle",
    "section": "Références",
    "text": "Références\n\n\nAgresti, A. (2002), « Categorical Data Analysis », Wiley Series in Probability and Statistics. https://doi.org/10.1002/0471249688\n\n\nAitchison, J. & Ho, C.H. (1989), « The multivariate Poisson-log normal distribution », Biometrika, vol. 76, n°4, pp. 643‑653. https://doi.org/10.1093/biomet/76.4.643\n\n\nC200 (2022), « Revenus, pauvreté et niveau de vie en 2017 - Données carroyées. Dispositif Fichier localisé social et fiscal (Filosofi) »,.\n\n\nColin Cameron, A. & Windmeijer, F.A.G. (1997), « An R-squared measure of goodness of fit for some common nonlinear regression models », Journal of Econometrics, vol. 77, n°2, pp. 329‑342. https://doi.org/10.1016/s0304-4076(96)01818-0\n\n\nConway, M.W., Byrd, A. & Linden, M. van der (2017), « Evidence-Based Transit and Land Use Sketch Planning Using Interactive Accessibility Methods on Combined Schedule and Headway-Based Networks », Transportation Research Record: Journal of the Transportation Research Board, vol. 2653, n°1, pp. 45‑53. https://doi.org/10.3141/2653-06\n\n\nConway, M.W., Byrd, A. & Van Eggermond, M. (2018), « Accounting for uncertainty and variation in accessibility metrics for public transport sketch planning », Journal of Transport and Land Use, vol. 11, n°1. https://doi.org/10.5198/jtlu.2018.1074\n\n\nConway, M.W. & Stewart, A.F. (2019), « Getting Charlie off the MTA: a multiobjective optimization method to account for cost constraints in public transit accessibility metrics », International Journal of Geographical Information Science, vol. 33, n°9, pp. 1759‑1787. https://doi.org/10.1080/13658816.2019.1605075\n\n\nDios Ortúzar, J. de & Willumsen, L.G. (2011), Modelling transport, John wiley & sons.\n\n\nFlowerdew, R. & Aitkin, M. (1982), « A Method of Fitting the Gravity Model Based on the Poisson Distribution* », Journal of Regional Science, vol. 22, n°2, pp. 191‑202. https://doi.org/10.1111/j.1467-9787.1982.tb00744.x\n\n\nFotheringham, A.S. (1983), « A New Set of Spatial-Interaction Models: The Theory of Competing Destinations », Environment and Planning A: Economy and Space, vol. 15, n°1, pp. 15‑36. https://doi.org/10.1177/0308518X8301500103\n\n\nJosselin, D., Carpentier-Postel, S., Audard, F., Amarouch, S., Durand, J.-B., Brachet, N., Coulon, M. & Garcin, L. (2020), « Estimer des flux de navetteurs avec un modèle gravitaire : application géomatique en région Provence-Alpes-Côte d’Azur (France)1 », Geomatica, vol. 74, n°3, pp. 104‑130. https://doi.org/10.1139/geomat-2020-0009\n\n\nKullback, S. & Leibler, R.A. (1951), « On Information and Sufficiency », The Annals of Mathematical Statistics, vol. 22, n°1, pp. 79‑86. https://doi.org/10.1214/aoms/1177729694\n\n\nLenormand, M., Bassolas, A. & Ramasco, J.J. (2016), « Systematic comparison of trip distribution laws and models », Journal of Transport Geography, vol. 51, pp. 158‑169. https://doi.org/10.1016/j.jtrangeo.2015.12.008\n\n\nMOBPERS (2021), « EMP 2019 Résultats détaillés de l’enquête mobilité des personnes de 2019 »,.\n\n\nMOBPRO (2022), « Mobilités professionnelles en 2019 : déplacements domicile - lieu de travail Recensement de la population - Base flux de mobilité »,.\n\n\nPereira, R.H.M., Marcus Saraiva, Daniel Herszenhut, Carlos Kaue Vieira Braga & Matthew Wigginton Conway (2021), « r5r: Rapid Realistic Routing on Multimodal Transport Networks with R5 in R »,. https://doi.org/10.32866/001c.21262\n\n\n\n\n\nGraphique 1. carte des SCoT\nTableau 1. Description des échantillons d’estimation et de test\nTableau 1. Description des échantillons d’estimation et de test\nTableau 1. Description des échantillons d’estimation et de test\nTableau 1. Description des échantillons d’estimation et de test\nTableau 1. Description des échantillons d’estimation et de test\nTableau 1. Description des échantillons d’estimation et de test\nTableau 1. Description des échantillons d’estimation et de test\nGraphique 2. Modèles gravitaires, Observés versus estimés\nGraphique 3. Estimations non linéaires, Observés versus estimés\nGraphique 4. Localisation des emplois et des résidents, zones de la Rochelle. Le périmètre de du SCOT de la Rochelle est indiqué ainsi que les limites administratives des communes et des EPCI le composant.Sources : OSM, Mapbox, IGN, carroyage INSEE 2017, Flores et fichiers fonciers 2018\nGraphique 5. Temps d’accès à l’emploi. Pour chaque carreau de résidence, on détermine le temps minimal pour atteindre au moins 1000, 5000, 10000 ou 20000 emplois suivant l’un des quatre modes considéré.Calcul des auteurs. Source : OSM, Mapbox, IGN, Conveyal R5, carroyage INSEE 2017, Flores et fichiers fonciers 2018\nGraphique 5. Temps d’accès à l’emploi. Pour chaque carreau de résidence, on détermine le temps minimal pour atteindre au moins 1000, 5000, 10000 ou 20000 emplois suivant l’un des quatre modes considéré.Calcul des auteurs. Source : OSM, Mapbox, IGN, Conveyal R5, carroyage INSEE 2017, Flores et fichiers fonciers 2018\nGraphique 5. Temps d’accès à l’emploi. Pour chaque carreau de résidence, on détermine le temps minimal pour atteindre au moins 1000, 5000, 10000 ou 20000 emplois suivant l’un des quatre modes considéré.Calcul des auteurs. Source : OSM, Mapbox, IGN, Conveyal R5, carroyage INSEE 2017, Flores et fichiers fonciers 2018\nGraphique 5. Temps d’accès à l’emploi. Pour chaque carreau de résidence, on détermine le temps minimal pour atteindre au moins 1000, 5000, 10000 ou 20000 emplois suivant l’un des quatre modes considéré.Calcul des auteurs. Source : OSM, Mapbox, IGN, Conveyal R5, carroyage INSEE 2017, Flores et fichiers fonciers 2018\nGraphique 6. Courbe du temps d’accès aux emplois. Pour chaque commune, on calcule la médianne, pondérée par le nombre d’habitants par carreau, du temps d’accès à différents seuils d’emplois. Cela permet de caractériser les communes par leur accessibilité à l’emploi, une mesure plus pertinente de la ‹distance à l’emploi›.Sources : OSM, Mapbox, IGN, Conveyal R5, carroyage INSEE 2017, Flores et fichiers fonciers 2018\nGraphique 7. Densité des R^2_{KL} simulés par bootstrap pour une simulation de Monte-Carlo sur 64 ou 256 ou 1024 tirages.\nGraphique 8. La figure présente pour chaque configuration d’estimation le flux observé (axe des x) et le flux estimé (axe des y) en bleu lorsque oi,j est estimé et en rouge lorsque oi,j n’est pas estimé (les fuites sont toujours utilisées). La valeur de référence est répétée dans chaque panneau en gris clair.\nGraphique 9. La figure représente pour les 20 plus grandes communes de l’agglomération de la Rochelle les odd-ratios estimés (configuration 100% des flux) en fonction de la distance entre cette commune et les communes où travaillent les résidents. Les points marqués d’un petit point blancs sont les emplois situés hors du périmètre du SCoT.\nGraphique 10. La figure représente pour les 20 plus grandes communes d’emplois du périmètre géographique (33 km autour de l’agglomération de la Rochelle) les odd-ratios estimés (configuration 100% des flux) en fonction de la distance entre cette commune et les communes où résident les travailleurs de la commune.\nGraphique 11. Chaque cercle indique les odd-ratio estimés dans la diagonale (100% des flux). Les diamètres des cercles sont proportionels aux flux internes (de i à i).\nGraphique 12. La figure présente pour chaque configuration d’estimation le flux observé (axe des x) et le flux estimé (axe des y) en bleu lorsque oi,j est estimé et en rouge lorsque oi,j n’est pas estimé (les fuites sont toujours utilisées). La valeur de référence est répétée dans chaque panneau en gris clair.\nGraphique 13. La figure présente pour chaque configuration d’estimation le flux observé (axe des x) et le flux estimé (axe des y) en bleu lorsque oi,j est estimé et en rouge lorsque oi,j n’est pas estimé (les fuites sont toujours utilisées). La valeur de référence est répétée dans chaque panneau en gris clair.\nGraphique 14. Distributions empiriques cumulées des flux selon la distance. MOBPRO est indiqué en trait pointillé noir. La figure du haut est la distribution cumulée, celle du bas la différence entre la distribution et celle de MOBPRO"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MEAPS : Modèle Ergodique d’Absorption avec Priorité et Saturation",
    "section": "",
    "text": "MEAPS : Modèle Ergodique d’Absorption avec Priorité et Saturation\nLe modèle gravitaire utilisé pour distribuer les trajets entre une origine et une destination représente mal l’influence de la distance sur les choix. En partant du modèle des « intervening opportunities » de Stouffer (1940) et du modèle radiatif de Simini et al. (2012), nous construisons un Modèle Ergodique d’Absorption avec Priorité et Saturation qui permet de construire ces choix sur des fondements microscopiques explicites et flexibles – qui peuvent s’adapter à une grande palette de situations. Ainsi, ce modèle s’accommode de différentes formulations des processus stochastiques microscopiques qui permettent d’estimer des paramètres fondamentaux et de leur donner une interprétation.\nAutour de ce modèle nous avons produit trois documents :\n\nDans le premier document, Aspects théoriques (Parodi & Timbeau, 2023), nous définissons le modèle et nous en dérivons quelques propriétés théoriques. La logique est de classer pour chaque résident les opportunités qu’il peut atteindre. Ce classement peut être par exemple dans l’ordre défini par les distances. Chque individu parcoure alors les opportunités et a à chaque rencontre une probabilité de s’arrêter (Absorption). Chaque absorption diminue la quantité d’opportunités disponibles aux autres individus jusqu’à la Saturation. L’affectation des opportunités est faite en fonction d’un ordre de Priorité des individus et nous considérons la moyenne des affectations sur un ensemble d’ordre tirés au sort (Ergodique). A partir de simulations sur des données synthétiques (c’est-à-dire générées par des processus connus), nous explorons les propriétés du modèle théorique.\n\n\n\n\n\n\n\n\n\nDans le second document, Estimation à la Rochelle (Parodi & Timbeau, 2024b), nous ajustons MEAPS sur des données en le comparant aux modèles gravitaires. Un point important est l’hypothèse faire sur le processus générateur. La nature des données de flux et leur distribution fait privilégier une distribution de Poisson à la distribution log-normale habituellement choisie. Ceci conduit à privilégier la minimisation de l’entropie relative de Kullback-Leibler à la somme des erreurs au carré. En changeant de métrique on peut estimer des modèles par des procédures non linéaires. Nous comparons systématiquement les modèles gravitaires avec MEAPS augmenté de structures particulières sur les odds-ratios et, à moins de le normer localement et globalement, le modèle gravitaire ressort moins pertinent que MEAPS. En effet, deux propriétés importantes doivent être respectées : l’additivité locale et l’agrégation. Lorsque ces propriétés sont respectées, les modèles ont de bonnes performances hors échantillon. En utilisant une information infracommunale, il est possible d’augmenter la capacité prédictive des modèles, en particulier de MEAPS. Ceci permet également de projeter à une échelle infra-communale les flux simulés.\n\n\n\n\n\nDans un troisième document, Projections des trajets (Parodi & Timbeau, 2024a), nous proposons une application de MEAPS à la Rochelle de la modélisation des trajets quotidiens entre le domicile et le travail. En ajoutant une modélisation des fréquences de trajets, de leur complexité (multi motifs), des modes de transport, déclinée pour différentes catégories de ménages, nous produisons une cartographie des émissions de CO2 au carreau 200m. Cette modélisation permet de reprendre la discussion entre densité et émissions de CO2, que nous retraçons dans la littérature pour conclure que ce lien est plus complexe qu’habituellement considéré. Il est en effet illusoire vouloir capturer la notion de « ville compacte » avec seulement une mesure de la densité ou d’autres métriques (les fameux 3Ds). Il est nécessaire de prendre en compte le lien entre la distribution spatiale des résidents et de leurs centre d’intérêts (ici leurs emplois) pour appréhender l’impact de la forme urbaine et donc disposer d’une modélisation plus riche.\n\n\n\n\n\n\n\n\n\n\nLicence\n\n\n\nCette œuvre est mise à disposition selon les termes de la Licence Creative Commons Attribution 4.0 International.\n\n\n\n\n\n\n\n\nRemerciements\n\n\n\nNous remercions Francesco Pirri et Pablo Vallier pour leur travail durant un stage à l’OFCE pendant l’été 2022 et une trop courte période d’assistant de recherche. Tanguy Enez et Jeanne Devineau ont pris le relais de Pablo et Francesco et ont significativement contribué à leur tour. Les discussions et les travaux conduits avec David Miet, Lucas Pouvreau et Valentin Stuhfault de Villes Vivantes ont été particulièrement fructueux pour l’application à la Rochelle, en partie financée par l’agglomération de la Rochelle. Nous remercions également Florence Nassiet et Bernard Habbouche ainsi que leurs collègues des services de l’agglomération de la Rochelle dont les encouragements et les questionnements nous aurons guidé dans ce travail. L’ensemble des calculs a été réalisé sur nuvolos.cloud dont le support technique s’est avéré indispensable. Tout le reste, et en particulier les erreurs, sont de notre fait.\n\n\n\n\n\n\n\n\nCode, Shiny, Quarto\n\n\n\nLe code utile, principalement en C++, pour les calculs est regroupé dans un package R{rmeaps} accessible dans un dépôt public github.com/maxime2506/rmeaps.\nUne application shiny permet de reproduire les simulations synthétiques, accessible à ofce.shinyapps.io/rmeaps dont le code se trouve dans le dépôt github github.com/xtimbeau/meaps.\nCes documents ont été produits avec Quarto. Le document « Aspects théoriques » ne demande rien de plus pour être exécutée qu’un environnement supportant Quarto. La partie Simulations synthétiques est exécutable complètement à partir des fichiers présent dans le dossier R du dépôt github github.com/xtimbeau/meaps. Le document « Estimation à la Rochelle » est exécutable en partie, la partie infracommunale nécessitant l’accès à des données spécifiques pour lesquelles nous étudions la possibilité de diffusion. N’hésitez pas à contacter les auteurs sur ce point.\nNous utilisons de nombreux packages et logiciels libres dont tidyverse, data.table, matrixStats, R5, r5r, Rcpp, OpenMP, quarto, shiny, shinyWidgets, shinydashboard, future, furrr et bien sûr R et RStudio de Posit.\n\n\nContacts : maxime.parodi@sciencespo.fr ou xavier.timbeau@sciencespo.fr\n\n\n\n\nParodi, M. & Timbeau, X. (2023), « MEAPS : modéliser les flux de navetteurs », Document de travail de l’OFCE, n°11-2023.\n\n\nParodi, M. & Timbeau, X. (2024a), « La ville compacte : une solution pour réduire les émissions de gaz à effet de serre ? », Document de travail de l’OFCE, n°5-2024.\n\n\nParodi, M. & Timbeau, X. (2024b), « MEAPS&Gravitaire : Estimations à la Rochelle », Document de travail de l’OFCE, n°4-2024.\n\n\nSimini, F., González, M.C., Maritan, A. & Barabási, A.-L. (2012), « A universal model for mobility and migration patterns », Nature, vol. 484, n°7392, pp. 96‑100. https://doi.org/10.1038/nature10856\n\n\nStouffer, S.A. (1940), « Intervening Opportunities: A Theory Relating Mobility and Distance », American Sociological Review, vol. 5, n°6, pp. 845. https://doi.org/10.2307/2084520"
  },
  {
    "objectID": "trajets.html",
    "href": "trajets.html",
    "title": "La Ville Compacte, une solution aux émissions de gaz à effet de serre",
    "section": "",
    "text": "Réduire les émissions de gaz à effet de serre est aujourd’hui un objectif central des politiques publiques. Or, un tel objectif ne peut être atteint sans agir à différents niveaux et dans de nombreux domaines. Notamment, il ne va pas suffire de remplacer, au sein de notre système de production d’énergie, les sources fossiles par des sources renouvelables. Il faut aussi développer une stratégie de sobriété énergétique, de manière à réduire le coût de la bascule vers des énergies propres, à limiter l’empreinte environnementale liée à ces investissements dans le système énergétique actuel et, également, à éviter de produire de manière indirecte des émissions de gaz à effet de serre.\nL’un des principaux enjeux autour de la sobriété est lié à l’habitat et à la mobilité des individus : quels modèles urbains promouvoir pour éviter ou limiter les déplacements énergivores ? Le Groupe Intergouvernemental des Experts du Climat (Lwasa, S. et al., 2022 ; Seto et al., 2014) a ainsi réaffirmé que la ville compacte est un des grands leviers de la transition vers des sociétés neutres en carbone. Cette position s’inscrit dans un long débat aussi bien aux Etats-Unis, où les défenseurs de la ville compacte s’opposent à l’étalement urbain (Ewing (1997) vs Gordon & Richardson (1997); Newman & Kenworthy (1989a)), qu’en Europe (Jenks, Williams & Burton, 1996) ou en Chine (Pan, Shen & Zhang, 2009) pour ne citer que quelques exemples emblématiques.\nL’endroit où vivent les individus conditionne leurs émissions de gaz à effet de serre par deux canaux principaux : d’une part, les émissions liées au logement, au moment de sa construction puis celles induites par ses dépenses énergétiques, principalement le chauffage. D’autre part, la mobilité quotidienne pour accéder à l’emploi, à l’éducation et à toutes les aménités dont les ménages ont l’usage. On pourrait ajouter des liens plus difficiles à mettre en évidence entre le lieu de résidence et les comportements de consommation. Ainsi, l’effet « barbecue » ou « hypothèse de compensation » (Holden & Norland, 2005 ; Massot & Orfeuil, 2007 ; Muñiz, Calatayud & Dobaño, 2013 ; Orfeuil & Soleyret, 2002) voudrait que les ménages urbains se déplacent moins la semaine mais ont un besoin de nature ou un besoin de fuir la ville qui les conduit à faire plus de déplacements de loisirs les week-ends ou pendant les vacances. Une fois contrôlé des plus importantes variables socio-économiques, un ménage urbain prend effectivement plus souvent l’avion pour les vacances et, plus marginalement, effectue des déplacements plus longs le week-end qu’un ménage vivant à la campagne. Toutefois, les citadins n’effectuent pas ces déplacements pour satisfaire un besoin de nature ou pour fuir la ville, puisque les destinations sont souvent d’autres villes (Munafò, 2017). La mobilité occasionnelle des citadins doit plus s’interpréter comme la traduction de leurs goûts pour les expériences diverses, contrastées et cosmopolitiques, qui expliquent leur désir de vivre dans des centres urbains. Il reste que la hausse des kilomètres attribuables à cet effet « barbecue » est marginal (un facteur 10) en regard de la différence de kilomètres parcourus entre un ménage urbain et un ménage rural. Il faudrait également tenir compte du cas d’un ménage s’éloignant de l’emploi mais qui compense en télétravaillant. Pour l’heure, il est encore difficile de dresser un réel bilan kilométrique de ces cas (Cervero, 1989 ; Orfeuil & Soleyret, 2002).\nLes postes « mobilité » et « logement » couvrent plus de 50% de l’empreinte carbone des ménages. Selon le SDES (Baude, 2022), la mobilité représentait 30% de l’empreinte carbone d’un français en 2017. L’empreinte carbone inclue les émissions directes et indirectes et s’élevait en 2017 à 9,5 tCO2eq/an par habitant en France. Les émissions liées au logement représentent 23% de l’empreinte totale. L’empreinte carbone de la mobilité se décompose en 60% (18% de l’empreinte totale) d’émissions directes par la combustion de fossiles, 19% (5,7% de l’empreinte) pour la construction et l’entretien des véhicules. Le transport aérien compte pour 10% (6% de l’empreinte). La part restante (11% et 6,6% de l’empreinte) est liée aux services de transport directs ou indirects que les ménages consomment (Baude, 2022, pp. 16).\nL’enjeu est donc clair et les leviers sont nombreux (Hsu et al., 2023). Pour les consommations résidentielles : une plus grande efficacité thermique des bâtiments, des températures cibles plus basses l’hiver, un moindre recours à la climatisation l’été et une moindre utilisation de l’eau chaude. Pour la construction des bâtiments : la décarbonation de la construction, des normes d’efficacité énergétique pour les nouveaux bâtiments, une limitation des constructions nouvelles, l’utilisation du bâti existant ou le partage du bâti existant en réduisant l’espace alloué par personne ou en multipliant les usages d’un local au cours d’un cycle. Pour les mobilités : l’électrification des véhicules, la hausse de l’occupation moyenne des véhicules (covoiturage, transport en commun), le passage à des mobilités douces (vélo ou marche) et, enfin, la réduction des distances parcourues, soit par la baisse de la fréquence des trajets, soit par le raccourcissement des trajets en habitant plus près des emplois et services.\nLe modèle de la ville compacte (Jenks, Williams & Burton, 2003) paraît répondre à chacun de ces enjeux en combinant l’utilisation de nombreux leviers. En regroupant activités et résidents, la forme urbaine réduit a priori les distances, fournit les services et les activités dans un voisinage accessible sans voiture, permet des transports en commun rentables et denses et réduit de nombreux coûts (entretien des routes et des réseaux en tout genre, services de livraison, gestion des déchets, etc.). Toutefois, ce modèle urbain a ses adversaires, qui interprètent celle-ci sous des formes repoussantes (tours gigantesques, espace privé minuscule, etc.) comme si la compacité ne pouvait se matérialiser que d’une unique façon. Depuis l’invention du terme (attribué à Dantzig, Dantzig & Saaty, 1973), la controverse entre un modèle de ville fondé sur l’usage de la voiture, dans lequel les gains de vitesse apporté par la technologie invitent à l’étalement, et un modèle organisé pour exclure la voiture des mobilités quotidiennes est vive.\nCette controverse a, au cours des 50 dernières années, pris plusieurs formes. La notion de ville fonctionnelle (dans la lignée de Janes Jacob (Jacobs, 1961) et contre Le Corbusier) a trouvé dans le New Urbanism un argument fondé sur les préférences des individus et le développement organique des villes, poussé par les besoins des habitants. L’étalement urbain serait alors une manifestation d’un désir d’être entre-soi de certains groupes sociaux : ainsi des riches évitant les pauvres et des blancs fuyant les noirs (Levine, 2010). La question climatique, par l’injonction à la sobriété, est un autre terrain d’affrontement entre ces deux visions radicales de la ville. Cet affrontement prend une nouvelle dimension en opposant non plus seulement étalement urbain et ville compacte, mais aussi ville compacte et mode de vie sobre avec une faible division du travail et une grande autonomie – parfois appelé décroissance ou post-croissance urbaine (Savini, Ferreira & von Schönfeld, 2022).\nOutre la question climatique, l’usage la voiture, notamment thermique, au sein des villes apporte son lot de problèmes : pollution de l’air, congestion, accidents de la route, qui tous impactent négativement la santé humaine. Dans un contexte de hausse des coûts relatifs de l’énergie à court et à long terme, les mobilité quotidiennes et la consommation d’énergie résidentielle exercent une contrainte de plus en plus importantes sur les budgets des ménages. La répartition spatiale étant conditionnée notamment par les prix de l’immobilier, les choix de localisation peuvent être fait sans pouvoir anticiper correctement les évolutions des coûts futurs et induire un enfermement de certaines populations, souvent modestes, dans des zones excentrées qui finiront par entraîner des coûts de transport difficilement soutenables. La facilité d’accès à l’emploi et à d’autres aménités en fonction de son lieu de résidence –- que l’on peut mesurer par l’accessibilité –- détermine les pratiques de mobilités des résidents : les modes de transport possibles, les coûts de chaque trajets, l’activité physique induite, ou encore la possibilité pour des individus ne pouvant pas conduire (comme les plus jeunes) d’accéder aux aménités de manière autonome.\nL’argument environnemental pour les villes compactes repose sur une empreinte carbone plus faible pour des déplacements plus courts et plus doux que dans le cas de l’étalement urbain ou dans le cas d’une mégalopole où les distances s’allongent malgré une densité importante. Dans ce débat, une littérature assez récente (depuis les années 2000) a versé un grand nombre d’arguments empiriques en utilisant les données de grandes enquêtes auprès des ménages sur les mobilités. Il en ressort un diagnostic mitigé : une plus grande densité est bien associée à de moindres déplacements, mais cette conclusion est fragile en raisons de nombreuses difficultés méthodologiques (liées à l’endogénéité des variables et à des biais de sélection). Plus encore, l’effet identifié semble faible – une élasticité de -0,1 entre densité et nombre de kilomètres parcourus – au point qu’il est illusoire de compter sur la hausse de la densité pour réduire les émissions Duranton & Turner (2018).\nNous présentons dans la section suivante cette littérature, les principaux résultats ainsi qu’une analyse critique des méthodes qui conduisent au résultat principal. Nous présenterons ensuite une approche alternative, s’attachant à mieux définir la notion de densité et surtout à préciser ce qu’augmenter la densité veut dire, pour montrer qu’il s’agit bien d’une levier efficace pour réduire les émissions liées à la mobilité, conformément à l’intuition initiale de Newman et Kenworthy."
  },
  {
    "objectID": "trajets.html#limpératif-dun-habitat-sobre",
    "href": "trajets.html#limpératif-dun-habitat-sobre",
    "title": "La Ville Compacte, une solution aux émissions de gaz à effet de serre",
    "section": "",
    "text": "Réduire les émissions de gaz à effet de serre est aujourd’hui un objectif central des politiques publiques. Or, un tel objectif ne peut être atteint sans agir à différents niveaux et dans de nombreux domaines. Notamment, il ne va pas suffire de remplacer, au sein de notre système de production d’énergie, les sources fossiles par des sources renouvelables. Il faut aussi développer une stratégie de sobriété énergétique, de manière à réduire le coût de la bascule vers des énergies propres, à limiter l’empreinte environnementale liée à ces investissements dans le système énergétique actuel et, également, à éviter de produire de manière indirecte des émissions de gaz à effet de serre.\nL’un des principaux enjeux autour de la sobriété est lié à l’habitat et à la mobilité des individus : quels modèles urbains promouvoir pour éviter ou limiter les déplacements énergivores ? Le Groupe Intergouvernemental des Experts du Climat (Lwasa, S. et al., 2022 ; Seto et al., 2014) a ainsi réaffirmé que la ville compacte est un des grands leviers de la transition vers des sociétés neutres en carbone. Cette position s’inscrit dans un long débat aussi bien aux Etats-Unis, où les défenseurs de la ville compacte s’opposent à l’étalement urbain (Ewing (1997) vs Gordon & Richardson (1997); Newman & Kenworthy (1989a)), qu’en Europe (Jenks, Williams & Burton, 1996) ou en Chine (Pan, Shen & Zhang, 2009) pour ne citer que quelques exemples emblématiques.\nL’endroit où vivent les individus conditionne leurs émissions de gaz à effet de serre par deux canaux principaux : d’une part, les émissions liées au logement, au moment de sa construction puis celles induites par ses dépenses énergétiques, principalement le chauffage. D’autre part, la mobilité quotidienne pour accéder à l’emploi, à l’éducation et à toutes les aménités dont les ménages ont l’usage. On pourrait ajouter des liens plus difficiles à mettre en évidence entre le lieu de résidence et les comportements de consommation. Ainsi, l’effet « barbecue » ou « hypothèse de compensation » (Holden & Norland, 2005 ; Massot & Orfeuil, 2007 ; Muñiz, Calatayud & Dobaño, 2013 ; Orfeuil & Soleyret, 2002) voudrait que les ménages urbains se déplacent moins la semaine mais ont un besoin de nature ou un besoin de fuir la ville qui les conduit à faire plus de déplacements de loisirs les week-ends ou pendant les vacances. Une fois contrôlé des plus importantes variables socio-économiques, un ménage urbain prend effectivement plus souvent l’avion pour les vacances et, plus marginalement, effectue des déplacements plus longs le week-end qu’un ménage vivant à la campagne. Toutefois, les citadins n’effectuent pas ces déplacements pour satisfaire un besoin de nature ou pour fuir la ville, puisque les destinations sont souvent d’autres villes (Munafò, 2017). La mobilité occasionnelle des citadins doit plus s’interpréter comme la traduction de leurs goûts pour les expériences diverses, contrastées et cosmopolitiques, qui expliquent leur désir de vivre dans des centres urbains. Il reste que la hausse des kilomètres attribuables à cet effet « barbecue » est marginal (un facteur 10) en regard de la différence de kilomètres parcourus entre un ménage urbain et un ménage rural. Il faudrait également tenir compte du cas d’un ménage s’éloignant de l’emploi mais qui compense en télétravaillant. Pour l’heure, il est encore difficile de dresser un réel bilan kilométrique de ces cas (Cervero, 1989 ; Orfeuil & Soleyret, 2002).\nLes postes « mobilité » et « logement » couvrent plus de 50% de l’empreinte carbone des ménages. Selon le SDES (Baude, 2022), la mobilité représentait 30% de l’empreinte carbone d’un français en 2017. L’empreinte carbone inclue les émissions directes et indirectes et s’élevait en 2017 à 9,5 tCO2eq/an par habitant en France. Les émissions liées au logement représentent 23% de l’empreinte totale. L’empreinte carbone de la mobilité se décompose en 60% (18% de l’empreinte totale) d’émissions directes par la combustion de fossiles, 19% (5,7% de l’empreinte) pour la construction et l’entretien des véhicules. Le transport aérien compte pour 10% (6% de l’empreinte). La part restante (11% et 6,6% de l’empreinte) est liée aux services de transport directs ou indirects que les ménages consomment (Baude, 2022, pp. 16).\nL’enjeu est donc clair et les leviers sont nombreux (Hsu et al., 2023). Pour les consommations résidentielles : une plus grande efficacité thermique des bâtiments, des températures cibles plus basses l’hiver, un moindre recours à la climatisation l’été et une moindre utilisation de l’eau chaude. Pour la construction des bâtiments : la décarbonation de la construction, des normes d’efficacité énergétique pour les nouveaux bâtiments, une limitation des constructions nouvelles, l’utilisation du bâti existant ou le partage du bâti existant en réduisant l’espace alloué par personne ou en multipliant les usages d’un local au cours d’un cycle. Pour les mobilités : l’électrification des véhicules, la hausse de l’occupation moyenne des véhicules (covoiturage, transport en commun), le passage à des mobilités douces (vélo ou marche) et, enfin, la réduction des distances parcourues, soit par la baisse de la fréquence des trajets, soit par le raccourcissement des trajets en habitant plus près des emplois et services.\nLe modèle de la ville compacte (Jenks, Williams & Burton, 2003) paraît répondre à chacun de ces enjeux en combinant l’utilisation de nombreux leviers. En regroupant activités et résidents, la forme urbaine réduit a priori les distances, fournit les services et les activités dans un voisinage accessible sans voiture, permet des transports en commun rentables et denses et réduit de nombreux coûts (entretien des routes et des réseaux en tout genre, services de livraison, gestion des déchets, etc.). Toutefois, ce modèle urbain a ses adversaires, qui interprètent celle-ci sous des formes repoussantes (tours gigantesques, espace privé minuscule, etc.) comme si la compacité ne pouvait se matérialiser que d’une unique façon. Depuis l’invention du terme (attribué à Dantzig, Dantzig & Saaty, 1973), la controverse entre un modèle de ville fondé sur l’usage de la voiture, dans lequel les gains de vitesse apporté par la technologie invitent à l’étalement, et un modèle organisé pour exclure la voiture des mobilités quotidiennes est vive.\nCette controverse a, au cours des 50 dernières années, pris plusieurs formes. La notion de ville fonctionnelle (dans la lignée de Janes Jacob (Jacobs, 1961) et contre Le Corbusier) a trouvé dans le New Urbanism un argument fondé sur les préférences des individus et le développement organique des villes, poussé par les besoins des habitants. L’étalement urbain serait alors une manifestation d’un désir d’être entre-soi de certains groupes sociaux : ainsi des riches évitant les pauvres et des blancs fuyant les noirs (Levine, 2010). La question climatique, par l’injonction à la sobriété, est un autre terrain d’affrontement entre ces deux visions radicales de la ville. Cet affrontement prend une nouvelle dimension en opposant non plus seulement étalement urbain et ville compacte, mais aussi ville compacte et mode de vie sobre avec une faible division du travail et une grande autonomie – parfois appelé décroissance ou post-croissance urbaine (Savini, Ferreira & von Schönfeld, 2022).\nOutre la question climatique, l’usage la voiture, notamment thermique, au sein des villes apporte son lot de problèmes : pollution de l’air, congestion, accidents de la route, qui tous impactent négativement la santé humaine. Dans un contexte de hausse des coûts relatifs de l’énergie à court et à long terme, les mobilité quotidiennes et la consommation d’énergie résidentielle exercent une contrainte de plus en plus importantes sur les budgets des ménages. La répartition spatiale étant conditionnée notamment par les prix de l’immobilier, les choix de localisation peuvent être fait sans pouvoir anticiper correctement les évolutions des coûts futurs et induire un enfermement de certaines populations, souvent modestes, dans des zones excentrées qui finiront par entraîner des coûts de transport difficilement soutenables. La facilité d’accès à l’emploi et à d’autres aménités en fonction de son lieu de résidence –- que l’on peut mesurer par l’accessibilité –- détermine les pratiques de mobilités des résidents : les modes de transport possibles, les coûts de chaque trajets, l’activité physique induite, ou encore la possibilité pour des individus ne pouvant pas conduire (comme les plus jeunes) d’accéder aux aménités de manière autonome.\nL’argument environnemental pour les villes compactes repose sur une empreinte carbone plus faible pour des déplacements plus courts et plus doux que dans le cas de l’étalement urbain ou dans le cas d’une mégalopole où les distances s’allongent malgré une densité importante. Dans ce débat, une littérature assez récente (depuis les années 2000) a versé un grand nombre d’arguments empiriques en utilisant les données de grandes enquêtes auprès des ménages sur les mobilités. Il en ressort un diagnostic mitigé : une plus grande densité est bien associée à de moindres déplacements, mais cette conclusion est fragile en raisons de nombreuses difficultés méthodologiques (liées à l’endogénéité des variables et à des biais de sélection). Plus encore, l’effet identifié semble faible – une élasticité de -0,1 entre densité et nombre de kilomètres parcourus – au point qu’il est illusoire de compter sur la hausse de la densité pour réduire les émissions Duranton & Turner (2018).\nNous présentons dans la section suivante cette littérature, les principaux résultats ainsi qu’une analyse critique des méthodes qui conduisent au résultat principal. Nous présenterons ensuite une approche alternative, s’attachant à mieux définir la notion de densité et surtout à préciser ce qu’augmenter la densité veut dire, pour montrer qu’il s’agit bien d’une levier efficace pour réduire les émissions liées à la mobilité, conformément à l’intuition initiale de Newman et Kenworthy."
  },
  {
    "objectID": "trajets.html#sec-densemis",
    "href": "trajets.html#sec-densemis",
    "title": "La Ville Compacte, une solution aux émissions de gaz à effet de serre",
    "section": "2 Une densité plus élevée fait-elle baisser les émissions ?",
    "text": "2 Une densité plus élevée fait-elle baisser les émissions ?\nLe lien entre la géographie, la forme urbaine et les mobilités résidentielles a donné lieu à un débat nourri, vieux de quelques décennies et persistant. Tout le monde a en tête les travaux et le graphique de Newman et Kenworthy (graphique 1) (Newman & Kenworthy, 1989a, 1989b, 1999) représentant une corrélation négative entre consommation d’énergie annuelle de carburant et densité, qui a confortée l’intuition que les villes compactes sont plus soutenables que les villes « étalées ». Le graphique de (Newman & Kenworthy, 1999) a été largement critiqué et la corrélation affichée sur le graphique a été jugée en partie fallacieuse du fait de nombreux facteurs, dont le niveau de développement de chacune des villes considérées, le prix local du carburant ou d’autres facteurs explicatifs communs (Ewing et al., 2017). En 2015, Ewing & Hamidi (2015) recensaient plus de 200 études empiriques et 12 revues de littérature sur ce sujet. Plusieurs éléments à la fois théoriques, méthodologiques et empiriques ont été raffinés et conduisent à un résultat pour le moins mitigé selon lequel l’influence de la densité ou d’autres dimensions de la forme urbaine sur les consommations de carburant seraient trop petits pour jouer un rôle prépondérant dans la réduction des émissions de gaz à effet de serre.\n\n\n\nGraphique 1. Lien entre densité moyenne et consommation de carburant par villes (Newman&Kenworthy 1989)\n\n\n\n\n\n\nAinsi, l’affirmation initiale s’est trouvé « anesthésiée » et il faudrait croire que le lien entre densité et empreinte carbone est trop faible pour justifier une politique urbaine. Une telle anesthésie a été possible parce que la densité est plutôt un mauvais indicateur de la forme urbaine ; c’est un indicateur équivoque. Les critiques méthodologiques de l’article de Newman et Kentworthy sont certes justifiées, mais leur intuition exige un examen qui ne se limite pas à redéfinir la mesure de la densité urbaine. Par exemple, des quantification centrées sur l’accessibilité à l’emploi ont un meilleur pouvoir explicatif. Mais, plus encore, il faudrait surtout démêler deux questions : celle de savoir si toute densification, en général, entraîne nécessairement une réduction des émissions – la question qui a monopolisé l’attention – et celle de savoir quels scénarios de densification apportent un niveau de réduction suffisant pour justifier une politique publique.\n\n2.1 Quantifier la forme urbaine\nLa densité de population, l’indicateur retenu par Newman & Kenworthy (1989a), ne suffit pas à décrire la forme et la structure des villes. La même distribution spatiale de la densité peut cacher des formes urbaines très diverses. Depuis Cervero & Kockelman (1997), les indicateurs complémentaires à la densité ont été catalogué et sont généralement appelés les D. Aux 3 D initialement proposés par Cervero et Kockelman, pour Densité, Diversité et Design, ont été ajouté d’autres D comme la distance au centre des emplois (Central Business District) ou la distance aux transports en commun (le plus proche, un indicateur de connectivité, etc…). Une plus grande densité devrait induire moins de kilomètres parcourus par résident, du moins si l’on mesure la densité à la bonne échelle, de manière à rendre compte de la proximité des centres d’intérêt des résidents.\nLe terme « densité » recouvre ainsi différentes notions : la densité peut être celle des habitants, des logements, des bâtiments ou de la surface habitable. Elle peut être calculée à différentes échelles et éventuellement lissée, conduisant à des résultats sensiblement différents puisque les tissus urbain sont toujours très hétérogènes sur un territoire donné. La façon la plus immédiate de calculer la densité est de prendre le ratio entre le nombre d’habitants et la surface bâtie, pour une zone donnée, mais il est également possible de calculer la densité moyenne en pondérant la densité sur une maille (régulière ou non) par le nombre d’habitants résidents dans cette maille. Cette densité pondérée par la population (PWD), parfois appelée « densité articulée », rend mieux compte de la densité moyenne ressentie par les résidents. Par exemple, la densité moyenne simple de New York dans son ensemble est plus faible que celle de Los Angeles alors que la densité pondérée par la population met New York au dessus de Los Angeles en termes de densité, puisque les résidents de Manhattan sont nombreux a percevoir que la densité de Manhattan est forte.\nLe deuxième D –- la diversité –- cherche à tenir compte de la spécialisation de l’environnement urbain. Dans beaucoup de villes américaines, du fait d’une politique persistante de zonage peu pratiquée en Europe (Hirt, 2012), les espaces sont spécialisés, en particulier entre zones de résidences et de commerce ou d’activité économique. La diversité, mesurée par exemple par (l’opposé d’) un indice de Herfindahl, permet de rendre compte de l’imbrication des services ou des opportunités d’emplois avec les lieux de résidence. Là encore, l’échelle de prise en compte de la diversité est un point important et, à nouveau, l’imbrication peut être pondérée pour mieux rendre compte des perceptions. Tout comme pour la densité, on s’attendrait à ce qu’une plus grande diversité soit associée à moins de kilomètres parcourus.\nLe troisième D –- le design –- fait référence à la configuration des rues, des routes ou du réseau de transport. Une configuration de routes peu denses, composé d’axes traversant continus et à fort débit est peu propice à la marche. Un réseau de ruelles entourant des blocs de bâtiments plus petits permet au contraire une circulation capillaire. La mesure du design passe par des indicateurs variés comme le nombre d’intersection, la taille des blocs. Alternativement, (blaudindethé?) utilisent la dimension fractale des bâtiments1.\n1 La dimension fractale est définie comme la pente du ratio entre le nombre de bâtiments et le nombre de pavés lorsque la taille du pavage varie et tend vers 0 (éventuellement en log).La distance au centre des emplois (CBD) est une mesure assez simple dès lors qu’on peut identifier facilement le centre de l’emploi. Malheureusement, le modèle monocentrique qui justifierait cette mesure décrit très mal la plupart des villes et elle est très insatisfaisante dans le cas général. Malgré cela, le nombre de kilomètres voyageurs (VKT) est corrélé fortement à ce type de mesure (voir plus bas).\nLa distance aux transports en commun est également simple conceptuellement. On retient généralement la distance au plus proche arrêt de transport en commun ou le nombre d’arrêt dans un périmètre donné (par exemple 10 minutes de marche). C’est toutefois un indicateur assez frustre puisqu’il ne suffit pas de résider près d’une station de métro ou d’un arrêt de bus, il faut encore que le transport desserve les bonnes destinations aux bons moments. Ceci dit, cette mesure est renseignée dans les enquêtes de mobilité (comme l’Enquête Mobilité Certifiée CEREMA, EMC2) et elle peut être intéressante une fois associée aux données sur les réseaux de transports (de type GTFS).\nEn décrivant la forme urbaine par ces grandeurs, on dispose d’indicateurs qui sont principalement locaux et associés à l’endroit de résidence. Ils peuvent être calculés à différentes échelles, comme dans l’analyse multiniveaux de Lee & Lee (2020), mais aucun de ces indicateurs n’éclaire réellement la capacité systémique des infrastructures d’une ville à relier les résidents à leurs lieux d’intérêt, emplois ou aménités.\n\n\n2.2 Endogénéité et autosélection des résidents\nBien qu’il soit délicat de tirer une conclusion simple et univoque du large panel d’analyses sur le lien entre densité et émissions, des mesures de la forme urbaine comme la densité d’habitants ou d’emploi, parfois des mesures plus complexes comme la dimension fractale du bâti (blaudindethé?), la diversité locale de l’emploi, des indicateurs de centralité, de connectivité ou de continuité (Ewing & Hamidi, 2015) sont corrélées négativement avec le nombre de kilomètres-voyageurs (abrégé en VKT pour Vehicule Kilometers Traveled ou Vehicule Miles Traveled dans la littérature en langue anglaise).\nL’évaluation du lien causal demeure délicate en raison de possibles biais de sélection des résidents : dans quelle mesure les ménages qui de moindres revenus et se trouvent contraints à des déplacements plus courts et non motorisés habitent-ils des zones plus denses et des logements plus petits et plus proches du centre-ville ? Ou encore, les individus effectuent-ils de longs trajets en voiture parce qu’ils habitent loin ou, à l’inverse, est-ce qu’ils résident loin parce qu’ils aiment faire de la voiture ? Autant de questions qui fragilisent l’établissement d’un lien causal entre densité et VKT. En général, dans ces études, la corrélation est considérée en partie comme causale mais faible. (Duranton & Turner, 2018) concluent ainsi pour les Etats-Unis à une élasticité de l’ordre de -0.1 entre densité et kilomètres parcourus. (Holian, 2020) dans la suite de (Grazi, Bergh & Ommeren, 2008) utilise une variable instrumentale astucieuse (le fait d’avoir des enfants de même sexe permet de les loger dans une même chambre et offre à ces ménages plus de choix résidentiel sans lien avec leurs préférences de déplacement) et concluent à une élasticité proche de celles rapportées dans la littérature, à ceci près qu’ils mesurent un effet local moyen sans pouvoir séparer des contextes urbains très différents. On retiendra toutefois que le biais d’endogénéité qu’ils identifient reste assez faible.\nLe tableau suivant (tableau 1) est extrait de la méta-analyse de (Stevens, 2017) qui synthétise la littérature en essayant de prendre en compte la diversité des mesures possibles pour calculer des élasticités comparables. L’autosélection des individus, c’est-à-dire le fait que les ménages sont triés spatialement en fonction de leurs préférences et de leurs revenus, se traduit par une élasticité des kilomètres-voyageurs à la distance au centre-ville ou à la densité plutôt supérieure lorsqu’elle est prise en compte. L’élasticité à la densité de population est plutôt faible bien que supérieure à celle de Duranton & Turner (2018).\nAu vu des résultats reportés dans ce tableau, il est peu vraisemblable que la hausse de la densité puisse réduire significativement les émissions de gaz à effet de serre, puisque son élasticité est au mieux de -0.22 et qu’il faudrait une multiplication par 2.5 de la densité de population pour réduire les kilomètres-voyageurs de 50%.\n\n\n\nTableau 1. Méta-analyse de Stevens (2017) pour les km-voyageurs\n\n\n\n\n\n\n\n\n\n\nVariable mesurée (D)\nElasticité des km-voyageurs (VKT) à D\navec/sans autosélection\nN études avec/sans autosélection\n\n\n\n\nDistance au centre-ville (CBD, downtown, centre géographique, barycentre de l’emploi, des habitants)\n-0.63/-0.34\n3/14\n\n\nDensité de population ou de ménages\n-0.22/-0.10\n5/19\n\n\nAccessibilité à l’emploi en voiture\n-0.20\n0/10\n\n\nDensité des intersections ou des rues\n-0.14\n1/15\n\n\nMélange des usages (diversité)\n0.11/-0.033\n2/15\n\n\nDensité des emplois\n-0.07/-0.01\n2/11\n\n\n% d’intersections entre 4 voies\n-0.06\n1/4\n\n\nDistance à l’arrêt de transport en commun le plus proche\n-0.05\n5AR/12\n\n\nAccessibilité aux emplois par les transports en commun\n0.00 (ns)\n0/3\n\n\nDéséquilibre entre les emplois et les résidents\n0.00 (ns)\n0/8\n\n\n\n\n\n\nUne première conclusion tirée des analyses empiriques est donc qu’il existe un effet des variables quantifiant la forme urbaine et que le signe de cet effet est généralement tel qu’attendu. Une forme urbaine plus compacte induit moins de kilomètres-voyageurs parcourus. La prise en compte de l’autosélection et l’utilisation de variables instrumentales peuvent modifier les estimations des élasticités, mais les modifications sont petites et n’invalident pas la première conclusion.\nLa seconde conclusion importante est que plusieurs facteurs jouent et qu’il faut probablement les combiner pour arriver à une réduction significative des émissions de gaz à effet de serre. Cette conclusion est sans doute un peu décevante et intègre le fait que l’étalement urbain n’est pas inéluctablement un facteur d’augmentation des émissions. Les études empiriques ne parviennent pas à un résultat tranché parce que la diversité des situations observées est grande. Sur le plan théorique on peut également imaginer que des effets d’équilibre général jouent un rôle important. Les individus peuvent vivre dans des zones peu denses mais avoir un accès à des centres d’emplois à des distances raisonnables. Les concentrer dans des pôles urbains peut accroître les mouvements pendulaires. (Gaigné, Riou & Thisse, 2012) développent un modèle avec plusieurs centre d’emploi et montrent que la concentration n’a pas toujours l’effet attendu de réduire les kilomètres si on n’assigne pas les individus à aller au plus proche. Par ailleurs, la bi-activité des ménages peut rendre impossible l’optimisation des distances à moins de proposer une très forte concentration des résidences et des emplois au même endroit.\nLa troisième conclusion que l’on peut tirer de ces analyses est que la quantification de l’étalement urbain ou de son opposé, la compacité urbaine, est un exercice difficile et qui n’a pas été conduit à son terme. Il s’agit de relier d’une part la distribution spatiale des habitants, de l’autre celle des emplois et des différents services comme les écoles ou les commerces de proximité, de prendre en compte les possibilités de transport offertes en chaque point du territoire tout en intégrant d’autres contraintes comme la congestion des transports, les conséquences pour la santé, les îlots de chaleurs, et ainsi de suite. Or cette complexité ne peut pas se résumer à quelques indicateurs agrégés ou strictement localisés. Et, pour les mêmes raisons, les politiques publiques ne peuvent pas se concevoir ou s’évaluer uniquement à travers un prisme qui écraserait toute l’information nécessaire pour retranscrire la réalité d’une géographie urbaine donnée.\nComme le notent de nombreux auteurs Stevens (2017), la distance au centre des emplois (CBD) joue un rôle plus important que d’autres facteurs2. Toutefois, cette notion est d’un intérêt limité Elle est pertinente pour les formes urbaines monocentriques ou encore lorsque la concentration spatiale de l’emploi est importante, mais elle devient trompeuse lorsque les formes urbaines sont plus complexes et, plus encore, pour des zones urbaines de grande taille. Prenons le cas de l’agglomération parisienne, où pourtant l’hypercentre joue un rôle éminent. On ne peut pas considérer que l’emploi est particulièrement concentré sur l’Île de la Cité ou l’Île Saint Louis. L’emploi est diffus sur une large zone, avec des zones plus concentrées comme la rive droite (Opéra, Havre-Caumartin, Champ-Elysées), la Défense ou encore Saint-Denis. Plus encore, cette concentration est toute relative et il y a de l’emploi un peu partout, que ce soit des emplois liés à la présence de résidents ou liés à des équipements non centraux (un hôpital, une université, un pôle administratif privé ou public, une zone commerciale, etc…).\n2 Il est délicat de comparer les élasticités de variables aussi disparates que la densité et la distance au centre. Dans le cas d’une densité uniforme de population sur une cercle de rayon r, la densité (N/{\\pi r^2}) et la distance moyenne au centre du cercle (\\pi r^2) sont inversement proportionnelles. Dans ce cas, il est simple de passer d’une élasticité à l’autre et, donc, de les comparer. Mais si l’on prend une densité gaussienne, le ratio entre la densité et la distance moyenne pondérée par la population est proportionnel au paramètre de dispersion de la densité (\\sigma). Il est alors facile de construire, avec des distributions plus ou moins concentrées, pour une même densité, une grande palette de distances moyennes. La comparaison des élasticités n’est plus lisible et dépend d’un autre paramètre.D’après FLORES (INSEE), en 2021, les 9 arrondissements à 1 chiffre concentrent un peu plus de 800 000 emplois salariés sur les 4,26 millions que compte la région Ile-de-France. L’emploi salarié dans les arrondissements centraux représente 19% de l’emploi de la région pour moins d’1% de la surface. Il y a indéniablement concentration spatiale. Pour autant, plus de 80% des emplois salariés sont à l’extérieur de ce petit noyau central. Ce qui est vrai pour Paris l’est pour toute grande agglomération, de Tokyo à Los Angeles, et fait du modèle monocentrique une approximation grossière, qui n’est pertinente que pour quelques agglomérations de petite taille et de structure spécifique.\nNe pas pouvoir prendre en compte la répartition spatiale de l’emploi et des activités dans toutes les dimensions est également un frein à une analyse des politiques publiques dont l’objet est souvent le développement de telle ou telle zone, pour des raisons diverses allant de la stratégie d’aménagement générale de la zone urbaine, de son articulation avec les réseaux de transport, à la réhabilitation de terrains, selon leur disponibilité ou leur prix. La décision publique ne se limite pas à plus de densité en général et il faut que l’analyse s’appuie sur ce qui compte localement."
  },
  {
    "objectID": "trajets.html#pourquoi-et-comment-projeter",
    "href": "trajets.html#pourquoi-et-comment-projeter",
    "title": "La Ville Compacte, une solution aux émissions de gaz à effet de serre",
    "section": "3 Pourquoi et comment projeter ?",
    "text": "3 Pourquoi et comment projeter ?\n\n3.1 Pourquoi ?\nC’est à partir de la troisième conclusion (la difficulté de la quantification) que nous proposons une approche différente du lien entre densité et kilomètres parcourus. Au lieu de partir d’observations individuelles ou agrégées de mobilité, qui associent des déplacements à des informations sur la forme urbaine générale ou locale pour quantifier avec plus ou moins de bonheur un lien causal, nous proposons d’expliciter par une modélisation l’articulation entre les distributions spatiales des habitants, des emplois et des aménités, en tenant compte de la géographie et des infrastructures de transport.\nLa méthode s’apparente à celles recensées par (Rodier, 2009) dans lequel on utilise un modèle dit de « Land Use Transport Interaction » (LUTI) pour analyser sur une zone urbanisée les effets de modification de la forme urbaine, de changement dans les infrastructures, de changement de comportement ou de politiques diverses, comme la taxation de l’essence ou le péage urbain. Idéalement la modélisation est robuste c’est-à-dire que les différentes briques qui la composent sont soumis à une analyse de causalité et on suppose que le biais de modélisation (phénomènes omis, granularité temporelle ou spatiale de de la représentation) n’est pas trop fort.\nCette démarche est celle des sciences du climat et Masson et al. (2014) en discutent la validité pour l’analyse des villes et du changement climatique. Plus généralement, dès que l’on a affaire à des systèmes complexes (Thurner, Klimek & Hanel, 2018), on est confronté à une double difficulté : d’un côté, les causalités s’imbriquent et toute analyse empirique devient difficile voire impossible à moins que l’on dispose de sources de variations aléatoires qui ramènent à un cas quasi-expérimental. Lorsque c’est le cas, les expériences quasi naturelles observables doivent être suffisamment nombreuses pour produire des conclusions généralisables. De l’autre côté, il n’est pas assuré qu’un système complexe puisse être décrit par des relations simples entre quantités macroscopiques. Il existe quelques exemples de telles propriétés émergentes, sous des conditions de validité bien définies, comme la fameuse loi de Boyle-Mariotte . Mais, dans le cas général, un système complexe est toujours plus riche que la description macroscopique. Ces deux arguments se recoupent partiellement, l’approche par quasi expérience étant d’autant plus généralisable que des lois macroscopiques valides et pleine de signification émergent du système complexe.\nL’approche par modélisation, suivie de validation des briques par des (quasi-)expériences naturelles, des simulations numériques ou des analyses des propriétés, est alors une méthode pertinente poursuivie, entre autres, par (Batty, 2013 ; Bettencourt, 2021) ou encore dans les modèles LUTI. Le recours à des microfondations, décrivant plus en détail la complexité du système, n’est pas pour autant la garantie d’une meilleure compréhension, ni d’une représentation exempte de biais. La modélisation doit être parcimonieuse et ne pas se transformer en boîte noire. La simulation numérique rend difficile la compréhension de la modélisation surtout lorsque celle-ci se déploie dans des espaces numériques de grande dimension. De plus, la profondeur du modèle doit être fonction de la nature des données que l’on a à sa disposition. Un modèle qui repose sur une paramétrisation qui dépasse de loin la dimension des observations court le risque du surapprentissage, parce qu’il existe plus de paramètres à calibrer que d’observations indépendantes. Le surapprentissage peut donner le sentiment que l’on explique bien les observations, mais c’est au prix d’une impossibilité de généralisation, ce qui est précisément ce que l’on cherche à faire par la modélisation.\nLes briques de la modélisation structurelle que nous allons mettre en place sont multiples et s’inspirent de la construction du modèle à 4 étapes (Hensher & Button, 2007 ; Patrick Bonnel, 2001). Les quatre étapes sont : la génération du nombre de trajets en partance de chaque origine (les résidences), et des trajets qui arrivent à chaque destination (les emplois, les aménités). La deuxième étape distribue ces trajets sur l’ensemble des paires origine-destination. La troisième étape est celle du choix modal de chacun des trajets et la quatrième vise à déterminer le tracé du trajet, compte tenu de l’origine, de la destination et du mode de transport. Comme nous le verrons, l’articulation de ces briques se ramène en fait à un simple emboîtement de probabilités conditionnelles, ce qui souligne à la fois que cette modélisation est finalement plus simple qu’il n’y paraît et que le modèle à 4 étapes a probablement été développé à partir de l’intuition que chacune des étapes n’est qu’une étape de calcul de la probabilité de trajets, qui est la colonne vertébrale de la modélisation.\nNotre méthodologie, développée dans Parodi & Timbeau (2023), reprend cette approche. La première étape consiste à localiser les résidents (à partir des données carroyées de l’INSEE (2022a)), les emplois (à partir de (2022b) et des fichiers fonciers pour une imputation infra-communale). Nous calculons ensuite les distances et les temps de trajets pour les 4 modes considérés (marche, vélo, transport en commun, voiture, mais pas de trajets multimodaux hors ceux avec la marche à pied) – ce qui anticipe l’étape 4 – entre toutes les résidences (les origines) et tous les emplois (les destinations). Par analogie avec un modèle radiatif (Simini et al., 2012 ; Stouffer, 1940), MEAPS nous permet de répartir les flux de « navetteurs » et d’affecter à chaque résident une distribution de probabilité sur le lieu où il travaille sur la base des distances, du nombre de résidents et de la quantité d’emploi sur le territoire considéré. Ce modèle radiatif est augmenté d’un processus de saturation et de priorité (MEAPS) de façon à assurer de façon explicite et paramétrable que chaque résident occupe un emploi et un seul et que tous les emplois sont occupés. Nous avons montré dans Parodi & Timbeau (2023) que ce modèle permettait de mieux rendre compte des flux de navetteurs entre communes mesurés par MOBPRO que le modèle gravitaire par la prise en compte de la géographie des résidents, des emplois et des réseaux, du moins sur le territoire de La Rochelle.\nIl n’en reste pas moins que si Parodi & Timbeau (2023) permet de reproduire (2022b) et d’en proposer une interpolation à la maille du carreau INSPIRE à 200m, il faut utiliser plus d’informations pour déterminer la quantité globale de déplacements, c’est-à-dire le nombre de kilomètres parcourus annuellement par un résident moyen d’un carreau donné. L’approche par MEAPS ne donne en effet que le flux (ou une probabilité) de personnes d’une résidence vers un emploi, à une distance donnée, mais sans préciser la fréquence de ces déplacements. Cette information n’est pas dans (2022b) et rend approximatif la détermination des kilomètres parcourus sur cette seule base. Nous proposons ici une approche qui résout cette indétermination en modélisant le nombre de trajets et en introduisant des caractéristiques socio-économique des individus, ce qui permet d’ajouter une couche supplémentaire à l’analyse spatiale par MEAPS.\nPour ce faire, il faut examiner les pratiques de mobilité des Français. Nous nous appuyons ici sur l’enquête mobilité des personnes MOBPERS (2021) (EMP 2019). Cette enquête ne permet pas d’analyses locales, parce que l’échantillon est trop petit et le tirage aléatoire n’a pas été conçu pour un tel usage. Elle permet en revanche d’associer les caractéristiques des individus, de leur ménage, de leur équipement en véhicule aux trajets effectués pour différents motifs. Il est alors possible de modéliser leurs pratiques de mobilités selon ces caractéristiques. En associant la méthode MEAPS à cette analyse, on pourra alors évaluer au carreau les kilomètres parcourus par chaque résident et procéder à des agrégations à tous les niveaux souhaités en exploitant au maximum l’information contenue dans EMP 2019, dans (2022b), dans la localisation fine des résidents, selon leurs caractéristiques socio-économique et des emplois et dans la géographie des réseaux.\nLa modélisation retenue suppose que les réseaux, la position des habitants, des emplois ou des aménités est considérée comme exogène. Endogénéiser ces éléments, sous contrainte du respect des zonages et des règlements d’urbanisme, compliquerait exagérément la modélisation. Il faudrait introduire des dynamiques longues, celles de la localisation des habitants, de la construction de nouveaux logements, de la création de nouvelles zones d’activité, qui s’imbriquent avec d’autres plus courtes comme les flux résidence-emplois ou les modes de transport. Il est difficile – voire impossible – de calibrer les paramètres qui président aux dynamiques longues, pour lesquelles on dispose de trop peu d’éléments. Le développement urbain dépend de choix politiques qui ne peuvent être aisément anticipés. Cela conduit également à distinguer des horizons temporels variés dans lesquels on modélise des dynamiques transitoires multipliant les informations à représenter. En fixant ces éléments de dynamique longue, on simplifie la représentation en renvoyant l’analyse de ces dimensions à l’élaboration de scénarios exogènes qui ignorent les causalités entre par exemple une nouvelle ligne de transport et le développement des zones d’activité.\n\n\n3.2 Comment ? Représentation formelle et stratégie d’estimation\nOn considère des individus appartenant à des catégories k3 caractérisant leurs comportements de mobilités. Ces individus sont localisés par l’endroit i où ils résident et l’endroit j où ils travaillent. On note alors km^m_{ijk} le nombre de kilomètres parcourus chaque année par un individu de la catégorie k qui réside au carreau i et travaille au carreau j en utilisant le mode de transport m. On se limite ici aux kilomètres parcourus pour des motifs professionnels en considérant que les individus effectuent des boucles domicile_i - travail_j - domicile_i, éventuellement allongées en raisons d’étapes intermédiaires (cf. plus loin).\n3 Les catégories k sont construites dans la suite par le croisement de variables catégoriques observées sur les individus (type de ménage, possession d’une voiture, distance au transport en commun par exemple). Le coût en calcul augmente linéairement comme k qui est le produit des nombres de modalités dans chacune des catégories considérées. Ce nombre peut donc augmenter très vite si l’on n’est pas parcimonieux dans la description des individus. Une autre approche serait de dériver les catégories d’une classification distinguant au mieux différents comportements de mobilités.Pour chaque individu k, km^m_{ijk} se ramène au produit des trois facteurs suivants : (i) le nombre de boucles effectuées par l’individu pour des raisons professionnelles au cours d’une année entre sa résidence i et son lieu de travail j, que l’on note nb^{bcl}_k ; (ii) la longueur typique de chacune de ces boucles, que l’on note L^{bcl}_k ; et (iii) la probabilité qu’une de ces boucles soit effectuée dans le mode de transport m, notée P^{bcl}_{k,m}. Chacun de ces facteurs dépend des caractéristiques k de l’individu et des caractéristiques bcl de la boucle typique passant par i et j. Nous reviendrons plus loin sur les modèles mobilisés pour évaluer ces facteurs. Soulignons, pour l’heure, que le nombre de boucles professionnelles effectuées dans l’année est une fonction des caractéristiques de l’individu et de la distance domicile-travail ou, plus exactement, de la longueur de la boucle typique. Cette longueur de boucle est évidemment une fonction de la distance domicile-travail. Le plus souvent, il s’agit simplement du double (l’aller puis le retour), mais nous tenons compte également de boucles plus complexes, qui allongent le parcours. Nous noterons par la suite K le ratio entre la longueur de la boucle et la distance domicile_travail. K vaut 2 dans le cas des boucles simples, et 2 ou plus dans le cas des boucles complexes. Enfin, le choix modal dépend des caractéristiques des individus et de la longueur de la boucle.\nkm^m_{ijk} se décompose donc de la façon suivante :\n\n\\begin{aligned}\nkm^m_{ijk} & = Nombre\\ de\\ boucles \\times longueur\\ d'une\\ boucle \\times part\\ modale\n\\\\&= nb^{bcl}_k \\times L^{bcl}_k \\times P^{bcl}_{k,m}\n\\end{aligned}\n\\tag{1}\nComme nous connaissons la composition sociale de chaque carreau de résidents, le nombre de kilomètres parcourus par un individu moyen résident en i et travaillant en j, noté km^m_{ij}, s’obtient simplement en calculant la moyenne pondérée sur les caractéristiques des résidents en i de équation 1. En notant prop_{ik} la proportion de la catégorie k au sein du carreau i, on a :\n\n\\begin{aligned}\nkm^m_{ij} &= \\sum_k (km^m_{ijk} \\times prop_{ik})\n\\end{aligned}\n\\tag{2}\nL’étape suivante consiste à se servir du modèle MEAPS pour calculer km^m_i, soit le nombre de kilomètres parcourus dans l’année pour un individu résident en i dans le mode de transport m. MEAPS nous permet d’évaluer le flux de navetteurs des résidences en i vers les lieux de travail situé en j, flux que nous notons f_{ij}. On peut réécrire ce flux comme une probabilité pour un individu résident en i de travailler en j en divisant par la somme des flux partant de i. Le calcul de km^m_i se ramène alors à un simple calcul de l’espérance mathématique des km^m_{ij} sur l’ensemble de lieux de travail j.\n\n\\begin{aligned}\nkm^m_{i} &= \\sum_j (km^m_{ij} \\times \\frac{f_{ij}}{\\sum_{j'} f_{ij'}})\n\\end{aligned}\n\\tag{3}\nOn notera que, par souci de simplicité, nous avons évalué les flux f_{ij} indépendamment de k, mais il serait tout à fait envisageable d’intégrer cet aspect dans nos estimations.\nLe tableau 2 indique les stratégies d’estimation pour chacun des facteurs et la mobilisation des données sources associés à chacun.\n\n\n\nTableau 2. Facteurs intervenant dans le modèle multiplicatif des kilomètres parcourus\n\n\n\n\n\n\n\n\n\n\n\nfacteur\ndescription\nmodélisation\nsource de données\n\n\n\n\nd_{ij}\ndistance routière entre le carreau i de résidence et le carreau j d’emploi en utilisant une voiture et en suivant le réseau routier\nMoteur de routage R^5 ou {dodgr}\nOpen Street Map\n\n\ntt^m_{ij}\ntemps de parcours pour chaque mode entre i et j\nMoteur de routage R^5 ou {dodgr}\nOpen Street Map, GTFS locaux\n\n\nf_{ij}\nflux des navetteurs entre i et j4 | Alternativement MEAPS/modèle gravitaire/répartition uniforme pour l’intrapolation infra communale. Dépend de la distance d_{ij} ou du rang des temps t^m_{ij}et du nombre d’emplois en j | Recensement fichier détail « mobilités professionnelles » intercommunales 2018, carroyage 200m de l’INSEE pour les résidents, MOBPRO et Fichiers fonciers pour l’emploi |\n\n\n\n\nnb^{bcl}_k\nfréquence annuelle des boucles ayant les caractéristiques bcl pour un individu de catégorie k\nModèle de Poisson ou de Conway-Maxwell selon lequel le nombre de boucles dépend de la longueur de la boucle et d’autres variables descriptives.\nEnquête mobilité des personnes 2019\n\n\nK_{ijk}\nratio de la longueur d’une boucle sur la distance domicile-travail d_{ij}\nModèles estimés pour la possibilité d’effectuer une boucle complexe et pour l’allongement qui résulte des détours effectués. Dépend de la distance d_{ij}, de la densité résidentielle et des caractéristiques des navetteurs h_i\nEnquête mobilité des personnes 2019\n\n\np^m_{ijk}\nprobabilité modale\nModèle estimé (Random Utility Model), les probabilités modales dépendent des temps de parcours pour chaque mode. Deux modèles sont estimés suivant que les transports en commun sont à portée ou non\nOpen Street Map, GTFS locaux, Enquête mobilité des personnes 2019\n\n\n\n4 Les répartitions des destinations entre i et j sont ajustées sur les données MOBPRO. En notant mbp_{IJ} le flux entre la commune d’origine I et de destination J, on a : \\sum_{i \\in I j \\in J}{n_i e_j f_{ij}}=mbp_{IJ}\n\n\nComme on peut le constater, il est nécessaire pour poursuivre notre stratégie d’estimation de modéliser les pratiques de mobilités des navetteurs.\n\n\n3.3 Retour sur l’autosélection et le biais d’endogénéité\nAupavant, il vaut de revenir sur les problèmes méthodologiques des méthodes retenues habituellement dans la littérature (cf. (sec_densemis?)), dont nous avons rappelé les résultats plus haut dans le texte, pour mieux apprécier notre approche. La stratégie usuelle consiste à estimer pour chaque individu observé le lien entre, d’un côté, les kilomètres qu’il a parcourus et, de l’autre, ses caractéristiques socio-économiques ainsi que quelques indicateurs géographiques supposés adéquats pour rendre compte de la densité urbaine. Le problème de cette perspective est qu’elle s’abstrait d’emblée de la géographie réelle pour n’en retenir que quelques descripteurs comme la densité urbaine, le design, la diversité ou encore la distance au centre des affaires. Ce faisant, les données du problème sont comme « agrégées » selon les niveaux de densité et les niveaux de tous les autres descripteurs géographiques retenus ; au passage, la géographie réelle est « écrasée ». On peut se représenter la réduction qui est opérée de la manière suivante : les données géographiques peuvent être représentées par une carte remplie de données géolocalisées, voire deux cartes si l’on s’intéresse à des flux, avec des données sur les points de départ et d’arrivée. Cette carte est comme un grand tableau de données. Toutefois, ce n’est pas sur ce tableau que les estimations usuelles vont être effectuées ; c’est sur le tableau réduit où l’on a mis dans la même case les individus aux caractéristiques socio-économiques et aux niveaux de descripteurs géographiques identiques. Or, cette réduction n’est pas sans conséquence. Elle est au contraire l’une des sources des nombreux doutes méthodologiques qui « travaillent » la communauté des spécialistes du domaine. Les interrogations sur l’endogénéité remettent typiquement en question la similitude supposée des individus appartenant à une même case du tableau réduit.\nPour le comprendre, il faut revenir à la formulation classique du problème, où il s’agit d’estimer le nombre km_i de kilomètres parcourus (parfois en log) par un individu i en fonction des j caractéristiques socio-économiques X_i^j, des k descripteurs géographiques locaux L_{local(i)}^k et des l descripteurs globaux G_{global(i)}^l.\n km_i = \\alpha_j X_i^j + \\beta_k L^k_{local(i)} + \\gamma_l G^l_{global(i)} + \\varepsilon_i  \\tag{4}\nUn problème d’endogénéité survient lorsque la densité – une des composantes du vecteur L^k_{local(i)} ou du vecteur G^l_{global(j)} – est corrélée avec certaines caractéristiques socio-économiques X^j_i, ce qui induit un biais dans l’estimation du cœfficient \\beta_k. Pour savoir si l’on se heurte à un problème d’endogénéité, il faut donc se poser la question un peu étrange : les individus ont-ils des préférences de densité résidentielle ? Et cette préférence est-elle identique au sein de toutes les catégories socio-économiques ? Il est peu vraisemblable que les individus se posent ces questions sous cette forme : ils font leur choix de résidence en arbitrant entre de multiples critères, de multiples contraintes, et en mettant au centre de ce choix le lieu de cette résidence sur une carte, et non en optant pour une densité. Aussi, si un biais d’endogénéité existe, c’est de manière indirecte, parce que la densité est corrélée à des critères importants de choix résidentiels, comme par exemple l’accès à des transports en commun. Pour les catégories qui ne possèdent pas de voiture ou pas de permis de conduire, cet accès est un critère qui a des chances de peser plus fortement sur le choix de résidence. Et inversement, pour ceux qui possèdent une ou plusieurs voitures et déclarent aimer conduire (encore que, sur ce dernier point, on peut se demander dans quelle mesure la nécessité de prendre la voiture altère la psychologie de l’automobiliste). En revanche, est-ce réellement un biais sur la densité ? N’est-ce pas plutôt un biais sur l’accès aux transports en commun ? Il est toujours possible d’ajouter cette dernière variable dans la régression, mais on ne sait pas réellement où arrêter les ajouts. Faut-il ajouter la présence de commerces de proximité ? C’est également un critère important pour celui qui n’a pas de voitures. Puis la présence d’école, etc. Il y a une tentation de réintroduire ici toute la géographie qui a été auparavant écrasée.\nMais revenons à l’équation équation 4. Il peut y avoir un biais d’endogénéité parce qu’il existe une variable cachée qui est liée à la fois à la densité et aux caractéristiques individuelles. Imaginons, par exemple, que le fait d’aimer conduire soit cette variable et que les catégories supérieures aimeraient plus conduire, pour la simple raison qu’ils ont acheté des gros SUV ostentatoires. Dans ce cas, l’estimation effectuée sur les données du tableau réduit n’aboutit pas aux mêmes résultats que les estimations que l’on peut effectuer sur les sous-tableaux définis conditionnellement à une valeur fixée de cette variable cachée. Dans le sous-tableau de ceux qui aiment conduire, on a plus de cadres supérieurs qui habitent loin, dans des zones peu denses, et qui font beaucoup de kilomètres. Dans ce cas, l’élasticité du nombre de kilomètres selon la densité va être fortement négative. Dans l’autre sous-tableau, l’élasticité va être au contraire faiblement négative. Plus problématique, ceux qui aiment conduire ne sont pas allés n’importe où, ils ont choisi d’habiter dans des zones certes moins denses, mais avec une bonne accessibilité en voiture à de nombreuses aménités, dans des zones valorisées, bien entretenues, avec des prix élevés… Ils n’ont pas fait que choisir une zone peu dense mais, encore une fois, certains lieux sur une carte. La forte élasticité observée n’est donc pas un résultat établi sur l’ensemble du territoire observé, mais sur une sélection implicite. C’est ce qui fait que l’on ne peut même pas se contenter d’une estimation moyenne sur les deux sous-tableaux. En réalité, pour des mêmes descripteurs géographiques, une même densité, un même design, il y a des lieux différents sur la carte qui ne sont pas forcément choisis par les mêmes catégories d’individus avec une même appétence à multiplier les trajets en voiture.\nLa stratégie de modélisation que nous proposons s’efforce au contraire de mener l’analyse en conservant la géographie, sans la réduire a priori à quelques descripteurs synthétiques qui induisent plus de difficultés méthodologiques qu’ils n’en résolvent. Nous estimons chaque composante de l’équation 1 séparément, pour chaque catégorie k d’individu ou de ménage. Chacun des modèles s’efforce d’expliquer un comportement de mobilité – fréquence des boucles, complexité des boucles, choix modal – en mobilisant les données disponibles avec l’idée de pouvoir prédire le comportement d’un individu résidant en un lieu donné. La distance domicile-travail est mobilisée comme variable explicative du comportement, sans que cela pose de problèmes puisque la variable expliquée n’est pas la distance parcourue. Ceci ne signifie pas qu’il ne peut pas y avoir de biais d’endogénéité au sein de ces modèles, mais la stratégie indirecte que nous suivons, en évitant l’exercice de construction de descripteurs géographiques, limite a priori le nombre et la portée de ces éventuels biais.\nNous évitons notamment les interrogations et les biais induits par le tri spatial de la population. En nous efforçant d’expliquer le comportement d’un individu en fonction de son lieu de résidence sur une carte, on évite les difficultés liées à des tris spatiaux spécifiques selon telle ou telle catégorie, tel ou tel descripteur géographique. Les distances parcourues sont estimées en fonction d’une position sur une carte pour une catégorie d’individu ou de ménage. Et ce n’est qu’une fois cette exercice mené à son terme que l’on examine réellement le lien entre la densité ou d’autres descripteurs géographiques et les KVT.\nNous retrouverons la question de l’autosélection et du tri spatial non pas pour estimer le nombre de kilomètres parcourus mais lorsque nous voudrons évaluer la variation de kilomètres que l’on peut attendre d’une modification de la localisation d’un ménage. En effet, l’expérience de pensée qui consiste à changer la localisation d’un ménage ou d’un individu ne peut omettre la question de la vraisemblance de ce scénario : est ce que l’individu ou le ménage acceptent cette localisation ? Ainsi posée la question est cependant bien plus claire. La question de l’acceptation du scénario peut être explicitement débattue, elle peut être favorisée ou imposée que ce soit par des incitations fiscales ou par une réglementation comme le zonage ou l’ouverture de droits à construire limités et localisés. Enfin, les préférences individuelles des ménages qui s’installent n’ont aucune raison d’être celles des ménages moyens que l’on a observé dans une enquête réalisée à une autre époque, dans un autre contexte ou dans un autre endroit et qui consiste à céder au syndrome de l’anecdote dénoncé par Heckman ou Deaton à propos des estimateurs locaux, même sans biais. Ainsi, à défaut de le résoudre complètement, nous pensons largement clarifier la question liée au biais d’endogénéité."
  },
  {
    "objectID": "trajets.html#les-données-enquête-mobilité-du-trajet-à-la-boucle",
    "href": "trajets.html#les-données-enquête-mobilité-du-trajet-à-la-boucle",
    "title": "La Ville Compacte, une solution aux émissions de gaz à effet de serre",
    "section": "4 Les données : Enquête mobilité, du trajet à la boucle",
    "text": "4 Les données : Enquête mobilité, du trajet à la boucle\nPour analyser les pratiques de mobilité des Français, nous nous sommes appuyées sur l’enquête Mobilité des Personnes de 2019. Cette enquête a été conduite par l’INSEE entre avril 2018 et avril 2019 auprès de 13 825 ménages et nous renseigne sur l’équipement en véhicules du ménage et sur les déplacements effectués par un membre du ménage de plus de 6 ans (choisi selon la méthode KISH) au cours d’une journée de la semaine précédent le jour d’enquête. Elle livre une information riche sur les pratiques de mobilité des Français juste avant la grande vague de COVID-19 de 2020 et les confinements. On peut ainsi savoir combien de trajets sont effectués au cours d’une journée, quel est le motif de chacun des déplacements et quelle est le mode de transport utilisé.\nToutefois, derrière l’apparente simplicité des questions posées dans ce type d’enquête se cachent d’importantes difficultés de définition de l’objet. Il n’est en effet pas si simple de définir chacun des trajets et d’y associer de manière univoque un motif de déplacement. Pour ne prendre qu’un exemple, si, en chemin vers mon lieu de travail, je m’arrête pour acheter un croissant, est-ce que je déclare uniquement un déplacement domicile-travail, avec le motif travail, en négligeant l’escale du croissant, considérée comme secondaire, ou bien, est-ce que je déclare deux trajets en considérant que le premier trajet a pour motif d’acheter un croissant ? La difficulté est que cette première partie du trajet, ou ce premier trajet, poursuit plusieurs objectifs. Selon que l’on retient l’un ou l’autre des motifs, on aura des chiffrages très différent du poids de la mobilité des Français pour des motifs professionnels et des motifs alimentaires.\nAussi nous avons adopté la perspective des boucles : une boucle est une série de déplacements qui débute par un départ du domicile et finit par un retour au domicile. Une boucle peut être effectué avec de nombreux motifs. Par exemple, une personne quitte le matin son domicile pour accompagner son enfant à l’école, puis enchaîne en allant directement à son lieu de travail ; le soir, elle prend le temps de faire quelques courses avant de rentrer chez elle. Au cours de cette boucle, les motifs auront été d’accompagner un enfant à l’école, d’aller travailler, de faire des courses et, enfin, de rentrer chez soi. On considère alors que chaque boucle est effectuée pour un motif principal tandis que les autres motifs expliquent les détours et les écarts par rapport à un aller-retour direct entre le domicile et la destination associée au motif principal.\nNous avons retenu quatre grande catégorie de motifs de déplacement : le travail, les études, les courses et, enfin, tous les motifs restants. Et nous les avons hiérarchisés en considérant que certains motifs sont plus impératifs que d’autres et qu’ils constituent en général le motif principal d’une boucle. Le travail est le motif qui domine les autres, suivi des études, des courses et, finalement, tous les autres motifs.\nPour chaque boucle, nous avons aussi retenu un mode de transport principal. Ceci ne pose pas de réelles difficultés car, dans la plupart des cas, il y a unicité du mode de transport tout au long d’une boucle. Si je prends la voiture pour aller au travail, il est très probable qu’au passage j’accompagne mon enfant à l’école en voiture et que, le soir, je fasse un détour en voiture pour faire les courses avant de rentrer à la maison en voiture. En revanche, si j’accompagne mon enfant à pied, avant d’aller rejoindre le métro pour aller à mon travail, nous retiendrons que le mode principal de la boucle est le métro. En 2019, il n’y avait quasiment pas de boucles réellement multimodales, c’est-à-dire de boucles où la personne alterne entre la voiture, les transports en commun ou le vélo.\n\n4.1 Les kilomètres parcourus selon EMP 2019\nL’enquête mobilité des personnes nous sert de source, conjointement à MOBPRO, et il est est donc utile d’avoir en tête quelques résultats qui seront confrontés aux résultats des simulations. La ville compacte étant une dimension au cœur de notre discussion, il est intéressant de séparer les communes suivant leur densité. Il s’agit ici de la classification de l’INSEE de la « grille communale »5 qui présente les mêmes défauts –- échelle arbitraire, fixe, administrative dans ce cas et donc de taille variable, ne tenant pas compte de l’environnement général –- que ceux évoqués précédemment.\n5 https://www.insee.fr/fr/information/6439600Comme on peut le constater au tableau 3, entre une « commune très dense » et une « commune peu dense », il y a un ratio de un peu moins que 1 à 2 pour les kilomètres parcourus annuellement, pour le motif principal travail.\n\n\n\n\nTableau 3. Nombre de kilomètres parcourus par an selon EMP2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrance hors IdF\n\n\nkm par personne par an\n\n\n\npar actif\npar adulte\n\n\ntravail\ntravail\netudes\ncourses\nautres\ntotal\n\n\n\n\nkm\n\n\ntrès dense\n6 011[5 393, 6 791]\n2 908[2 612, 3 313]\n976[836, 1 143]\n1 186[1 064, 1 341]\n2 211[1 943, 2 488]\n7 309[6 884, 7 782]\n\n\ndensité intermédiaire\n7 854[7 220, 8 565]\n3 602[3 310, 3 971]\n1 106[935, 1 284]\n1 506[1 355, 1 690]\n3 194[2 920, 3 516]\n9 436[8 973, 9 880]\n\n\npeu dense\n10 826[10 126, 11 555]\n5 496[5 145, 5 876]\n1 646[1 451, 1 865]\n2 107[1 914, 2 306]\n3 747[3 405, 4 125]\n13 016[12 526, 13 520]\n\n\ntrès peu dense\n10 163[7 985, 13 090]\n5 471[4 179, 7 211]\n1 753[1 223, 2 470]\n2 325[1 881, 2 880]\n4 186[3 346, 5 207]\n13 793[12 245, 15 600]\n\n\ntotal\n8 598[8 214, 8 982]\n4 188[3 999, 4 394]\n1 297[1 184, 1 416]\n1 678[1 582, 1 771]\n3 170[3 001, 3 361]\n10 341[10 066, 10 601]\n\n\nrelatif\n\n\ntrès dense\n1[1, 1]\n1[1, 1]\n1[1, 1]\n1[1, 1]\n1[1, 1]\n1[1, 1]\n\n\ndensité intermédiaire\n1.3[1.1, 1.5]\n1.2[1.1, 1.4]\n1.1[0.89, 1.4]\n1.3[1.1, 1.5]\n1.4[1.2, 1.7]\n1.3[1.2, 1.4]\n\n\npeu dense\n1.8[1.6, 2]\n1.9[1.6, 2.1]\n1.7[1.4, 2.1]\n1.8[1.5, 2]\n1.7[1.5, 2]\n1.8[1.7, 1.9]\n\n\ntrès peu dense\n1.7[1.3, 2.2]\n1.9[1.4, 2.5]\n1.8[1.2, 2.6]\n2[1.5, 2.5]\n1.9[1.5, 2.4]\n1.9[1.6, 2.2]\n\n\ntotal\n1.4[1.3, 1.6]\n1.4[1.3, 1.6]\n1.3[1.1, 1.5]\n1.4[1.3, 1.6]\n1.4[1.3, 1.6]\n1.4[1.3, 1.5]\n\n\n\nSource : EMP 2019,\n38.7M adultes (AGE&gt;=18) dans la zone\n10.1k observations dans EMP19\n512 répétitions de rééchantillonage\nentre crochets : intervalle de confiance à 95%"
  },
  {
    "objectID": "trajets.html#estimations",
    "href": "trajets.html#estimations",
    "title": "La Ville Compacte, une solution aux émissions de gaz à effet de serre",
    "section": "5 Estimations",
    "text": "5 Estimations\n\n5.1 De la fréquence des boucles\nA ce stade, notre objectif est d’estimer la fréquence journalière des boucles à partir des comportements constatés dans EMP 2019. Nous limitons ici notre examen aux boucles effectuées pour le travail, ce pourquoi nous étudions uniquement les comportements des actifs. Par ailleurs, nous avons exclus l’Ile-de-France car les pratiques de mobilités y sont spécifiques (plus de transport en commun) et les résidents s’écartent de la population moyenne (plus de jeunes actifs diplômés). Cela risquerait de produire un effet de composition (Yule-Simpson) qui biaiserait les résultats. La distribution de la fréquence peut être observée à partir d’un rootogram, selon la suggestion de John Tukey (Tukey, 1977). On voit alors sur le graphique graphique 2 que cette distribution est moins dispersée que ce que prévoit la distribution « classique » de Poisson. Il y a une forte concentration sur la valeur 1, ce qui ne constitue pas une surprise : la plupart des actifs font quotidiennement une unique boucle domicile-travail. Ensuite, certains font deux boucles, vraisemblablement parce qu’ils rentrent chez eux pour déjeuner. D’autres encore ne vont pas aller à leur travail pour diverses raisons (vacances, maladie, week-end…), mais la fréquence observée est inférieure à ce que prévoit une distribution de Poisson. Enfin, de rares actifs font plus de deux boucles domicile-travail au cours d’une journée. Dans l’ensemble, la distribution est peu dispersée, bien moins qu’attendue dans le cas de Poisson.\n\n\n\n\n\nGraphique 2. Rootogram du nombre de boucles domicile-travail pour les actifs hors IDF\n\n\n\n\n\n\n\n\nPour tenir compte de cette sous-dispersion, nous avons modélisé cette distribution à partir de la distribution de Conway-Maxwell-Poisson (Conway & Maxwell, 1962), qui ajoute au modèle de Poisson un paramètre pour ajuster la dispersion. Elle s’écrit comme suit :\n\nP(x=n|\\lambda,\\nu) = \\frac{\\lambda^n}{Z(\\lambda, \\nu) \\times (n!)^\\nu} \\quad pour\\ n=0,1,2...\n\navec la constante de normalisation Z(\\lambda, \\nu) = \\sum_{n=0}^\\infty \\frac{\\lambda^n}{(n!)^\\nu}. La distribution de Conway-Maxwell-Poisson (CMP) inclut la distribution de Poisson (\\nu=1), la distribution géométrique (\\nu=0, \\lambda&lt;1) ou encore la distribution de Bernoulli (\\nu \\xrightarrow[]{}\\infty) en tant que cas particuliers.\nOn estime le nombre de boucles journalières liées au travail à partir d’une régression de type Poisson, en substituant la distribution standard de Poisson par celle de CMP. Les variables dépendantes retenues sont la longueur de la boucle, la densité de la commune de résidence et le fait de posséder ou non une voiture. Nous nous en tenons à ces seules variables pour différentes raisons : (i) tout d’abord, nous nous devons d’être parcimonieux pour ne pas démultiplier les temps de calcul (une variable avec N catégories multiplie la quantité de calculs par N) ; (ii) puis on ne retient bien entendu que les variables qui produise un effet ; et (iii), plus encore, on ne retient que les variables qui induisent des différences spatiales. Par exemple, même si la variable sexe peut jouer un rôle au sein de la régression, elle n’a pas de conséquences notables sur la répartition spatiale de la variable dépendante (le nombre de boucles) puisque il y a toujours à peu près autant d’hommes que de femmes dans chaque carreau de résidents.\nLa spécification du modèle est la suivante pour un individu de catégorie k, sachant que nb^{bcl}_k est le nombre de boucles domicile-travail au cours d’une journée, L^{bcl}_k la longueur moyenne de ses boucles domicile-travail, dens_{res,k} la densité de la commune de résidence et, enfin, voiture_k le fait de disposer ou non d’une voiture.\n\nlog(nb^{bcl}_k) = \\alpha + \\gamma \\times log(L^{bcl}_k) + \\delta \\times dens_{res, k} + \\tau \\times voiture_k + \\varepsilon_k \\\\avec \\\\ \\varepsilon_k \\sim CMP(\\lambda, \\nu)\n\\tag{5}\n\n\n\n\nTableau 4. Régression de Conway-Maxwell-Poisson sur le nombre de boucles journalières domicile-travail\n\n\n\n\n\n\n\n\n\n\n\nCMP\n\n\n\n\n(Intercept)\n0.272 (0.074)*** &lt;0.001\n\n\nlog(distance)\n-0.237 (0.011)*** &lt;0.001\n\n\nCommune assez dense\n-0.022 (0.038) 0.572\n\n\nCommune peu dense\n0.082 (0.034)* 0.018\n\n\nA une voiture\n0.211 (0.071)** 0.003\n\n\nNum.Obs.\n4307\n\n\nAIC\n8869.5\n\n\nBIC\n8907.7\n\n\nLog.Lik.\n-4428.767\n\n\n\n\n\n\n\n\n\n\n\nLe tableau 4 présente les résultats des estimations. Le paramètre de dispersion \\nu est très significativement différent de 1 et vaut environ 2.2. Il y a bien sous-dispersion de la distribution. Ensuite, comme on peut le voir, la longueur de la boucle joue un rôle négatif, comme on pouvait s’y attendre : plus la distance domicile-travail est importante, moins un actif va envisager de multiplier les allers-et-retours. Disposer d’une voiture fait que l’on hésite moins à faire des allers-et-retours. Enfin, résider dans une commune peu dense conduit un peu plus à multiplier le nombre de boucles.\n\n\n5.2 Boucles simples ou boucles complexes\nDans la perspective des boucles, les individus ne se contentent pas de faire des allers-et-retours entre leur domicile et leur lieu de travail (boucle simple), mais ils effectuent aussi des détours pour d’autres motifs (boucle complexe). La longueur de la boucle fait alors plus du double de la distance domicile-travail. Du point de vue des individus, c’est un moyen rationnel de minimiser les distances en satisfaisant plusieurs motifs au cours d’un même trajet. Or il se pourrait tout à fait que les individus qui habitent le plus loin de leur lieu de travail soient aussi ceux qui réussissent le mieux à rationaliser les boucles qu’ils effectuent, quitte à ce que ces boucles soient plus complexes. On s’attendrait également à ce que le niveau de vie contraigne à des boucles plus optimisées et qu’au contraire les ménages avec enfants aient plus de contraintes à l’optimisation.\nL’examen des données montre tout d’abord que le cas des boucles complexes est relativement marginal : 82% des boucles ayant le travail pour motif principal sont simples. Ensuite, on n’observe pas de fortes différences de comportements selon le niveau de vie.\nNous avons modélisé les détours potentiels en deux étapes. Dans un premier temps, nous avons simplement estimé une régression logistique pour évaluer la probabilité de faire une boucle complexe plutôt qu’une boucle simple. Puis, dans un second temps, nous avons estimé le ratio K de la longueur de la boucle par rapport à la distance domicile-travail. Dans le cas d’une boucle simple, K vaut 2 ; et il vaut 2 ou plus dans le cas d’une boucle complexe.\nCommençons par la probabilité d’effectuer une boucle simple. Cette probabilité ne semble pas liée à beaucoup de variables et nous n’avons finalement retenu qu’une seule variable dépendante : le type de ménages.\n\nlogit(Prob^{simple}_k) = \\alpha + \\beta \\times typmen_k +\\varepsilon_k \\\\ avec\\ \\varepsilon_k \\sim Binomial\n\\tag{6}\n\n\n\n\nTableau 5. Régression logistique sur la chance qu’une boucle soit simple\n\n\n\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\nConstante\n1.468 (0.134)***\n\n\nMonoparent\n-0.037 (0.213)\n\n\nCouple sans enfant\n0.429 (0.182)*\n\n\nCouple avec enfant(s)\n0.000 (0.151)\n\n\nAutres\n0.593 (0.388)\n\n\nNum.Obs.\n2589\n\n\nAIC\n2414.0\n\n\nBIC\n2443.3\n\n\nLog.Lik.\n-1202.012\n\n\nRMSE\n0.38\n\n\n\n\n\n\n\n\n\n\n\nComme on peut le constater au tableau 5 et comme on pouvait s’y attendre, les ménages avec enfants effectuent plus souvent des boucles complexes.\n\n\n5.3 Longueur des détours et multiplicateur de distance\nVenons-en à l’estimation de la longueur des détours dans le cas des boucles complexes. L’examen des données donne une idée générale de l’allure de la relation entre la longueur du détour et la distance domicile-travail : plus l’on travaille loin de chez soi, plus la part des détours est faible. Autrement dit, plus la distance domicile-travail est importante, plus celle-ci exerce une contrainte à aller « droit au but » si l’on peut dire ; le détour tend vers zéro et la longueur de la boucle tend vers deux fois la distance domicile-travail. Inversement, dans le cas où l’on travaille très près de chez soi, il n’y a plus de contraintes et la longueur de la boucle n’est plus liée à la distance domicile-travail. Dans ce cas, la longueur de la boucle va surtout s’expliquer par les autres motifs, et non par le travail. C’est une limite de l’approche par boucles, qui définit hiérarchiquement un motif principal. Cette limite demeure toutefois moins gênante que les problèmes méthodologiques de l’approche par trajets, qui attribue des longs trajets à des motifs secondaires (comme dans l’exemple précédent le cas de l’arrêt pour l’achat d’un croissant en chemin vers son travail). Ici, le problème est somme toute assez circonscrit : il concerne uniquement ceux qui travaille près de chez eux, lorsqu’ils font des boucles complexes. Et l’erreur tient à un problème d’attribution du bon motif des kilomètres parcourus : il devient erroné de parler de détour au sein d’une boucle travail lorsque ce détour est presque l’essentiel de la boucle. Comme nous le verrons, ce problème pourrait être résolu, si le besoin s’en ressentait réellement, mais il est marginal.\nNous notons ici, de manière simplifiée, L la longueur d’une boucle, d la distance entre le domicile et le lieu de travail, \\Gamma la longueur des détours, \\gamma la proportion des détours rapportée à la distance domicile-travail et, enfin, K le ratio longueur sur distance. On a les relations suivantes entre ces variables :\n\nL = 2 \\times d + \\Gamma\n\\\\\nK = L / d\n\\\\\n\\gamma = \\Gamma / d\n\\\\\nK = 2 + \\gamma\n\\tag{7}\nOn s’attend à ce que K dépende de la complexité de la boucle (plus la boucle est complexe, plus K est grand) et de la distance d (plus la distance est grande, plus K est petit). La graphique 3 illustre ces intuitions en comparant les boucles A et B. L’emploi est plus éloigné dans le cas de la boucle B que dans la boucle A. Le trajet B consiste à faire un détour proportionnellement plus faible pour le motif course ou école. Le facteur multiplicateur K sera supérieur à 2 dans les deux cas, mais devrait être plus grand pour A que pour B (K^A \\geq K^B \\geq 2).\nLe facteur K a plusieurs intérêts dans notre perspective. Tout d’abord, le fait de définir pour chaque boucle un motif principal conduit à attribuer à tort les kilomètres supplémentaires liés aux détours au motif principal. Le facteur K permet d’identifier la part de ces kilomètres supplémentaires et, donc, pourrait permettre de réaffecter ces kilomètres aux autres motifs. Pour l’instant, nous n’avons pas opéré une telle réaffectation : non seulement cela ne changerait les résultats qu’à la marge, mais également nous nous intéressons plus aux kilomètres parcourues totaux qu’aux motifs.\nEnsuite, le facteur K ne nous sert pas uniquement pour évaluer l’importance des détours par rapport au trajet direct domicile-travail, mais il nous permet aussi, en sens inverse, d’inférer la distance domicile-travail à partir de la longueur de la boucle. Il se trouve que c’est une difficulté dans l’enquête EMP 2019 : nous connaissons la distance parcourue pour chacun des trajets et, donc, nous pouvons connaître la longueur de chaque boucle effectuée, mais nous n’avons pas d’information directe sur la distance domicile-travail. Nous en sommes réduits à devoir l’inférer.\nHeureusement, on peut identifier partiellement le lien entre ces deux distances. Dans le cas d’une boucle simple, le motif principal est le motif de l’aller et le retour a pour motif le bien nommé « retour au domicile ». La distance parcourue est alors de 2 fois la distance domicile-travail (K=2). Dans le cas d’une boucle complexe, il n’est pas toujours possible d’inférer la distance domicile-travail. Ce n’est possible que si le premier trajet de la boucle va directement au travail ou si le dernier trajet revient directement du travail. La graphique 3 permet d’illustrer cela. On peut repérer la distance domicile-travail par les trait bleus dans les cas B, C et D. Les boucles B et D sont des boucles complexes, mais telles que le premier ou le dernier trajet sont des trajets domicile-travail. On peut donc poser que la distance domicile-travail est égale à la distance bleue. En revanche, pour une boucle complexe comme la boucle A, où il n’y a pas de trajets directs domicile travail, on ne peut pas déduire la distance domicile-travail, ni le facteur K.\n\n\n\nGraphique 3. 4 boucles domicile travail\n\n\n\n\n\n\nEn se limitant aux individus pour lesquels il a été possible d’inférer la distance domicile-travail dans l’enquête EMP 2019, nous pouvons estimer la proportion de détours \\gamma en fonction de la distance d. La relation est de type log-log à condition de s’écarter des valeurs nulles, très proches de zéro ou au contraire très élevées. La proportion du détour est parfois nulle, aussi nous avons ajouté systématiquement 1% à cette proportion. Les distances proches de zéro sont également un problème puisqu’elles font diverger la proportion estimée. Or nous voulons un modèle qui renvoie une valeur finie raisonnable quand la distance tend vers 0. Nous avons donc ajouté 1 kilomètre à la distance dans l’équation à cet effet. Cet ajout ne perturbe pas l’estimation pour les longues distances et permet de borner l’effet du multiplicateur à courte distance. Nous avons également écarté les cas où K dépassait 10. Pour ne pas faire trop dépendre nos estimations de ces choix préalables, il fallait utiliser une méthode robuste. Nous avons opté pour une régression par quantile, en estimant la médiane, soit pour des individus indicés par l :\n\nlog(\\gamma_l) = \\alpha + \\beta \\times log(1 + d_l) + \\varepsilon_l\n\\\\ avec\\ \\varepsilon_l \\sim \\mathcal{N}\n\\\\ en\\ minimisant \\sum_l \\left\\lvert{\\varepsilon_l}\\right\\lvert\n\\tag{8}\n\n\n\n\nTableau 6. Estimation de la proportion des détours en fonction de la distance domicile-travail\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nconf.low\nconf.high\ntau\n\n\n\n\n(Intercept)\n1.675790\n1.226465\n2.0341652\n0.5\n\n\nlog(distance + 1)\n-1.070136\n-1.327079\n-0.8492878\n0.5\n\n\n\n\n\n\n\n\n\n\n\nLe modèle a un R^2 de 0.24. Le graphique graphique 4 montre l’allure de notre estimation médiane par rapport aux données issues de l’EMP.\n\n\n\n\n\nGraphique 4. Facteur K en fonction de la distance domicile-travail\n\n\n\n\n\n\n\n\nOn notera que les détours sont surtout importants – en proportion – à faibles distances et, comme nous l’avons vu précédemment, demeurent assez peu fréquents. L’un dans l’autre, le rôle joué par les détours dans notre modélisation reste relativement modeste\n\n\n5.4 Choix modal\nA ce stade de notre modélisation des pratiques de mobilités, nous savons prédire la fréquence des boucles et leur longueur. Il reste à estimer les choix modaux des individus en fonction de leurs caractéristiques et des caractéristiques des boucles envisagées. Pour ce faire, nous nous sommes appuyés fort classiquement sur les modèles d’utilités aléatoires (notés RUM par la suite, pour Random Utility Model, McFadden (1974)). Le principe de ces modèles est d’estimer pour chacun des modes de transport disponibles son utilité probable en fonction de divers paramètres comme le temps de trajet, le prix du trajet, le confort ressenti le long du trajet ou encore les caractéristiques de l’individu qui fera le trajet. Une des hypothèses du modèle est que les individus ont des préférences inobservables qui font que leur préférence pour un mode de transport vont varier aléatoirement (du point de vue de l’observateur) d’un individu à l’autre. Ce pourquoi, pour une demande de mobilité donnée, on estime en fait une distribution de probabilités de l’utilité pour chacun des modes. La comparaison des distributions permet ensuite d’estimer la probabilité d’un individu de choisir plutôt tel mode de transport que tel autre mode.\nNous avons estimé deux modèles RUM sur les données EMP 2019 : un modèle avec 4 choix modaux (marche à pied, vélo, voiture, transport en commun) et un autre avec uniquement les 3 premiers choix, pour les cas où il n’y a pas de transport en commun envisageable pour la boucle considérée. Pour mener à bien ces estimations, il faudrait idéalement pouvoir renseigner aux mieux chacun des choix modaux. Or l’enquête EMP nous renseigne essentiellement sur les caractéristiques du trajet effectif selon le mode retenu, et non sur les caractéristiques des modes alternatifs. En conséquence, nous n’avons mobilisé qu’une seule caractéristique spécifique selon le mode : le temps de trajet. Et nous avons dû l’inférer à partir de la vitesse moyenne de chaque mode et de la distance parcourue. Au passage, nous avons fait l’hypothèse que la distance parcourue est indépendante du mode, ce qui n’est pas toujours vérifiée. Même si, sur un territoire donnée, nous pouvons estimer une distance par mode (où, notamment, la distance à pied pourrait être parfois plus courte que celle en voiture), de telles distinctions ne sont pas disponibles dans EMP 2019.\nEn revanche, s’agissant des caractéristiques partagées entre les différents modes, nous sommes bien moins limités. Nous avons toutefois évacué certaines variables non pas parce qu’elles manqueraient de pertinence, mais parce qu’elles n’induisent pas d’hétérogénéité spatiale. Notamment, le sexe de l’individu peut jouer sur le choix modal, mais le fait d’intégrer cet aspect dans notre modèle n’a pas d’intérêt puisque la distribution spatiale des femmes est similaire à la celle des hommes. Seules nous intéresse les variables qui peuvent engendrer des différences de comportements moyens sur le territoire par effet de composition spatiale. Or, même si les hommes font, par exemple, plus souvent des trajets à vélo que les femmes, cet écart n’a pas de conséquence spatiale puisque la répartition homme-femme est homogène sur le territoire. Nous n’avons pas pris en compte non plus l’âge car nos estimations ont été effectuées sur les actifs uniquement. Certes, il y a bien des différences de comportements de mobilité selon l’âge, mais ces différences s’observent surtout entre les enfants, les étudiants, les actifs et les retraités, plus qu’entre les actifs.\nAu final, les modèles RUM estimés s’appuient sur les variables suivantes : U_{bcl,l}^m est l’utilité du mode de transport m pour un individu l prévoyant d’effectuer une boucle bcl, tt_{bcl, m} le temps total des trajets pour parcourir cette boucle dans le mode m, L_bcl la longueur de cette boucle, dens_l la densité de la commune de résidence (selon le code INSEE qui va de 1 pour « Très dense » à 4 pour « Très peu dense », en fusionnant les catégories 3 et 4 car cette dernière est rare dans EMP 2019), typmen_l le type de ménage, voiture_l le fait de posséder une voiture (au moins) et NdV_l le niveau de vie du ménage.\nIl s’agit d’estimer les fonctions d’utilités suivantes :\n\nU_l^m = \\alpha_m + \\beta \\times tt_{bcl,m} + \\gamma_m \\times log(L_{bcl}) + \\delta_m \\times log(NdV_l)\n\\\\ \\lambda_m \\times dens_l + \\mu_m \\times typmen_l + \\nu_m \\times voiture_l + \\varepsilon_{m,l}\n\\\\ avec\\ \\varepsilon_{m,l} \\sim Loi\\ de\\ Gumbel\n\\tag{9}\nNous nous en tenons, pour l’heure, à la modélisation la plus simple en faisant l’hypothèse que les erreurs sont distribuées selon une loi de Gumbel, conformément à la première formulation du modèle RUM par McFadden . Ceci revient à supposer que ces erreurs sont indépendantes et homoscédastiques et permet de se ramener à un simple modèle logistique multinomiale.\n\n\n\n\nTableau 7. Estimation des paramètres du modèle d’utilité aléatoire avec transport en commun\n\n\n\n\n\n\n\n\n\n\nFacteur\nCœfficient estimé\nEcart type\nt Student\np Value\n\n\n\n\n(Intercept):car\n3.0\n1.9\n1.5\n0.1\n\n\n(Intercept):transit\n10.6\n2.7\n3.9\n0.0\n\n\n(Intercept):walk\n7.0\n2.2\n3.2\n0.0\n\n\ntt\n0.0\n0.0\n−2.0\n0.0\n\n\nDENSITECOM_RESAssez dense:car\n1.0\n0.2\n5.0\n0.0\n\n\nDENSITECOM_RESAssez dense:transit\n−0.8\n0.3\n−2.8\n0.0\n\n\nDENSITECOM_RESAssez dense:walk\n0.1\n0.2\n0.4\n0.7\n\n\nDENSITECOM_RESPeu dense:car\n0.5\n0.2\n2.3\n0.0\n\n\nDENSITECOM_RESPeu dense:transit\n−3.1\n0.7\n−4.4\n0.0\n\n\nDENSITECOM_RESPeu dense:walk\n0.1\n0.3\n0.3\n0.8\n\n\nldistance:car\n0.7\n0.1\n5.0\n0.0\n\n\nldistance:transit\n0.7\n0.1\n4.9\n0.0\n\n\nldistance:walk\n−1.3\n0.1\n−11.6\n0.0\n\n\nTYPMEN5Monoparent:car\n−0.8\n0.3\n−2.8\n0.0\n\n\nTYPMEN5Monoparent:transit\n−0.4\n0.4\n−1.1\n0.3\n\n\nTYPMEN5Monoparent:walk\n−1.2\n0.3\n−3.6\n0.0\n\n\nTYPMEN5Couple sans enfant:car\n−0.4\n0.3\n−1.4\n0.2\n\n\nTYPMEN5Couple sans enfant:transit\n0.0\n0.4\n0.1\n0.9\n\n\nTYPMEN5Couple sans enfant:walk\n−0.8\n0.3\n−2.9\n0.0\n\n\nTYPMEN5Couple avec enfant(s):car\n−0.3\n0.2\n−1.5\n0.1\n\n\nTYPMEN5Couple avec enfant(s):transit\n−0.1\n0.3\n−0.4\n0.7\n\n\nTYPMEN5Couple avec enfant(s):walk\n−0.8\n0.3\n−3.2\n0.0\n\n\nTYPMEN5Autres:car\n−0.1\n0.8\n−0.1\n0.9\n\n\nTYPMEN5Autres:transit\n1.7\n0.9\n1.9\n0.1\n\n\nTYPMEN5Autres:walk\n0.0\n0.9\n0.0\n1.0\n\n\nvoitureTRUE:car\n2.4\n0.3\n8.0\n0.0\n\n\nvoitureTRUE:transit\n−1.5\n0.3\n−4.7\n0.0\n\n\nvoitureTRUE:walk\n0.0\n0.3\n−0.1\n0.9\n\n\nlrevuce:car\n−0.4\n0.2\n−2.1\n0.0\n\n\nlrevuce:transit\n−1.0\n0.3\n−3.7\n0.0\n\n\nlrevuce:walk\n−0.3\n0.2\n−1.5\n0.1\n\n\n\n\n\n\n\n\n\n\n\nOn peut voir au tableau 7 les estimations du modèle dans le cas où il y a des transports en commun. Le modèle à un R^2 de McFadden de 0.42. Le modèle sans la possibilité de transports en commun n’est pas très différent."
  },
  {
    "objectID": "trajets.html#projection-du-modèle-sur-lagglomération-de-la-rochelle",
    "href": "trajets.html#projection-du-modèle-sur-lagglomération-de-la-rochelle",
    "title": "La Ville Compacte, une solution aux émissions de gaz à effet de serre",
    "section": "6 Projection du modèle sur l’agglomération de la Rochelle",
    "text": "6 Projection du modèle sur l’agglomération de la Rochelle\nNous avons effectué la projection du modèle sur le territoire de La Rochelle au carreau INSPIRE de 200m. La procédure consiste à appliquer l’équation 1 en imputant au carreau 200m les variables nécessaires. Ces variables sont celles qui nourrissent les différents modèles et qui sont répertoriées dans le tableau 2.\nLa carte graphique 5 montre, par exemple, l’estimation du nombre moyen de kilomètres parcourus annuellement par un navetteur résidant dans chaque carreau d’habitation. Comme attendu, plus l’on s’éloigne des zones urbanisées, plus ce nombre de kilomètres augmente. Il est d’une certaine manière une traduction chiffrée de la dépendance à la voiture puisque, avec les modèles de comportements, nous avons pris ici en compte l’adaptation des comportements due à l’éloignement aux emplois.\n\n\n\nGraphique 5. Km parcourus en voiture par un navetteur pour ses déplacements professionels"
  },
  {
    "objectID": "trajets.html#scénarios-de-densification",
    "href": "trajets.html#scénarios-de-densification",
    "title": "La Ville Compacte, une solution aux émissions de gaz à effet de serre",
    "section": "7 Scénarios de densification",
    "text": "7 Scénarios de densification\nL’intérêt de cette modélisation ne réside pas uniquement dans le fait de pouvoir synthétiser les pratiques de mobilités observées à une maille fine, mais également dans la possibilité de prédire l’évolution de ces pratiques en fonction de certains changements, de certains scénarios de modification urbaine. Ici, pour éclairer le lien entre densité urbaine et émission de gaz à effet de serre, nous avons simulé tout un ensemble de scénarios de densification et estimé les conséquences sur les kilomètres effectués en voiture par les navetteurs.\nChaque scénario a consisté en un petit « choc » démographique –- l’ajout de 100 actifs –- au sein d’un IRIS donné. Comme notre modélisation suppose qu’il y a autant de navetteurs que d’emplois localisés sur le territoire, il fallait également définir comment évoluait la distribution spatiale des emplois. Nous avons considéré que celle-ci croissait de 100 nouveaux emplois répartis à proportion de la distribution initiale. Cette répartition d’emplois ne favorise aucun IRIS en particulier en posant l’indépendance de l’évolution des emplois par rapport aux IRIS. Elle est donc le plus neutre possible (puisqu’elle est correspond à la répartition à l’entropie max) et elle est similaire dans tous les scénarios présentés ici.\nOn notera que tous les IRIS ne font pas la même taille6. Le choc n’a donc pas le même impact localement et l’on pourrait se demander pourquoi nous n’avons pas plutôt envisagé des chocs migratoires proportionnels à la taille des IRIS. La raison est simple : nous nous intéressons ici avant tout aux conséquences globales, plus qu’à celles très locales, et il fallait donc mener les comparaisons en procédant à un choc de même importance globalement. Nous regardons ainsi comment le territoire « absorbe » ces 100 nouveaux navetteurs en fonction de l’IRIS où ils s’installent.\n6 Le plus petit contient 134 actifs, l’iris médian en contient 724, et le plus gros 2338.On notera également qu’il y a 91 743 navetteurs sur le territoire que nous observons. A cet aune, 100 de plus apparaît comme un petit « choc ». Il fallait vérifier si l’ampleur du choc bouleversait nos résultats et de quelle manière. Aussi avons-nous estimé le modèle avec des chocs plus importants (500, 1000, …), plus faibles (50, 10), voire négatifs (-10, -100). Il se trouve que l’ampleur du choc ne change pas grand chose sur le fond. En effet, notre principal élément de comparaison entre les scénarios est le nombre annuel de kilomètres parcourus en voiture par un résident actif sur le territoire de La Rochelle. Au premier ordre, cette quantité est assez simple à estimer à partir du scénario de référence (graphique 5) : si l’on ajoute x individus dans le carreau i alors on peut estimer qu’ils parcourent le nombre de kilomètres typique des résidents de ce carreau i dans le scénario de référence ; il suffit alors de recalculer la moyenne en prenant en compte les kilomètres de ces nouveaux arrivants. Soulignons que cette propriété de quasi-linéarité est une propriété souhaitable de notre modèle : l’ajout de quelques individus ne vient pas perturber les grands équilibres et chacun se comporte à peu près comme les autres résidents de son carreau d’arrivée. Sans cette propriété, le modèle serait instable. Bien entendu, plus l’on rajoute d’individus dans un carreau ou un IRIS, plus notre modèle va finir par faire apparaître des effets non linéaires, en raison notamment de la saturation des emplois de proximité, qui va obliger les nouveaux venus à chercher plus loin un emploi disponible. Et c’est exactement ce que l’on observe. Il reste que, en raison de cette quasi-linéarité, l’ampleur du choc n’est pas un facteur décisif pour estimer les élasticités présentées ici.\nOn notera enfin que les 100 actifs ajoutés ont à chaque fois les mêmes caractéristiques sociales. Nous avons retenu comme caractéristiques de référence celles du cas majoritaire : des actifs vivant en couple, avec un ou plusieurs enfants, possédant au moins une voiture et ayant le niveau de vie moyen du territoire. Ils ont donc le même modèle de comportements, ce qui ne veut pas dire qu’ils auront au final les mêmes pratiques. Selon les carreaux où ils s’installent, les pratiques seront différentes puisque les comportements s’adaptent à la situation géographique du carreau.\nLa carte graphique 6 fait clairement apparaître que le nombre de kilomètres parcourus en voiture par les navetteurs sur le territoire varie selon l’endroit où se produit la densification de population. L’élasticité du nombre de kilomètres sur la population totale (soit le ratio de la variation du nombre de kilomètres rapportée à l’ampleur du choc démographique) est négative au cœur de l’aire urbaine, dans le centre de La Rochelle, et devient positive à mesure qu’on s’en éloigne.\n\n\n\n\n\nGraphique 6. Elasticité de km voiture sur la population totale pour 100 nouveaux navetteurs dans l’IRIS\n\n\n\n\n\n\n\n\nCette carte conforte l’intuition commune qui associe une forte densité urbaine à une réduction des kilomètres parcourus en voiture et, donc, une réduction des émissions de gaz à effet de serre. Il est possible de préciser cette relation en examinant pour chacun des scénarios le lien entre l’élasticité des kilomètres rapportés au choc démographique et l’élasticité de la densité articulée (ou, terme que nous préférons, la densité ressentie) rapportés à ce même choc démographique."
  },
  {
    "objectID": "trajets.html#de-la-densité-aux-kilomètres",
    "href": "trajets.html#de-la-densité-aux-kilomètres",
    "title": "La Ville Compacte, une solution aux émissions de gaz à effet de serre",
    "section": "8 De la densité aux kilomètres",
    "text": "8 De la densité aux kilomètres\nLe graphique graphique 7 montre l’élasticité des kilomètres rapportés au choc démographique et l’élasticité de la densité ressentie rapportée à ce même choc. Nous aurions pu présenter le même graphique avec la densité urbaine au sens usuel mais, dans ce cas, le graphique aurait été simplement moins intéressant puisque l’élasticité de la densité urbaine est une constante dans tous les scénarios. Ce graphique aurait été unidimensionnel en écrasant la dispersion selon l’axe des abscisses. Mais il aurait fourni la même information sur l’élasticité des kilomètres parcourus en voiture sur la population.\nComme on peut le constater sur le graphique graphique 7, l’élasticité des kilomètres peut être aussi bien positive que négative. Pour un même choc démographique, une même variation de la densité urbaine, on peut avoir une dégradation du bilan kilométrique ou une amélioration. Une densification –- au sens usuel –- dans un des IRIS situés en haut du graphique conduit à dégrader le bilan kilométrique. Il s’agit des IRIS correspondant aux communes rurales, celles qui ont été identifiées comme éloignés des emplois. Et, inversement, une densification dans un des IRIS du bas du graphique améliore le bilan kilométrique par actif.\nIl est intéressant de relier cette simple analyse aux variations de l’élasticité de la densité ressentie7. On observe tout d’abord que l’élasticité de la densité peut être négative. En effet, lorsque l’on augmente le nombre d’individu dans une zone peu dense, deux effets contradictoires se combinent : d’un côté, on augmente la densité de cette zone, mais d’un autre côté, on augmente la probabilité qu’un individu pris au hasard soit un individu de cette zone peu dense, ce qui a pour effet de diminuer l’espérance de densité. Quand ce deuxième effet domine, la densité ressentie diminue. C’est ce qui se produit pour une partie des IRIS situés en haut du graphique : le choc démographique augmente le nombre de ruraux et diminue la densité ressentie. Pour ces IRIS, le bilan kilométrique se dégrade.\n7 La densité urbaine au sens classique se contente de faire une moyenne sur des unités spatiales au lieu de faire une moyenne sur des individus. Or, ce qui nous importe, c’est la densité autour de chaque individu. On peut l’illustrer simplement par le cas de deux unités spatiales où résident 10 individus. La densité urbaine usuelle est de 5 dans tous les cas. Pourtant, ce n’est pas la même chose de se répartir entre les deux unités spatiales en deux groupes égaux de 5 et 5 ou, par exemple, en un groupe de 9 et un de 1. Dans le premier cas, il y a dans chaque unité 5 individus qui cohabitent avec 5 individus (lui compris) : chacun perçoit une densité de 5 et la moyenne est donc de 5. Dans le dernier cas, ce sont 9 individus qui vivent auprès de 8 autres (plus lui-même), et 1 qui vit seul. Cette fois, on a 9 contributions à la densité qui s’élèvent à 9, soit 81, et une contribution qui vaut 1. La densité moyenne est de 8,2. Techniquement, la densité ressentie, c’est l’espérance de densité pour un individu pris au hasard ; la densité urbaine, c’est l’espérance de densité pour une unité spatiale prise au hasard.Dans le cadran en bas à droite du graphique, on a une autre composante attendue du lien entre densité et KVT : un choc démographique dans un IRIS très urbanisé – ici, le centre de La Rochelle – provoque à la fois une claire augmentation de la densité ressentie et une amélioration du bilan kilométrique par actif.\n\n\n\n\nGraphique 7. Elasticité de km voiture en fonction de la densité ressentie\n\n\n\n\n\n\n(a) pour un choc démographique ciblé dans un IRIS\n\n\n\n\n\n\n\n\n\n\n\nIl y a enfin un dernier cadran non vide, situé en bas à gauche, où le choc démographique n’a pas d’impact fort sur la densité ressentie tout en améliorant le bilan. Il s’agit de la première couronne autour de La Rochelle. Ainsi, un choc démographique dans cette zone précise a la particularité de ne pas être ressentie comme une densification tout en permettant une forte réduction des émissions de gaz à effet de serre. De nombreux opposants à la densification associent celle-ci à l’image de résidents entassées dans des tours, image qu’ils jugent repoussante. Or ce cadran montre qu’il existe des formes de densification écologique qui ne sont pas ressenties comme des fortes densifications."
  },
  {
    "objectID": "trajets.html#références",
    "href": "trajets.html#références",
    "title": "La Ville Compacte, une solution aux émissions de gaz à effet de serre",
    "section": "Références",
    "text": "Références\n\n\n(2022a), « Revenus, pauvreté et niveau de vie en 2017 - Données carroyées. Dispositif Fichier localisé social et fiscal (Filosofi) »,.\n\n\n(2022b), « Mobilités professionnelles en 2019 : déplacements domicile - lieu de travail Recensement de la population - Base flux de mobilité »,.\n\n\nBatty, M. (2013), The New Science of Cities, The MIT Press. https://doi.org/10.7551/mitpress/9399.001.0001\n\n\nBaude, M. (2022), « La décomposition de l’empreinte carbone de la demande finale de la France par postes de consommation : transport, alimentation, habitat, équipements et services », document de travail, n°59, Ministère de la transition écologique et de la cohésion des territoires.\n\n\nBettencourt, L. (2021), Introduction to Urban Science: Evidence and Theory of Cities as Complex Systems. https://doi.org/10.7551/mitpress/13909.001.0001\n\n\nBrownstone, D. & Golob, T.F. (2009), « The impact of residential density on vehicle usage and energy consumption », Journal of Urban Economics, vol. 65, n°1, pp. 91‑98. https://doi.org/10.1016/j.jue.2008.09.002\n\n\nCervero, R. (1989), « Jobs-Housing Balancing and Regional Mobility », Journal of the American Planning Association, vol. 55, n°2, pp. 136‑150. https://doi.org/10.1080/01944368908976014\n\n\nCervero, R. & Kockelman, K. (1997), « Travel demand and the 3Ds: Density, diversity, and design », Transportation Research Part D: Transport and Environment, vol. 2, n°3, pp. 199‑219. https://doi.org/10.1016/S1361-9209(97)00009-6\n\n\nConway, R.W. & Maxwell, W.L. (1962), « A queuing model with state dependent service rates », Journal of Industrial Engineering, vol. 12, n°2, pp. 132‑136.\n\n\nDantzig, G.B., Dantzig, G.B. & Saaty, T.L. (1973), Compact City: A Plan for a Liveable Urban Environment, W. H. Freeman.\n\n\nDuranton, G. & Turner, M.A. (2018), « Urban form and driving: Evidence from US cities », Journal of Urban Economics, vol. 108, pp. 170‑191. https://doi.org/10.1016/j.jue.2018.10.003\n\n\nEwing, R. (1997), « Is Los Angeles-Style Sprawl Desirable? », Journal of the American Planning Association, vol. 63, n°1, pp. 107‑126. https://doi.org/10.1080/01944369708975728\n\n\nEwing, R. & Cervero, R. (2010), « Travel and the Built Environment », Journal of the American Planning Association, vol. 76, n°3, pp. 265‑294. https://doi.org/10.1080/01944361003766766\n\n\nEwing, R. & Hamidi, S. (2015), « Compactness versus Sprawl: A Review of Recent Evidence from the United States », Journal of Planning Literature, vol. 30, n°4, pp. 413‑432. https://doi.org/10.1177/0885412215595439\n\n\nEwing, R., Hamidi, S., Tian, G., Proffitt, D., Tonin, S. & Fregolent, L. (2017), « Testing Newman and Kenworthy’s Theory of Density and Automobile Dependence », Journal of Planning Education and Research, vol. 38, pp. 0739456X1668876. https://doi.org/10.1177/0739456X16688767\n\n\nGaigné, C., Riou, S. & Thisse, J.-F. (2012), « Are compact cities environmentally friendly? », Journal of Urban Economics, vol. 72, n°2-3, pp. 123‑136. https://doi.org/10.1016/j.jue.2012.04.001\n\n\nGordon, P. & Richardson, H.W. (1997), « Are Compact Cities a Desirable Planning Goal? », Journal of the American Planning Association, vol. 63, n°1, pp. 95‑106. https://doi.org/10.1080/01944369708975727\n\n\nGrazi, F., Bergh, J.C.J.M.V.D. & Ommeren, J.N.V. (2008), « An Empirical Analysis of Urban Form, Transport, and Global Warming », The Energy Journal, vol. 29, n°4. https://doi.org/10.5547/ISSN0195-6574-EJ-Vol29-No4-5\n\n\nHensher, D.A. & Button, K.J. (dir.) (2007), « Handbook of Transport Modelling », Handbooks in Transport. https://doi.org/10.1108/9780857245670\n\n\nHirt, S. (2012), « Mixed Use by Default: How the Europeans (Don’t) Zone », Journal of Planning Literature, vol. 27, n°4, pp. 375‑393. https://doi.org/10.1177/0885412212451029\n\n\nHolden, E. & Norland, I.T. (2005), « Three Challenges for the Compact City as a Sustainable Urban Form: Household Consumption of Energy and Transport in Eight Residential Areas in the Greater Oslo Region », Urban Studies, vol. 42, n°12, pp. 2145‑2166. https://doi.org/10.1080/00420980500332064\n\n\nHolian, M.J. (2020), « The impact of urban form on vehicle ownership », Economics Letters, vol. 186, pp. 108763. https://doi.org/10.1016/j.econlet.2019.108763\n\n\nHsu, D., Andrews, C.J., T. Han, A., G. Loh, C., C. Osland, A. & P. Zegras, C. (2023), « Planning the Built Environment and Land Use Towards Deep Decarbonization of the United States », Journal of Planning Literature, vol. 38, n°3, pp. 426‑441. https://doi.org/10.1177/08854122221097977\n\n\nJacobs, J. (1961), The Death and Life of Great American Cities, Vintage Books (A Vintage livre).\n\n\nJenks, M., Williams, K. & Burton, E. (1996), « A Sustainable Future through the Compact City? Urban Intensification in the United Kingdom », Environments by Design, vol. 1, pp. 5‑20.\n\n\nJenks, M., Williams, K. & Burton, E. (dir.) (2003), « The Compact City: A Successful, Desirable and Achievable Urban Form? », in Routledge, pp. 54‑65. https://doi.org/10.4324/9780203362372-12\n\n\nLee, S. & Lee, B. (2020), « Comparing the impacts of local land use and urban spatial structure on household VMT and GHG emissions », Journal of Transport Geography, vol. 84, pp. 102694. https://doi.org/10.1016/j.jtrangeo.2020.102694\n\n\nLevine, J. (2010), Zoned Out: Regulation, Markets, and Choices in Transportation and Metropolitan Land Use, Taylor & Francis.\n\n\nLwasa, S., Seto, K.C., Bai, X., Blanco, H., Gurney, K.R., Kılkış, Ş., Lucon, O., Murakami, J., Pan, J., Sharifi, A. & Yamagata, Y. (2022), « Urban Systems and Other Settlements », in Cambridge, UK; New York, NY, USA, Cambridge University Press.\n\n\nMasson, V., Marchadier, C., Adolphe, L., Aguejdad, R., Avner, P., Bonhomme, M., Bretagne, G., Briottet, X., Bueno, B., Munck, C. de, Doukari, O., Hallegatte, S., Hidalgo, J., Houet, T., Le Bras, J., Lemonsu, A., Long, N., Moine, M.-P., Morel, T., Nolorgues, L., Pigeon, G., Salagnac, J.-L., Viguié, V. & Zibouche, K. (2014), « Adapting cities to climate change: A systemic modelling approach », Urban Climate, vol. 10, pp. 407‑429. https://doi.org/10.1016/j.uclim.2014.03.004\n\n\nMassot, M.-H. & Orfeuil, J.-P. (2007), « La contrainte énergétique doit-elle réguler la ville ou les véhicules ? Mobilités urbaines et réalisme écologique », Les Annales de la Recherche Urbaine, vol. 103, n°1, pp. 18‑29. https://doi.org/10.3406/aru.2007.2710\n\n\nMcFadden, D. (1974), « The measurement of urban travel demand », Journal of Public Economics, vol. 3, n°4, pp. 303‑328. https://doi.org/10.1016/0047-2727(74)90003-6\n\n\nMOBPERS (2021), « EMP 2019 Résultats détaillés de l’enquête mobilité des personnes de 2019 »,.\n\n\nMunafò, S. (2017), « Forme urbaine et mobilités de loisirs : l’« effet barbecue » sur le grill », Cybergeo: European Journal of Geography. https://doi.org/10.4000/cybergeo.28634\n\n\nMuñiz, I., Calatayud, D. & Dobaño, R. (2013), « The compensation hypothesis in Barcelona measured through the ecological footprint of mobility and housing », Landscape and Urban Planning, vol. 113, pp. 113‑119. https://doi.org/10.1016/j.landurbplan.2013.02.004\n\n\nNewman, P. & Kenworthy, J. (1989b), Cities and Automobile Dependence, Brookfield, Gower Technical.\n\n\nNewman, P. & Kenworthy, J. (1989a), « Gasoline Consumption and Cities », Journal of the Amrican Planning Association, vol. Winter 1989, pp. 24‑37. https://doi.org/10.1080/01944368908975398\n\n\nNewman, P. & Kenworthy, J. (1999), Sustainability and Cities: Overcoming Automobile Dependence, Island Press.\n\n\nOrfeuil, J.-P. & Soleyret, D. (2002), « Quelles interactions entre les marchés de la mobilité à courte et à longue distance ? », Recherche - Transports - Sécurité, vol. 76, pp. 208‑221. https://doi.org/10.1016/S0761-8980(02)00013-4\n\n\nPan, H., Shen, Q. & Zhang, M. (2009), « Influence of Urban Form on Travel Behaviour in Four Neighbourhoods of Shanghai », Urban Studies, vol. 46, n°2, pp. 275‑294. https://doi.org/10.1177/0042098008099355\n\n\nParodi, M. & Timbeau, X. (2023), « MEAPS : modéliser les flux de navetteurs », Document de travail de l’OFCE, n°11-2023.\n\n\nPatrick Bonnel (2001), Prévision de la demande de transport, thèse de doctorat, Lyon, France.\n\n\nRodier, C. (2009), « Review of International Modeling Literature: Transit, Land Use, and Auto Pricing Strategies to Reduce Vehicle Miles Traveled and Greenhouse Gas Emissions », Transportation Research Record, vol. 2132, n°1, pp. 1‑12. https://doi.org/10.3141/2132-01\n\n\nSavini, F., Ferreira, A. & von Schönfeld, K.C. (2022), Post-Growth Planning, Routledge. https://doi.org/10.4324/9781003160984\n\n\nSeto, K.C., Dhakal, S., Bigio, A., Blanco, H., Delgado, G.C., Dewar, D., Huang, L., Inaba, A., Kansal, A., Lwasa, S., McMahon, J., Müller, D.B., Murakami, J., Nagendra, H., Ramaswami, A., Bento, A., Betsill, M., Bulkeley, H., Chavez, A., Christensen, P., Creutzig, F., Fragkias, M., Güneralp, B., Jiang, L., Marcotullio, P., McCollum, D., Millard-Ball, A., Pichler, P., Salat, S., Tacoli, C., Weisz, H., Zwickel, T., Cervero, R. & Martinez, J.T. (2014), « 12 Human Settlements, Infrastructure, and Spatial Planning », in Cambridge, United Kingdom; New York, NY, USA, Cambridge University Press.\n\n\nSimini, F., González, M.C., Maritan, A. & Barabási, A.-L. (2012), « A universal model for mobility and migration patterns », Nature, vol. 484, n°7392, pp. 96‑100. https://doi.org/10.1038/nature10856\n\n\nStevens, M.R. (2017), « Does Compact Development Make People Drive Less? », Journal of the American Planning Association, vol. 38, n°1, pp. 7‑17.\n\n\nStouffer, S.A. (1940), « Intervening Opportunities: A Theory Relating Mobility and Distance », American Sociological Review, vol. 5, n°6, pp. 845. https://doi.org/10.2307/2084520\n\n\nThurner, S., Klimek, P. & Hanel, R. (2018), Introduction to the Theory of Complex Systems, Oxford University Press. https://doi.org/10.1093/oso/9780198821939.001.0001\n\n\nTukey, J.W. (1977), Exploratory Data Analysis, Addison-Wesley.\n\n\n\n\n\nGraphique 1. Lien entre densité moyenne et consommation de carburant par villes (Newman&Kenworthy 1989)\nGraphique 2. Rootogram du nombre de boucles domicile-travail pour les actifs hors IDF\nGraphique 3. 4 boucles domicile travail\nGraphique 4. Facteur K en fonction de la distance domicile-travail\nGraphique 6. Elasticité de km voiture sur la population totale pour 100 nouveaux navetteurs dans l’IRIS\nGraphique 7 (a). pour un choc démographique ciblé dans un IRIS"
  },
  {
    "objectID": "R/signature.html",
    "href": "R/signature.html",
    "title": "MEAPS",
    "section": "",
    "text": "MEAPS : distribution statistique des trajets entre le domicile et le travail\nCette application illustre les propriétés de MEAPS sur des simulations synthétiques. Pour plus de détails consultez le document de travail de l’OFCE 11-2023.\npar Maxime Parodi et Xavier Timbeau\n\n\n\n\nRéutilisationCC BY 4.0CitationVeuillez citer ce travail comme suit :\n(s. d.),."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "MEAPS",
    "section": "",
    "text": "Maxime Parodi est sociologue à l’OFCE\n \n\n\n\nXavier Timbeau est économiste et directeur principal de l’OFCE"
  },
  {
    "objectID": "theorie.html",
    "href": "theorie.html",
    "title": "Modéliser les flux des navetteurs : MEAPS",
    "section": "",
    "text": "Dans l’analyse des phénomènes spatiaux, la distance joue un rôle important. Cette évidence est ce qu’on appelle parfois le principe de Tobler :\n\nTout est relié mais les choses proches sont plus reliées que les choses éloignées.\n\nSi nous prenons l’exemple de l’appariement géographique des emplois et des résidents, la proximité de l’emploi est un facteur incontournable, même si d’autres facteurs interviennent dans le choix d’un emploi : le salaire, les compétences, etc. Le rôle de la distance lors du choix d’un emploi est évalué généralement à l’aide d’un modèle gravitaire. Peu d’alternatives ont été étudiées dans la littérature et le modèle gravitaire s’est imposé comme un standard, un outil que l’on peut oublier pour se consacrer à la prise en compte des autres facteurs.\nPourtant, en nous intéressant à la mobilité de la vie quotidienne à une échelle géographique fine – le carreau 200 mètres – nous nous sommes heurtés aux limites du modèle gravitaire, en particulier lorsqu’il a fallu se prononcer sur des scénarios de relocalisation de l’emploi. Ces limites tiennent à ce que le modèle gravitaire réduit le principe de Tobler à une mesure homogène de la distance. Il est possible d’améliorer nettement la compréhension des territoires en passant de la distance aux temps de transport selon les différents modes possibles. Plus finement encore, il est possible de passer à une notion de coût généralisé d’un déplacement, qui prend en compte différents aspects de ce trajet (son coût monétaire, son confort, sa fiabilité, etc.). Toutefois, ces améliorations de la « métrique » – certes indiscutables – ne font que changer l’input du modèle gravitaire, sans l’interroger. Or ce modèle souffre d’un défaut plus fondamental : il évacue ce qui fait la spécificité du spatial en voulant réduire celui-ci à une variable unidimensionnelle ; il évacue le fait que l’espace est habité et que chaque lieu est défini aussi par son voisinage.\nAinsi, le modèle gravitaire traite de la même façon les milieux urbains denses et les zones rurales. Il faudrait croire, par exemple, qu’un trajet d’une demi-heure en voiture est aussi pénible pour un gilet jaune que pour un Parisien. Or ce n’est évidemment pas le cas : celui qui réside en milieu rural fait de nécessité vertu et finit même par apprécier ces longs trajets quotidiens, tandis que celui qui réside dans des zones fortement urbanisées envisage des alternatives puisqu’il dispose d’un plus large éventail de possibles pour satisfaire ses demandes. Le défaut du modèle gravitaire n’est pas ici une simple histoire de relation subjective au temps de trajets. Plus fondamentalement, le défaut tient à ce que ce modèle ne voit pas l’espace ; il ne voit pas ce que le territoire offre ; il ne voit pas qu’en zone urbaine l’offre (d’emplois, de services, …) est plus ramassée et que cela change la manière de traiter les distances relatives et les coûts relatifs. La conséquence de cet aveuglement est que l’offre sur le territoire est traité comme si elle était homogène. Supposons, par exemple, que les pouvoirs publics souhaitent créer une zone industrielle offrant de nouveaux emplois. Le modèle gravitaire conduira à penser que les résidents en zone rural, parce qu’ils sont très parsemés, sont le plus souvent trop éloignés de la nouvelle zone d’emplois pour être intéressés : dans l’arbitrage entre utilité de l’emploi et coût du trajet, ce dernier devient rapidement si élevé qu’il semble préférable de renoncer à l’emploi. Or, l’arbitrage réel est loin d’être aussi simpliste car, bien entendu, un individu qui ne trouve pas d’emplois à proximité se résignera à faire plus de kilomètres pour travailler que quelqu’un qui, au contraire, vit près d’un centre économique dynamique. La distance ne pèse pas du même poids selon la quantité d’offre dans le voisinage.\nFace à ces anomalies liées au modèle gravitaire, nous proposons de nous appuyer sur une autre analogie : celle de la traversée par un flux de particules d’un matériau composé de sites d’absorption hétérogènes. Si l’on cherche un emploi dans une zone riche en emplois, la chance d’être satisfait à proximité de son point de départ sera importante, comme l’est la chance d’une particule d’être rapidement absorbée lorsqu’elle est entourée de sites absorbants. A l’inverse, si les emplois sont peu denses là où on réside, la distance à parcourir sera probablement plus grande, comme une particule traversant une zone de vide. En fait, la chance d’être absorbée ne dépend pas directement de la distance au site réceptacle ; elle dépend du nombre de sites qui sont traversées avant celui-ci. Ou, disons encore, elle dépend du rang de ce site dans le classement des sites du plus proche au plus éloigné. Cette analogie se trouve déjà chez Stouffer (1940) et Simini et al. (2012). Toutefois, les modèles qu’ils ont développés peuvent encore être améliorés, notamment en modélisant le fait que les sites d’absorption peuvent avoir une capacité limitée. Nous proposons donc un modèle qui tient compte de l’absorption et de la saturation. Il est de nature stochastique et, par un raisonnement de physique statistique, nous pouvons conjecturer une stationnarité des principales prédictions. Nous l’avons appelé Modèle Ergodique à Absorption et Saturation, qui s’abrège en MEAPS.\nCe modèle respecte tout autant le principe que ce qui est proche joue – toutes choses égales par ailleurs – un rôle plus important que ce qui est loin. Mais au lieu de la distance, on utilise le rang dans le classement des distances. La différence peut sembler mineure, mais elle répond à la question de l’hétérogénéité spatiale et de la densité des milieux traversés. Dans le modèle gravitaire, il arrive toujours un moment où, pour prendre encore un autre exemple, l’école est trop éloigné et où ça ne « vaut » plus le coût. Dans la perspective initiée par Stouffer, et reprise ici, l’école la plus proche, celle de rang 1, aussi éloignée soit-elle, demeure utile précisément parce qu’elle est la plus proche. La remarquable série de documentaires intitulée « Les chemins de l’école » souligne parfaitement que l’école la plus proche vaut toujours le coup, même si les écoliers doivent marcher plusieurs heures pour y aller.\nL’analogie employée permet de considérer le processus d’appariement comme résultant d’une procédure de recherche qui examinerait les opportunités dans l’ordre de leur proximité. Une telle procédure permet de spécifier des comportements qui servent de référence et d’hypothèse nulle pour se confronter aux données. Des amendements à la marge de cette procédure de recherche pourront produire un meilleur ajustement et s’interpréter directement. Pour l’heure, nous oublions ici tous les autres déterminants de l’appariement, comme le salaire, les compétences demandées ou offertes ou encore le secteur d’activités. Nous ajustons un modèle réduit à l’argument de la distance sur des données riches, issues du recensement français et mesurant les flux entre communes de résidence et communes d’emplois. Sous l’hypothèse que tous les emplois ne diffèrent que par leur localisation, nous parvenons à un ajustement de données bien meilleur que le modèle gravitaire. Des données plus riches – à supposer qu’elles existent – pourraient améliorer encore l’ajustement en introduisant les différences de salaires ou de compétences. Cependant, une prise en compte plus rigoureuse de la géographie nous semble une première étape essentielle, puisqu’elle modifie d’un ordre de grandeur au moins la qualité de l’ajustement.\nL’approche est donc structurelle : c’est un modèle même frustre qui définit la façon dont oin peut interpréter les données. Les données sans le modèles ne veulent pas dire grand chose, le modèle sans les données n’est que spéculation, et, suivant l’injonction de Kant, nous associons l’un avec les autres pour décrire la réalité.\nCe document décrit la construction du modèle théorique. Nous y développons la critique du modèle gravitaire et filons l’analogie du modèle radiatif. Le modèle complet n’est pas solvable dans une forme fermée. Nous décrivons donc un algorithme qui permet de le calculer. Dans une seconde partie (section 4) nous analysons les principales propriétés du modèle théorique sur des simulations synthétiques, c’est-à-dire générés explicitement. Ceci permet en particulier de donner de la vraisemblance, à défaut d’une démonstration, à la propriété d’ergodicité du modèle, qui conditionne la possibilité de le simuler.\nDans deux autres documents, nous procédons à l’estimation du modèle sur des données réelles et à une comparaison détaillée avec le modèle gravitaire et ses variantes les plus communes (Estimations à La Rochelle). Nous utilisons ensuite cette modélisation pour discuter du lien entre densité et émissions de CO2 (Ville compacte). Nous construisons également une carte en haute résolution des émissions de CO2 à La Rochelle à partir d’une projection qui intègre les comportements de fréquence et d’association de motifs pour différentes catégories de ménages."
  },
  {
    "objectID": "theorie.html#tobler-nimplique-pas-la-gravité",
    "href": "theorie.html#tobler-nimplique-pas-la-gravité",
    "title": "Modéliser les flux des navetteurs : MEAPS",
    "section": "",
    "text": "Dans l’analyse des phénomènes spatiaux, la distance joue un rôle important. Cette évidence est ce qu’on appelle parfois le principe de Tobler :\n\nTout est relié mais les choses proches sont plus reliées que les choses éloignées.\n\nSi nous prenons l’exemple de l’appariement géographique des emplois et des résidents, la proximité de l’emploi est un facteur incontournable, même si d’autres facteurs interviennent dans le choix d’un emploi : le salaire, les compétences, etc. Le rôle de la distance lors du choix d’un emploi est évalué généralement à l’aide d’un modèle gravitaire. Peu d’alternatives ont été étudiées dans la littérature et le modèle gravitaire s’est imposé comme un standard, un outil que l’on peut oublier pour se consacrer à la prise en compte des autres facteurs.\nPourtant, en nous intéressant à la mobilité de la vie quotidienne à une échelle géographique fine – le carreau 200 mètres – nous nous sommes heurtés aux limites du modèle gravitaire, en particulier lorsqu’il a fallu se prononcer sur des scénarios de relocalisation de l’emploi. Ces limites tiennent à ce que le modèle gravitaire réduit le principe de Tobler à une mesure homogène de la distance. Il est possible d’améliorer nettement la compréhension des territoires en passant de la distance aux temps de transport selon les différents modes possibles. Plus finement encore, il est possible de passer à une notion de coût généralisé d’un déplacement, qui prend en compte différents aspects de ce trajet (son coût monétaire, son confort, sa fiabilité, etc.). Toutefois, ces améliorations de la « métrique » – certes indiscutables – ne font que changer l’input du modèle gravitaire, sans l’interroger. Or ce modèle souffre d’un défaut plus fondamental : il évacue ce qui fait la spécificité du spatial en voulant réduire celui-ci à une variable unidimensionnelle ; il évacue le fait que l’espace est habité et que chaque lieu est défini aussi par son voisinage.\nAinsi, le modèle gravitaire traite de la même façon les milieux urbains denses et les zones rurales. Il faudrait croire, par exemple, qu’un trajet d’une demi-heure en voiture est aussi pénible pour un gilet jaune que pour un Parisien. Or ce n’est évidemment pas le cas : celui qui réside en milieu rural fait de nécessité vertu et finit même par apprécier ces longs trajets quotidiens, tandis que celui qui réside dans des zones fortement urbanisées envisage des alternatives puisqu’il dispose d’un plus large éventail de possibles pour satisfaire ses demandes. Le défaut du modèle gravitaire n’est pas ici une simple histoire de relation subjective au temps de trajets. Plus fondamentalement, le défaut tient à ce que ce modèle ne voit pas l’espace ; il ne voit pas ce que le territoire offre ; il ne voit pas qu’en zone urbaine l’offre (d’emplois, de services, …) est plus ramassée et que cela change la manière de traiter les distances relatives et les coûts relatifs. La conséquence de cet aveuglement est que l’offre sur le territoire est traité comme si elle était homogène. Supposons, par exemple, que les pouvoirs publics souhaitent créer une zone industrielle offrant de nouveaux emplois. Le modèle gravitaire conduira à penser que les résidents en zone rural, parce qu’ils sont très parsemés, sont le plus souvent trop éloignés de la nouvelle zone d’emplois pour être intéressés : dans l’arbitrage entre utilité de l’emploi et coût du trajet, ce dernier devient rapidement si élevé qu’il semble préférable de renoncer à l’emploi. Or, l’arbitrage réel est loin d’être aussi simpliste car, bien entendu, un individu qui ne trouve pas d’emplois à proximité se résignera à faire plus de kilomètres pour travailler que quelqu’un qui, au contraire, vit près d’un centre économique dynamique. La distance ne pèse pas du même poids selon la quantité d’offre dans le voisinage.\nFace à ces anomalies liées au modèle gravitaire, nous proposons de nous appuyer sur une autre analogie : celle de la traversée par un flux de particules d’un matériau composé de sites d’absorption hétérogènes. Si l’on cherche un emploi dans une zone riche en emplois, la chance d’être satisfait à proximité de son point de départ sera importante, comme l’est la chance d’une particule d’être rapidement absorbée lorsqu’elle est entourée de sites absorbants. A l’inverse, si les emplois sont peu denses là où on réside, la distance à parcourir sera probablement plus grande, comme une particule traversant une zone de vide. En fait, la chance d’être absorbée ne dépend pas directement de la distance au site réceptacle ; elle dépend du nombre de sites qui sont traversées avant celui-ci. Ou, disons encore, elle dépend du rang de ce site dans le classement des sites du plus proche au plus éloigné. Cette analogie se trouve déjà chez Stouffer (1940) et Simini et al. (2012). Toutefois, les modèles qu’ils ont développés peuvent encore être améliorés, notamment en modélisant le fait que les sites d’absorption peuvent avoir une capacité limitée. Nous proposons donc un modèle qui tient compte de l’absorption et de la saturation. Il est de nature stochastique et, par un raisonnement de physique statistique, nous pouvons conjecturer une stationnarité des principales prédictions. Nous l’avons appelé Modèle Ergodique à Absorption et Saturation, qui s’abrège en MEAPS.\nCe modèle respecte tout autant le principe que ce qui est proche joue – toutes choses égales par ailleurs – un rôle plus important que ce qui est loin. Mais au lieu de la distance, on utilise le rang dans le classement des distances. La différence peut sembler mineure, mais elle répond à la question de l’hétérogénéité spatiale et de la densité des milieux traversés. Dans le modèle gravitaire, il arrive toujours un moment où, pour prendre encore un autre exemple, l’école est trop éloigné et où ça ne « vaut » plus le coût. Dans la perspective initiée par Stouffer, et reprise ici, l’école la plus proche, celle de rang 1, aussi éloignée soit-elle, demeure utile précisément parce qu’elle est la plus proche. La remarquable série de documentaires intitulée « Les chemins de l’école » souligne parfaitement que l’école la plus proche vaut toujours le coup, même si les écoliers doivent marcher plusieurs heures pour y aller.\nL’analogie employée permet de considérer le processus d’appariement comme résultant d’une procédure de recherche qui examinerait les opportunités dans l’ordre de leur proximité. Une telle procédure permet de spécifier des comportements qui servent de référence et d’hypothèse nulle pour se confronter aux données. Des amendements à la marge de cette procédure de recherche pourront produire un meilleur ajustement et s’interpréter directement. Pour l’heure, nous oublions ici tous les autres déterminants de l’appariement, comme le salaire, les compétences demandées ou offertes ou encore le secteur d’activités. Nous ajustons un modèle réduit à l’argument de la distance sur des données riches, issues du recensement français et mesurant les flux entre communes de résidence et communes d’emplois. Sous l’hypothèse que tous les emplois ne diffèrent que par leur localisation, nous parvenons à un ajustement de données bien meilleur que le modèle gravitaire. Des données plus riches – à supposer qu’elles existent – pourraient améliorer encore l’ajustement en introduisant les différences de salaires ou de compétences. Cependant, une prise en compte plus rigoureuse de la géographie nous semble une première étape essentielle, puisqu’elle modifie d’un ordre de grandeur au moins la qualité de l’ajustement.\nL’approche est donc structurelle : c’est un modèle même frustre qui définit la façon dont oin peut interpréter les données. Les données sans le modèles ne veulent pas dire grand chose, le modèle sans les données n’est que spéculation, et, suivant l’injonction de Kant, nous associons l’un avec les autres pour décrire la réalité.\nCe document décrit la construction du modèle théorique. Nous y développons la critique du modèle gravitaire et filons l’analogie du modèle radiatif. Le modèle complet n’est pas solvable dans une forme fermée. Nous décrivons donc un algorithme qui permet de le calculer. Dans une seconde partie (section 4) nous analysons les principales propriétés du modèle théorique sur des simulations synthétiques, c’est-à-dire générés explicitement. Ceci permet en particulier de donner de la vraisemblance, à défaut d’une démonstration, à la propriété d’ergodicité du modèle, qui conditionne la possibilité de le simuler.\nDans deux autres documents, nous procédons à l’estimation du modèle sur des données réelles et à une comparaison détaillée avec le modèle gravitaire et ses variantes les plus communes (Estimations à La Rochelle). Nous utilisons ensuite cette modélisation pour discuter du lien entre densité et émissions de CO2 (Ville compacte). Nous construisons également une carte en haute résolution des émissions de CO2 à La Rochelle à partir d’une projection qui intègre les comportements de fréquence et d’association de motifs pour différentes catégories de ménages."
  },
  {
    "objectID": "theorie.html#sec-theorie",
    "href": "theorie.html#sec-theorie",
    "title": "Modéliser les flux des navetteurs : MEAPS",
    "section": "2 Principe de la modélisation",
    "text": "2 Principe de la modélisation\nPour modéliser les trajets entre des lieux de résidence et des lieux d’emploi, on procède usuellement par la méthode à 4 étapes (Dios Ortúzar & Willumsen, 2011 ; Patrick Bonnel, 2001). Cette méthode consiste dans un premier temps à déterminer d’un côté le nombre de trajets en partance d’un lieu de résidence et, d’un autre côté, le nombre de trajets arrivant au total dans un lieu d’activité. C’est l’étape 1 de génération des trajets. La seconde étape consiste à distribuer les trajets de l’étape 1 entre chaque paire origine-destination. C’est l’étape de distribution. La troisième étape est celle du choix modal où un mode de transport adéquat est associé à chaque trajet. Enfin la quatrième étape du modèle est celle qui spécifie le trajet et permet d’en connaître les caractéristiques précises, comme le chemin emprunté ou les dénivelés effectués, pour en déduire notamment des prévisions de congestion. Cette décomposition est quelque peu arbitraire et ne rend pas justice de l’état de l’art sur les bonnes pratiques pour articuler ces 4 moments. Par exemple, le nombre de trajets effectué dépend des possibilités ouvertes par la géographie, qui sont définies par les caractéristiques précises des trajets. L’étape 4 est donc nécessaire pour comprendre l’étape 1, et l’étape 4 demande de connaître les choix modaux pour être utile aux choix fait en 1. L’étape 2 est nécessaire pour explorer les possibilités de trajets. Les imbrications sont nombreuses entre les étapes et la décomposition n’interdit pas d’effectuer des allers et retours entre les diverses étapes.\nLe modèle que nous développons porte sur l’étape 2, celui de la distribution des trajets entre les différentes paires origines-destinations, ou encore résidences-emplois . Le modèle gravitaire est largement dominant dans cette deuxième étape pour prendre en compte le rôle de la distance dans l’arbitrage entre différentes destinations.\nNous discutons dans une première partie des insuffisances du modèle gravitaire (section 2.1). Puis nous présentons le modèle des opportunités intervenantes de Stouffer (1940) et le modèle radiatif de Simini et al. (2012) et Simini, Maritan & Néda (2013). Ils font tout deux intervenir le rang de classement des emplois plutôt que la distance (section 2.2) en s’appuyant sur une analogie plus adéquate aux échelles géographiques que nous considérons (commune, région) que celle de la gravitation. Enfin, dans la continuité de ces approches, nous développons un modèle qui repose sur les deux idées suivantes :\n\nLes individus font leurs arbitrages non pas en fonction directement de la distance, mais en fonction du rang (dans l’ordre des distances) des opportunités qui se présentent à eux. Une autre façon de le voir est de penser que la distance est une métrique moins adéquate que le nombre d’emplois accessibles dans un cercle de rayon donné.\nChaque destination a une capacité d’accueil limitée et il faut donc introduire une notion de saturation qui oblique les individus a aller voir ailleurs. De cette manière, nous donnons un fondement microscopique au respect des contraintes aux marges (tout individu a un emploi, tout emploi est occupé par un individu) (section 3).\n\nLa formulation finale est probabiliste et nous en analysons quelques propriétés par des simulations synthétiques (section 4), en montrant que l’on peut arriver rapidement à simuler un état indépendant des conditions initiales.\n\n2.1 Les insuffisances du modèle gravitaire\nLe modèle gravitaire développe une analogie avec le modèle de la gravitation universelle d’Isaac Newton dont les succès en physique et en mécanique sont indiscutables. Ce modèle s’impose comme la pierre angulaire de l’étape de distribution des trajets (Dios Ortúzar & Willumsen, 2011 ; Patrick Bonnel, 2001, pp. 160). Il est également utilisé dans d’autres domaines, comme le commerce international ou l’analyse des épidémies, domaines que nous ne discuterons pas ici.\n\nLes (mauvaises) raisons du succès du modèle gravitaire\nFormellement, le modèle gravitaire décrit la force d’une relation entre deux objets en fonction de leur distance et de leur masse respective. Par analogie, le modèle gravitaire consiste ici à évaluer le nombre de trajets professionnels entre deux localisations en prenant pour masses le nombre d’habitants au point de départ et le nombre d’emplois au point d’arrivée et, au dénominateur, une fonction f croissante de la distance. On a ainsi, en indiçant les points de départ par i et les points d’arrivée par j :\n\nT_{i,j} = \\frac {N_{hab, i}\\times N_{emp, j}} {f(d_{i,j})}\n\\tag{1}\nLes premiers modèles gravitaires ont emprunté la fonction f à la physique newtonienne (f=d^2), mais d’autres formulations ont depuis été proposées. Par exemple, la fonction f=e^{d/\\delta} intervient dans les modèles de choix discrets proposés par McFadden (Ben-Akiva & Lerman, 2018 ; McFadden, 1974). En remplaçant la distance par la notion de coût généralisé du transport, on peut relier cette forme fonctionnelle à un modèle de choix avec une fonction d’utilité aléatoire (random utility model). Il est également possible d’ajuster des formes fonctionnelles plus complexes en ajoutant des paramètres. Le modèle gravitaire arrive alors à reproduire plus ou moins des distributions de distances observées dans des enquêtes de mobilité.\nUn raisonnement par minimisation de l’entropie a été proposé par Wilson (1967) pour donner un fondement théorique à l’équation 1. Il considère l’état de référence comme étant celui qui est le plus fréquent dans une distribution aléatoire des choix. Wilson (1967) montre alors que, si la fonction f est donnée, l’équation 1 a bien la forme proposée et que c’est le produit des habitants et des emplois qui doit se trouver au numérateur (et non une puissance de l’un ou l’autre par exemple). Mais rien ne permet de trouver un fondement à la forme fonctionnelle de f. Le parallèle avec la physique est simple à faire : l’interaction définit le rôle de la distance, la maximisation de l’entropie permet d’en déduire que l’équation macroscopique dépend des masses agrégées, mais ne permet de dire quoique ce soit de plus sur la nature de l’interaction.\nComme le notent Simini et al. (2012), les fondations théoriques et empiriques de la fonction f sont au mieux faibles. La multiplication des paramètres pour améliorer l’ajustement n’ont le plus souvent aucune justification théorique. De fait, on perd souvent toute possibilité de donner une signification aux paramètres estimé ce qui rend l’exercice d’ajustement opaque. Les comportements asymptotiques soulignent également des incohérences : par exemple, en faisant tendre vers l’infini les emplois à l’arrivée, le modèle prédit un nombre infini de trajets, même si le nombre de résidents au départ est limité ! Il est également insatisfaisant que le modèle gravitaire soit déterministe et ne permette ni d’expliquer les fluctuations statistiques du nombre de trajets prédits, ni d’évaluer la vraisemblance de différents cas empirique.\nMais la critique la plus forte du modèle gravitaire vient de ses propriétés fondamentales et des conclusions que l’on peut en tirer. Le nombre de trajets entre une origine (la résidence) et une destination (l’emploi) repose sur un simple arbitrage entre distance et quantité de résidents ou d’emplois. Le comportement du modèle aux limites, à nouveau, suscite la perplexité : un seul emploi à l’origine devrait être infiniment préféré un très grand nombre d’emplois un peu plus loin. C’est tout à fait irréaliste et l’on devine déjà que la distance ne joue pas un rôle si direct dans les comportements de mobilité. On voit également que le poids relatif de cet emploi quasi central par rapport aux « masses » d’emplois éloignés va varier de manière irréaliste selon qu’il est plus ou moins proche de l’origine.\nComme le soulignait déjà Stouffer (1940), ce n’est peut-être pas tant la distance aux emplois qui est décisive que le rang de ces emplois selon l’ordre des distances. Dans le modèle gravitaire, il faut faire une grande différence entre le cas où le deuxième emploi le plus proche est à 500 m et le cas où il est à 1 km. Si l’on applique le modèle newtonien, il faudrait croire, par exemple, que l’attractivité de ce dernier emploi est divisée par 4. Qui peut croire que 500 m de différence pèsent d’un si grand poids dans une recherche d’emploi ? L’attractivité de l’emploi dépend avant tout du fait qu’il s’agit du deuxième emploi disponible près de chez soi. Empiriquement, il y a peu de doutes que le modèle gravitaire a de piètres performances : il ne parvient pas à expliquer pourquoi, lorsque la densité des emplois est faible autour d’un résident, celui-ci va envisager des trajets plus long pour atteindre des zones denses en emplois ; c’est pourtant une observation très commune qui devrait se retrouver dans une modélisation adéquate.\nSimini et al. (2012) donnent quelques exemples pour les Etats-Unis de la difficulté du modèle gravitaire à reproduire les comportements observés en en stylisant quelques régularités. A l’évidence, le modèle gravitaire ne prédit que des destinations proches et néglige complètement les destinations lointaines. Il semble impossible à la forme fonctionnelle f(d_{ij}) de rendre compte empiriquement à la fois du nombre de trajets courts et du nombre de trajets distants au travers d’un modèle susceptible de rendre compte des trajets dans différentes régions, dès lors que les densités y sont distribuées différemment.\nAssez peu de publications se risquent à une comparaison systématique du modèle gravitaire avec d’autres formulations qui respecteraient la première loi de Tobler. On peut citer Heanue & Pyers (1966) comme une des premières tentatives de ce genre. Un travail récent de (Lenormand, Bassolas & Ramasco, 2016) tend à conclure que le modèle gravitaire étendu aurait un meilleur pouvoir explicatif en ce qui concerne les flux de mobilités inter communaux, cet constant tenant pour de nombreuses zones considérés dans plusieurs pays. L’extension habituelle du modèle gravitaire consiste à écrire, où \\alpha, \\beta et \\delta sont des paramètres positifs :\n\nT_{i,j} = \\frac {N_{hab, i}^\\alpha \\times N_{emp, j}^\\beta} {d_{i,j}^\\delta}\n\\tag{2}\nLes paramètres estimés \\alpha et \\beta sont habituellement inférieurs à 1, ce qui pose un problème soulevé par (Simini, Maritan & Néda, 2013) : dans cette forme le modèle gravitaire est non additif. Si l’on considère une zone dans laquelle se trouvent des actifs (origine) ou des emplois (destination) et que l’on décide de la distinguer en deux zones distinctes et proches 1 et 2, les flux T_1 et T_2 prévus par la forme estimée de équation 2 ne sont pas la somme du flux que l’on prévoirait si on joignait 1 et 2 dans la même zone. La raison de cette distinction est que l’on modifie l’unité spatiale d’agrégation (Modifeable Areal Unit Problem) ou que l’on distingue des sous populations (par exmple par secteur) au sein de la zone initiale. Cette plus grande finesse de description peut se faire avec des comportements de flux différents (ce qui justifierait la distinction), mais dans le cas limite où ces populations ne sont pas distinguables, il n’y a pas de raison d’en attendre des comportements différents.\nLa propriété d’additivité à l’origine comme à la destination est vérifiée pour le modèle radiatif. Comme (Simini, Maritan & Néda, 2013) le suggèrent, les paramètres \\alpha et \\beta du modèle gravitaire peuvent s’expliquer à travers le modèle radiatif (voir plus bas). Ils résument l’information spatiale supplémentaire, et dépendent de la distribution spatiale jointe des masses aux origines et aux destinations. Mais ces deux paramètres sont alors très dépendants à la fois de cette structure spatiale, du découpage unitaire effectué ou de sous-périmètres considérés. En ce sens, ils rejoignent l’analyse de Fotheringham (1983) selon laquelle il manque au modèle gravitaire une information spatiale essentielle.\n\n\nLe voile de la contrainte aux marges\nLe modèle gravitaire peut être encore complexifié pour mieux coller aux données qu’il ne le fait spontanément. Il perd alors un lien clair avec les réflexions théoriques le reliant à la maximisation de l’entropie (Wilson, 1967) ou au modèle de choix discret. L’ajustement du modèle devient un exercice factice dans lequel il est difficile d’avoir confiance en particulier dans l’analyse des scénarios modélisés. L’exercice consiste à ajouter une étape de « normalisation » en incorporant des cœfficients correctifs en ligne et en colonne dans la matrice origine-destination, ce qui revient à ajouter des effets fixes à chacun des points de départ et d’arrivée. La formulation du modèle gravitaire est alors modifiée comme suit :\n\nT_{i,j} = a_i \\times b_j \\times \\frac {N_{hab, i}^\\alpha \\times N_{emp, j}^\\beta} {f(d_{i,j})}\n\\tag{3}\nLa détermination des cœfficients a_i et b_j pose de nombreux problèmes. Ces cœfficients doivent permettre de respecter les contraintes aux marges : la somme des emplois pour une ligne de résidents doit être égale au nombre des résidents employés dans la zone et la somme des résidents employés sur un lieu d’emploi doit, en colonne donc, être égale au nombre d’emplois en ce lieu. On a pour a_i (en remarquant que \\Sigma_j T_{ij} = N_{hab,i} et que \\Sigma_i T_{ij} = N_{emp,j} :\n\n\\begin{aligned}\na_i &{}= \\frac {\\Sigma_j T_{i,j}} {\\Sigma_j \\frac {b_j \\times N_{hab, i}^\\alpha \\times N_{emp, j}^\\beta}{f(d_{i,j})}} \\\\\n&{}= \\frac{N_{hab}^{1-\\alpha}} {\\Sigma_j \\frac{ b_j \\times N_{emp,j}^\\beta}{f(d_{i,j})}}\n\\end{aligned}\n\\tag{4}\n\\Sigma_j T_{i,j} est généralement directement observé ou estimé lors de l’étape de génération dans les approches dites à 4 étapes. C’est le nombre de départs depuis le point i et il est proportionnel aux nombre d’actifs résidant en i. De la même façon on peut écrire pour b_j une expression symétrique de celle de a_i, qui fait intervenir \\Sigma_i T_{i,j} qui est également observée ou estimé auparavant. C’est le nombre de trajets convergeant vers le point d’arrivée j, qui est proportionnel au nombre d’emplois en j.\n\n\\begin{aligned}\nb_j &{}= \\frac {\\Sigma_i T_{i,j}}\n{\\Sigma_i \\frac {a_i \\times N_{hab, i}^\\alpha \\times N_{emp, j}^\\beta} {f(d_{i,j})}} \\\\\n&{}= \\frac{N_{emp, j}^{1-\\beta}}{\\Sigma_i \\frac{a_i \\times N_{hab,i}^{\\alpha}}{f(d_{i,j})}}\n\\end{aligned}\n\\tag{5}\nLa valeur de a_i, pour un i donné, dépend de l’évaluation de tous les b_j et réciproquement l’évaluation de chaque b_j dépend de celle de tous les a_i. On peut estimer ces cœfficients par itérations successives et espérer atteindre de cette manière un point fixe, éventuellement unique à une constante multiplicative près. Des algorithmes de résolution ont donc été proposés dans les principaux manuels. L’application de tels algorithmes (comme celui de Furness, Dios Ortúzar & Willumsen (2011), p. 192) peut toutefois modifier le résultat proposé par l’expression du modèle gravitaire équation 2, au risque d’en trahir la logique et les justifications initiales. En outre, la multiplicité des solutions et le choix retenu par l’algorithme demeure un angle mort de ces méthodes.\nLa procédure de respect des marges aurait pu être formulée différemment, par exemple en utilisant des corrections additives au lieu de corrections multiplicatives ou une combinaison d’additivité et de multiplicativité. Dans tous les cas, rien ne garantit l’existence d’une solution unique et compréhensible. En toute généralité, ces procédures peuvent conduire à des équilibres multiples que l’algorithme de résolution va sélectionner sans que l’on puisse justifier quoi que ce soit. Mais surtout, chacune de ces procédures manque de fondements théoriques : les a_i et b_j ne sont jamais que des « patchs » ; ils ne correspondent à aucune caractéristique interprétable de la zone géographique étudiée.\nLe respect de la contrainte aux marges est le pendant global de la contrainte locale d’additivité. Ces deux propriétés illustrent l’incapacité du modèle gravitaire simple à respecter les aspects fondamentaux du problème. La « plasticité » opérationnelle du modèle gravitaire permet de l’appliquer à des observations en respectant les contraintes observées tout en laissant croire qu’un fondement théorique continue de justifier les opérations. Aussi l’approche gravitaire est-elle largement reprise dans des modèles appliquées (notamment les modèles Land Use Transport Interaction) en dépit de ses défauts majeurs, peut-être faute de mieux. Mais le décalage avec les données rend urgent de dépasser cette approche qui survit en se transformant en boîte noire.\n\n\n\n2.2 Une première alternative : le modèle radiatif\nLe modèle radiatif est l’une des rares alternatives au modèle gravitaire (Dios Ortúzar & Willumsen, 2011). Il reprend les intuitions de Stouffer (1940) avec son modèle des « intervening opportunities », dont la logique est la suivante : un migrant prévoit d’aller dans un endroit distant mais trouve en chemin des opportunités ; il s’interrompt alors en chemin. Cette distraction de son objectif initial est le résultat des opportunités rencontrées en chemins, « intervenantes ». La différence avec le modèle gravitaire est que ce n’est pas la distance qui détermine la destination, mais le nombre de rencontres. La distance et la structure géographique continuent de peser indirectement sur le choix des destinations puisque plus le migrant parcourt une grande distance, plus il a de chances de rencontrer des opportunités. La modélisation initiale de Stouffer souffre toutefois de quelques défauts1 et ne résout pas les questions de capacité ou de respect des contraintes sur les marges. Mais elle ouvre une autre perspective, où le rôle de la distance est médiatisé par le nombre d’opportunités rencontré, ce qui répond avec élégance aux insuffisances de l’analogie gravitaire.\n1 Notamment des défauts dans la formalisation qui repose sur une série d’approximation pas toujours explicitées et qui rend le modèle peu manipulable.Avec Stouffer, c’est ainsi une autre métrique qui est proposée en lieu et place de la simple distance spatiale. Elle est liée à la notion d’accessibilité, c’est-à-dire au nombre d’emplois (et plus généralement d’opportunités) auxquels à accès un individu pour un temps de trajet ou une distance maximaux fixés. Un emploi apparaît ainsi d’autant plus « éloigné » d’un individu qu’il y a d’emplois plus proches de lui. Le modèle gravitaire posait que les individus font une grande différence entre le cas où le deuxième emploi disponible est à 500 m et celui où cet emploi est à 1 km. Dans la nouvelle perspective, il n’y a pas de différence car il s’agit toujours du second emploi rencontré. Autrement dit, la distance est relativisée par la prise en compte du milieu qui est traversé. Plus le milieu est riche en opportunités, moins il est nécessaire d’aller loin et, inversement, plus le milieu est désert, plus il faut se résoudre à aller loin. Ce modèle a connu de nombreuses applications, notamment à Chicago (Ruiter, 1967).\nLa proposition de Simini et al. (2012) répond à certaines failles de Stouffer (1940) en proposant un modèle inspiré de la physique des radiations. Celui-ci décrit l’émission de particules et leur absorption par le milieu qu’elle traverse. L’intuition est la même que celle de Stouffer (1940) : tant qu’une particule ne rencontre pas d’obstacle, elle poursuit son chemin. Elle ne s’arrête qu’en rencontrant un site qui peut l’absorber, selon un certaine probabilité. Plus le milieu est dense en obstacles, plus la particule a des chances de s’arrêter. Dans ce modèle, la distribution des distances parcourues dépend du milieu et de la quantité de sites d’absorption rencontrés.\nPlus précisément, dans le modèle de radiation, chaque particule – ou individu – est tirée aléatoirement d’une distribution de probabilité avec une caractéristique z. Chaque point d’absorption, qui représente un lieu possible de travail, possède une masse d’emploi n_i et se voit attribuer une caractéristique z_i qui est aléatoire. Les lieux possibles sont classés par ordre de distance, comme dans le modèle de Stouffer (1940) et la particule les rencontre dans cet ordre. Le tirage de z_i est construit en tirant n_i fois des z dans la distribution de probabilité et en prenant le maximum de ces z. Plus la masse est grande en i, plus le z_{max} sera grand. La particule émise est absorbée si son z est plus petit que z_i. Pour représenter que la particule sera émise si elle n’est pas absorbée par son point de départ, son propre z est tiré par la même méthode, c’est-à-dire le maximum de m_i tirages où m_i est la masse d’opportunités en i.\nLe résultat principal de Simini et al. (2012) est particulièrement élégant. La valeur moyenne (notée \\langle T_{i,j}\\rangle ) des trajets partant de i et allant en j a une expression qui ne dépend pas de la distribution de probabilité des z. Elle prend l’expression suivante, où s_{i,j}=\\Sigma_{k \\in (i \\rightarrow j)^*} n_k est la somme des opportunités entre i (non inclus) et j (non inclus) :\n\n\\langle T_{i,j}\\rangle = T_i \\times \\frac {m_i \\times n_j}{(m_i + s_{i,j}) \\times (m_i + n_i +s_{i,j})}\n\\tag{6}\nA partir d’hypothèses générales assez simples, on obtient une formulation qui s’apparente au modèle gravitaire en remplaçant la distance par l’accumulation des opportunités entre deux points, dès lors que les opportunités sont classées dans l’ordre des distances. Cette formulation respecte autant que le modèle gravitaire le premier principe de Tobler, mais elle repose sur des hypothèses explicites et permet de mieux représenter les phénomènes déjà évoqués. Un départ dans une zone peu dense produira des trajets plus longs pour trouver un nombre équivalent d’opportunités à des trajets plus courts dans une zone dense. De plus, aucune étape de « normalisation » ad hoc n’est requise et le modèle est probabiliste, ce qui permet de produire des marges d’erreurs et des tests empiriques.\nLes applications du modèle radiatif à des données diverses (mouvements pendulaires travail-domicile, appels téléphoniques, migrations, logistique) produisent des distributions de trajets plus proches des données que le modèle gravitaire, mettant à mal la croyance selon lequel le modèle gravitaire serait un « bon » modèle, validé par les données.\nOn notera que le modèle de Simini et al. (2012) admet comme cas limite, sous certaines hypothèses de densité des emplois, le modèle gravitaire. En effet, lorsque la densité d’emplois est uniforme, l’accumulation des opportunités est proportionnelle à la surface et la moyenne de trajets entre i et j est une fonction en 1/r^4 (voir aussi Ruiter (1967)). Ce cas limite montre sous quelle condition (très particulière) le modèle gravitaire peut être valide. Ce cas limite montre également que la forme fonctionnelle employée dans le modèle gravitaire dépend fortement de la distribution de la densité des opportunités. Et c’est bien là un des éléments qui manque au modèle gravitaire.\n\n\n\n\n\n\nEncadré 1. Le modèle des opportunités concurrentes de Fotheringham\n\n\n\n\n\nLe modèle des opportunités concurrentes de Fotheringham (1983) conduit à une critique proche du modèle gravitaire de celle que nous conduisons. L’argument est que le modèle gravitaire ne permet pas de distinguer entre différentes configurations spatiales, si ce n’est lorsqu’il est contraint en ligne (chaque individu occupe un emploi et un seul) ou en ligne et en colonne (chaque emploi est occupé par un individu et un seul). Fotheringham Fotheringham (1984) conclut que l’estimation habituelle du modèle gravitaire est biaisée d’une variable omise qui représente la structure spatiale. Le modèle des opportunités concurrentes est basé sur un index d’accessibilité (différent de celui que nous utiliserons ensuite) qui mesure pour chaque individu et chaque opportunité j en quoi elle est accessible pour les autres individus (k \\neq i) par l’expression A_{ij}=\\sum_{p \\neq i,j}M_p/d_{pj}. Ce terme introduit la structure spatiale, parce qu’une opportunité entourée d’individus a un index d’accessibilité plus élevé. Il découle de l’interprétation de la procédure de contrainte du modèle gravitaire. Ajouté au modèle gravitaire avec un paramètre ( f_{ij} = I_i M_j^\\beta d_{ij}^\\delta A_{ij}^\\phi \\mu_{ij} où I_i est le nombre d’individus à l’origine, M_j l’attraction de la destination, d_{ij} la distance entre i et j et \\mu_{ij} est un bruit) il permet d’introduire explicitement la structure dans le modèle gravitaire sans la faire intervenir dans une deuxième étape lorsque de la simple ou double contrainte. Fotheringham interprète le paramètre \\phi comme indiquant soit des effets d’agglomération (\\phi&gt;0) soit des effets de concurrences entre sites d’attraction (\\phi&lt;0). Notons que cette approche ne garantit pas l’additivité ou le respect des contraintes en ligne ou en colonne.\n(Fik & Mulligan, 1990) intègrent à ce modèle celui des opportunités intervenantes pour en proposer une version plus riche dans la prise en compte de la structure. Si le constat sur les insuffisances du modèle gravitaire est le même et bien que l’analyse proposée par Fotheringham est particulièrement éclairante sur le biais de variable omise, nous verrons que notre proposition dans al lignée de Simini et al. (2012) diffère de celles-ci par l’explicitation de la façon dont la structure spatiale est prise en compte, ce qui permet aussi plus de finesse dans l’articulation des questions d’agglomération ou de concurrence ou encore de saturation.\n\n\n\nIl subsiste deux défauts au modèle radiatif de Simini et al. (2012). Le premier est le pendant de son élégance : il n’y a pas de paramètres pour l’ajuster, ce qui limite les capacités du modèle à rendre compte de la richesses des données. L’élégant calcul de la moyenne des trajets n’est valide que lorsque le processus sous-jacent suit parfaitement l’hypothèse des auteurs. Or, si l’on veut un modèle de base simple et clair sur le plan conceptuel, on veut aussi pouvoir enrichir le modèle avec des paramètres qui auraient du sens en regard de la richesse des données. Or la seule proposition qu’ils font dans ce sens consiste à introduire un \\varepsilon pour modifier le poids du point de départ dans le choix des trajets. Ceci ne répond que très partiellement à ce que l’on souhaiterait. A cet égard, le modèle gravitaire et encore plus le modèle de Fotheringham (voir encadré) sont richement dotés en paramètres, ce qui permet de les ajuster sur les données, au risque toutefois d’un biais lié à la mauvaise définition des paramètres du modèle qui peuvent « attraper » tout ce qui n’a pas été explicité.\nLe second défaut est que le modèle ne respecte pas les contraintes aux marges pour les destinations. Dans l’équation 6 le terme T_i permet de caler le modèle sur le nombre de départs de i. En revanche, il n’existe pas de pendant pour se caler sur les destinations j et il n’est donc pas possible au modèle de tenir compte d’une contrainte capacitaire : un nombre de particules supérieur au nombre d’emplois peuvent être absorbées en j. Là aussi, le modèle gravitaire peut passer par dessus ce problème par l’applicaiton de procédure de contrainte, qui pourrait aussi bien être appliquées au modèle de Simini et al. (2012). Mais ici aussi on perd en route la possibilité d’interpréter ce que produit cette procédure de respect des contraintes."
  },
  {
    "objectID": "theorie.html#sec-meaps",
    "href": "theorie.html#sec-meaps",
    "title": "Modéliser les flux des navetteurs : MEAPS",
    "section": "3 MEAPS : un Modèle Ergodique d’Absorption avec Priorité et Saturation",
    "text": "3 MEAPS : un Modèle Ergodique d’Absorption avec Priorité et Saturation\nNous proposons maintenant une version étendue et remaniée de l’approche de Stouffer (1940) qui répond aux critiques que nous faisons au modèle de Simini et al. (2012). Dans cette section, nous présentons le modèle dans sa forme plus simple avant d’en exposer les extensions les plus directes. Des simulations synthétiques permettent alors d’apprécier les grandes lignes du fonctionnement de ce modèle. Nous discutons ensuite des procédures d’estimation envisageables ainsi que du développement de mesures issues de ce modèle.\n\n3.1 Rang, choix des destinations et absorption\nOn considère I individus et J emplois2 localisés sur un territoire. Ces localisations sont fixes et exogènes, ce qui signifie que l’on ne s’intéresse pas au problème de choix de localisation. Non que ce choix ne soit pas important, mais nous nous intéressons à la distribution des trajets, une fois fixées les localisations. L’idée est que pour déterminer le choix de localisation, il faudra prendre en compte ce que la distribution des trajets, leur longueur ou leur coût généralisé nous apprend.\n2 Dans ce qui suit on regarde la relation entre résident et emploi ce qui suggère les mobilités domicile travail. C’est principalement pour fixer les idées, mais la relation entre résident et tout type d’aménités peut être abordée de la même façon. Il est également possible de décliner les résident selon des caractéristiques observables et d’indexer le modèle par ces catégories.On suppose que toutes les localisations sont séparées et qu’il n’y a donc qu’un individu ou qu’un emploi par localisation (les emplois et les individus peuvent être au même endroit, ça ne change rien). Chaque individu i classe par ordre de distance croissante les J emplois et les examine dans cet ordre. Il a une probabilité p_a de prendre un emploi (tous les emplois sont similaires et ont la même probabilité d’être pris). Tant qu’il ne prend pas d’emplois, l’individu continue sa recherche en passant à l’emploi suivant le plus proche (de son point de départ). La probabilité d’occuper l’emploi j est donc égale à la probabilité de ne pas occuper les emplois plus proches multipliée par la probabilité p_a d’occuper le poste j. En notant r_{i}(j) le rang de l’emploi j dans le classement des distances depuis i, on peut écrire \\bar F(j) la probabilité de dépasser le j^{ème} élément :\n\n\\bar F(j)=(1-p_a)^{r_i(j)}\n\\tag{7}\nOn définit également la probabilité de fuite de la zone considérée. Cette probabilité est celle qu’un individu ne trouve pas parmi les J emplois celui qui lui convient et donc qu’il renonce ou cherche plus loin. En supposant pour le moment que cette probabilité est la même pour tous les individus, p_f, on peut déterminer p_a :\n\np_a = 1-(p_f)^{1/J}\n\\tag{8}\nLa probabilité P_i(j) de i de s’arrêter en j est :\n\nP_i(j) = (1-p_a)^{r_i(j)-1} \\times p_a = {p_f}^{\\frac {r_i(j)-1} {J}} \\times (1-{p_f}^{1/J})\n\\tag{9}\nCette expression définit donc la probabilité pour un individu i d’occuper l’emploi j comme une fonction de la probabilité de fuite, le rang de l’emploi et le nombre total d’emploi. La rang de j n’est autre que le nombre d’opportunités cumulées du point de départ de i jusqu’à j et remplace la distance, comme dans les expressions de Stouffer (1940) ou de Simini et al. (2012). Ce nombre n’est autre que l’accessibilité aux emplois de l’individu i dans un cercle de rayon [ij], que ce rayon soit défini en utilisant une distance euclidienne ou d’autres mesures comme le temps de parcours. On notera que l’on considère ici que les emplois sont identiques ou, du moins, parfaitement substituables pour l’individu.\nChaque emploi a été supposé distinct spatialement des autres. Dans le cas où les emplois ne seraient pas séparés et pourraient s’accumuler en un point ou au sein d’un carreau, la formalisation ne change pas. La probabilité que l’on s’arrête dans le carreau c_d situé à une distance d de i où se trouvent k emplois se déduit de l’équation 7 puisque les k emplois ont des rangs successifs. En notant s_i(d)=\\sum _{j/d_{i,j}&lt;d}1 le cumul de tous les emplois qui sont à une distance strictement inférieure à celle du carreau considéré pour i (et donc à l’exclusion des k emplois du le carreau c_d), on a :\n\nP_i(i\\in c_d) = {p_f}^{s_i(d)/J}\\times(1-{p_f}^{ k/J})\n\\tag{10}\nEn prenant un développement limité au 1er ordre de cette expression (sous l’hypothèse que k est petit devant le nombre total d’opportunités J) , on obtient, en notant \\mu=\\frac{-log(p_f)}{J} :\n\nP_i(i\\in c_d) \\approx k\\times \\mu \\times e^{-\\mu \\times s_i(d)}\n\\tag{11}\nCette expression fait apparaître clairement le cœur du modèle. La proportion d’emplois venant de i dans le carreau est une fonction des emplois dans le carreau multiplié par l’accessibilité jusqu’à ce carreau de i.\nLorsque la densité des emplois est constante sur un plan, s_i(d) est proportionnel à la surface et le modèle devient une fonction de la distance avec un terme en e^{-r^2/\\rho^2}. Ici aussi, le comportement de notre modèle rejoint, sous cette condition très particulière d’une répartition homogène des opportunités, celui proposé pour un modèle gravitaire, lorsque celui-ci est spécifié avec une fonction de distance en e^{r/\\rho}. La forme favorite du modèle gravitaire se justifierait pour une répartition homogène des opportunités le long d’une droite3. Ce résultat diffère de celui de Simini et al. (2012), qui trouvaient un comportement asymptotique en 1/r^4.\n3 La littérature sur le commerce international fait un grand usage du modèle gravitaire et on y trouve des développements très riches. Le problème du commerce international est un peu différent de celui de l’analyse des distribution de déplacement parce qu’on observe les flux bilatéraux par produit de façon répétée entre les pays. On dispose ainsi d’une grande quantité d’informations à relier entre elles par la représentation gravitaire. La question du transport est différente en ce que la distance entre origines et destination est bien connue, mais que les trajets bilatéraux ne le sont pas. On dispose en revanche d’information sur la distribution des trajets en fonction de leur distance, de leur motif et des modes employés.Tout comme dans le modèle de Simini et al. (2012), le résultat est sans paramètre, parce que la probabilité de fuite est entièrement déterminée par la contrainte en ligne (l’individu i a une espérance égale à 1 - p_f de trouver un emploi dans la zone considérée).\n\n\n3.2 Saturation et priorité\nIl reste encore à prendre en compte la contrainte en colonne, c’est-à-dire le fait que chaque emploi peut être pourvu une fois et une seule. Au lieu d’un ajustement ad hoc qui tombe de nulle part, nous proposons le mécanisme suivant de remplissage des emplois : chaque individu i est classé selon un ordre de priorité. L’individu au premier rang est confronté à l’ensemble des emplois et nous calculons ses probabilités de prendre un emploi j par la formule précédente (équation 9). Les emplois sont alors partiellement remplis à proportion de ces probabilités4. Le deuxième individu est traité de la même manière, et ainsi de suite, jusqu’à ce qu’un ou plusieurs emplois soient totalement pourvu (lorsque la somme des probabilités dépasse tout juste 1). On retire alors ces emplois de la liste des choix possibles et on continue l’affectation pour les individus suivants sur la liste réduite. A chaque individu ajouté, on peut être amené à retirer d’autres emplois de la liste de recherche.\n4 En toute rigueur, les probabilités ne s’additionnent pas si simplement et un traitement exact exigerait de tenir compte de probabilités conditionnelles au fait que tel emploi a été pris, ou non, auparavant. La procédure décrite ici est une simplification, en subsituant aux probabilités conditionnelles des espérances.A la fin de ce processus, tous les individus ont des emplois (à p_f près) et tous les emplois sont pourvus dès lors que l’on pose I \\times (1 - p_f) = J. Cette attribution avec priorité est Pareto-optimale. Il n’est pas possible d’augmenter la satisfaction d’un individu sans dégrader celle d’un autre. A chaque étape, chaque individu réalise ses choix sans contrainte autre que l’éventuelle saturation provoquée par ses prédécesseurs. Pour augmenter sa satisfaction, c’est-à-dire lui permettre d’occuper en probabilité un emploi mieux classé pour lui, il faudrait dégrader la situation d’un prédécesseur en lui attribuant un emploi plus éloigné pour lui. Cette procédure d’affectation avantage les premiers du classement, mais tient compte des choix de chacun.\nFormellement, on note \\phi_u(i,j) la probabilité de disponibilité (\\phi vaut 0 si l’emploi est complètement pris) de l’emploi j pour un ordre de priorité donné u au moment où l’individu i doit choisir. La probabilité de cet individu i de prendre l’emploi j s’écrit alors :\n\nP_{u, i}(j) = \\lambda_{u,i}.\\phi_u(i,j). p_a \\prod_{l=1}^{r_i(j)-1}(1-\\lambda_{u,i}. \\phi_u(i,r^{-1}(l)).p_a)\n\\tag{12}\nCette expression est rendue complexe par la nécessité de parcourir les emplois dans l’ordre qui correspond à chaque individu. La probabilité p_a doit alors être calculée pour que le taux de fuite de i soit inchangé. On suppose que les emplois restants demeurent parfaitement substituables tout au long du processus d’affectation. La probabilité de chacun est donc identique et ajustée d’un facteur multiplicatif \\lambda_{u,i}. Le terme \\lambda_{u,i} découle ainsi de l’indisponibilité potentielle des emplois. Lorsqu’un emploi est indisponible, l’individu i, lorsque c’est son tour de choisir, connait ses cibles potentielles. Il ajuste donc sa probabilité d’absorption de façon à respecter la probabilité de fuite. C’est de cette manière que nous respectons la contrainte en ligne, qui s’exprime par l’équation 13 ci-dessous. Ceci signifie qu’un individu a d’autant plus de chances d’accepter un emploi qu’il reste peu de choix.\nUne autre solution serait de considérer que la probabilité de fuite n’est pas conservée et que les indisponibilités se traduisent par une fuite plus élevée. On peut tout à fait envisager des solutions plus complexes. Nous nous en tenons pour l’instant au cas simple où tous les individus ont la même chance de travailler dans la zone considérée5. Sous cette hypothèse de conservation de la probabilité de fuite, on a :\n5 En pratique, pour éviter les effets de bord, il faut choisir une zone d’emplois plus grande que la zone des résidents.\n\\forall i, \\prod_{j=1} ^{J} (1-\\lambda_{u,i} \\times \\phi_u(i,j) \\times p_{a})= p_f\n\\tag{13}\nLa solution de cette équation est celle d’un polynôme en \\lambda_{u,i} d’un ordre élevé. Il y a possiblement plusieurs solutions, mais il est nécessaire que 0&lt;\\lambda_{u,i}\\times p_a&lt;1, ce qui réduit le nombre de solutions admissibles. Pour un i donné, on peut en produire une solution approchée par un développement limité à l’ordre 1 en prenant le log de l’équation 13 :\n\np_{a} \\times \\lambda_{u,i} = \\frac {-log(p_f)}{\\sum_{j=1} ^{J} \\phi_u(i,j)}\n\\tag{14}\nOn peut vérifier que 0&lt;\\lambda_{u,i}\\times p_a&lt;1 lorsque J est assez grand et que le nombre d’emplois restant demeure élevé (en probabilité) par rapport à -log(p_f).\n\n\n3.3 Ergodicité\nChaque ordre de priorité u définit une trajectoire possible d’affectation des emplois aux résidents (ou l’inverse). On aboutit à chaque fois à un état possible de l’appariement résidents-emplois d’où l’on déduit les trajets professionnels. Bien entendu, le résultat final dépend de l’ordre de priorité choisi. Pour s’en affranchir, la stratégie usuelle en physique statistique consiste à réitérer la procédure pour tous les ordres possibles de priorité et à considérer la moyenne des résultats obtenus sur les I! ordres de priorité possibles.\nL’hypothèse ergodique consiste ici à soutenir que cette moyenne sur tous ces ordres de priorité est proche du régime permanent des trajets professionnels sur la zone considérée.\nLa première grandeur que nous moyennons sur les ordres u est la variable de disponibilités \\phi_u(i,j) de l’emploi j pour le résident i. Cette moyenne \\langle\\phi\\rangle_u(n,j) correspond à la probabilité de disponibilité de l’emploi j pour n’importe quel résident après que n résidents occupent d’ores et déjà un emploi ou ont fuit la zone. Cette grandeur ne dépend pas de i, mais uniquement du nombre de résidents déjà positionnés.\nUne deuxième grandeur nous sera utile. Il s’agit de l’accessibilité moyenne aux emplois disponibles. On peut noter A_n(i,k) le cumul des emplois qui restent disponibles pour i lorsque n résidents se sont d’ores et déjà positionnés, en comptant les emplois depuis le plus proche de i jusqu’au k^{ième} le plus proche. La grandeur qui nous intéresse est la moyenne sur tous les n possibles, soit :\n\n\\langle A \\rangle_n(i,k) = \\langle\\sum_{j, r_i(j)\\leq k} \\langle \\phi \\rangle_u(n,j) \\rangle _n\n\\tag{15}\nLa particularité de cette accessibilité est qu’à mesure que les emplois sont pris (lorsque n s’accroît), l’accessibilité se restreint puisqu’elle ne retient que la part encore disponible des emplois proches.\nComme précédemment, nous considérons que la probabilité de fuite d’un individu est une constante. Dans ce cas, la probabilité d’absorption va augmenter au fur et à mesure que les emplois sont pris : moins il reste d’emplois disponibles, plus un résident est prêt à accepter ceux qui restent. La probabilité P_a va donc dépendre de n et s’écrire ici P_{a,n}.\nPour un n donné, on a :\n\nP_f=\\prod_{k=1}^J(1-P_{a,n}\\times \\langle \\phi \\rangle_u(n, r_i^{-1}(k))\n\\tag{16}\nEn passant en log et en effectuant un développement limité, on obtient :\n\nlog(P_f)=-P_{a,n}\\times\\sum_{k=1}^J \\langle \\phi \\rangle_u(n,r_i(k))=-P_{a,n}\\times(J-(1-P_f)\\times n)\n\\tag{17}\nNous avons alors tous les éléments pour calculer la probabilité P_n(i,j) que le résident i prenne l’emploi j après que n résidents se sont déjà positionnés (cf. équation 9). En passant alors en log, on a :\n\nlog(P_n(i,j))=log(P_{a,n})+log(\\langle\\phi \\rangle_u(n,j))+\\sum_{k=1}^{r_i^{-1}(j)}log(1-P_{a,n}\\times \\langle \\phi \\rangle_u(n,r_i(k))\n\\tag{18}\nEn faisant un développement limité du dernier terme puis la moyenne sur les n, il en découle :\n\nlog(P_{ij})\\approx\\langle log(P_{a,n})\\rangle _n+\\langle\\langle\\phi\\rangle_u(n,j)\\rangle_n + \\langle A\\rangle_n(i, r_i(j))\n\\tag{19}\nLa probabilité P_{ij} s’écrit donc à partir de la probabilité moyenne d’absorption, de l’espérance que l’emploi j est disponible et de l’accessibilité moyenne. Sur le plan conceptuel, c’est tout à fait satisfaisant et compréhensible. Il reste que ces grandeurs ne peuvent pas être calculées directement ; il faut en passer par des simulations.\n\n\n3.4 Hétérogénéité de la fuite et de l’absorption\nNous avons considéré jusqu’à présent le cas où les individus et les emplois étaient parfaitement substituables. Cela simplifie le modèle et permet une résolution explicite. Il est cependant possible de complexifier le modèle en introduisant des paramètres interprétables qui permettent une meilleure prédiction et l’extraction d’informations des données.\nTout d’abord, le paramètre de fuite peut être spécifique à chaque commune de résidents ou chaque type de résidents. Par exemple, le recensement nous permet de mesurer la proportion d’individu, par commune, qui ont un emploi à plus de 100km de leur domicile. Cette proportion est faible (&lt;5\\% pour une région comme celle étudiée dans l’application à la Rochelle) mais peut varier d’une commune à l’autre pour diverses raisons : les communes ne sont pas toutes aussi bien desservies ; certaines se trouvent à la périphérie de la zone d’étude ; les caractéristiques moyennes des résidents varient d’une commune à l’autre… Le modèle peut sans difficulté prendre en compte une probabilité de fuite p_{f,i} pour chaque individu.\nEnsuite, le paramètre d’absorption était jusqu’à maintenant identique pour tous les emplois et tous les individus. On peut le rendre dépendant des emplois, p_{a,j}, pour marquer un effet fixe spécifique à des emplois, de manière à souligner l’attractivité de telle ou telle zone d’emplois. Le recensement nous donne quelques informations sur les trajets professionnels de commune à commune et, donc, sur l’attractivité différentielle entre communes. D’autres données pourraient nous informer à un niveau infra-communal. On pourrait aussi vouloir faire dépendre la probabilité d’absorption de caractéristiques observables des emplois. Des emplois dans une zone dense en emploi peuvent, au-delà de l’effet masse déjà pris en compte, être plus attractifs que des emplois isolés. Dans ce cas, l’absorption dépend de caractéristiques X observées et en spécifiant la forme fonctionnelle de p_a(X) on peut l’estimer de façon à mieux reproduire l’information sur la distribution des déplacements.\nLe modèle présenté est suffisamment flexible pour pouvoir rendre compte de phénomènes plus complexes afin de, à la fois, pouvoir exploiter des données riches et modéliser des comportements (de fuite, d’absorption) qui semblent avoir un sens. Si au lieu d’apparier les individus et les emplois, on s’intéresse au cas du choix des écoles, on peut imaginer que l’absorption de l’école la plus proche est élevée tandis que celles de rang supérieur s’effondrent rapidement. Si l’individu est indifférent aux caractéristiques des écoles, hors leur emplacement, il prend l’école la plus proche. Le refus de cette première école peut s’expliquer par une exigence parentale non observable, qui se traduit par une distance parcourue plus élevée. Mais le modèle de base rendant compte d’une baisse de l’absorption au-delà du premier rang sera vraisemblablement assez bon6. Il est possible aussi d’augmenter ou de diminuer l’absorption de certaines paires résidents-écoles, ce qui est une manière d’introduire par exemple les informations sur la carte scolaire.\n6 De façon plus générale, on peut spécifier une loi de la probabilité d’absorption quelconque qui doit vérifier que \\sum_{k=1,J} p_{i,r_i(k)} = p_{f,i} pour tout i. Toute paramétrisation de cette loi de probabilité peut alors être simulée et ajustée sur des données. Si les paramètres ont une interprétation théorique, on peut alors les identifier.On peut ainsi modifier les probabilités d’absorption en donnant à un groupe particulier de paires individus emplois plus ou moins de chances d’être absorbé. En jouant sur les groupes qui partitionnent les paires individus \\times emplois on peut augmenter ou réduire le nombre de degré de liberté du système. Lorsque seule la probabilité d’absorption est un paramètre, le nombre de degré de liberté est diminué de 1 et le paramètre p est déterminé par la condition d’égalité entre le nombre d’emplois pourvus et d’individus. Si on dispose d’une information sur la probabilité de fuite par individu ou par groupe d’individus, le nombre de degré de liberté peut être accru par une probabilité de fuite différenciée selon ces groupes. On peut encore accroître le nombre de degré de liberté en croisant une probabilité d’absorption par groupes d’emplois et groupes d’individus. Le choix de la spécification dépendra de ce que l’on souhaite réaliser et du problème considéré. On verra dans l’estimation à la Rochelle une application en recourant à un grand nombre de degrés de liberté afin d’ajuster le modèle sur des données détaillées (donnant pour des paires commune de résidence \\times commune d’emploi une observation des flux de mobilité professionnels). Dans une publication ultérieure, nous montrerons une détermination parcimonieuse des cœfficients correcteurs afin de pouvoir extraire une information pertinente des données de flux entre communes et de pouvoir comparer le pouvoir prédictif de MEAPS à celui d’un modèle gravitaire, à degré de liberté égal.\nEn indexant par i les probabilités de fuite p_{f,i} et par i,j les cœfficients correcteurs \\lambda_{i,j}, les équations principales du modèle deviennent :\n\nP_{i, u}(j) = \\lambda_{i,j} . p_{a} \\prod _{l=1} ^{r_{u(i)}(j)-1} {[1-\\lambda_{i,r_{u(i)}(l)}. p_{a}.\\phi_u(i,r_{u(i)}^{-1}(l))]}\n\\tag{20}\n\n\\prod _{l=1} ^{J} {[1-\\lambda_{i,r_{u(i)}(l)}.p_{a}.\\phi_u(i,r_{u(i)}^{-1}(l))]}= p_{f,i}\n\\tag{21}\nIl n’est pas possible de donner une forme réduite de cette dernière expression. En revanche, elle est calculable numériquement pour chaque u, i et j en fonction des hypothèses du modèle (p_{f,i}, p_{a,j}, la structure spatiale des résidents et des emplois) et sert de base à l’algorithme de calcul employé dans les simulations présentées dans la partie section 47.\n7 L’implémentation de cette expression est implémentée dans le package R {rmeaps} disponible dasn le dépôt github github.com/maxime2506/rmeaps et s’installe dans R par devtools::install_github(\"maxime2506/rmeaps\"). Il est utile de disposer d’un compilateur qui implémente OpenMP, ce qui demande quelques manipulations sur MacOS. L’implémentation est faite en C++/opemmp et repose sur la parallélisation pour traiter le parcours des ordres de priorités.Le modèle ainsi construit est flexible puisqu’on peut spécifier des processus de fuite (contrainte en ligne équivalente à la contrainte 4) et des processus d’absorption qui respecte la contrainte de saturation des emplois (contrainte en ligne équivalente à la contrainte 5) par le processus de priorité décrit en section 3.2. Le parcours de toutes les permutations possibles permet de s’affranchir d’un ordre de priorité particulier et de définir une solution moyenne au processus. Lorsqu’on analyse le problème avec une grille de taille finie (ou de taille inférieure au nombre J d’opportunités), on peut conjecturer un comportement ergodique des quantités moyennes prédites par le modèle. On résout de cette façon explicitement le problème de contrainte aux marges du modèle gravitaire ou du modèle radiatif.\nPour étudier quelques-unes des propriétés du modèle, nous proposons ici d’explorer son comportement sur des données synthétiques. Les données synthétiques, générées de façon explicites, permettent de contrôler les variations de paramètres afin d’en isoler les conséquences. Ces simulations ne prétendent ni à l’exhaustivité ni à la démonstration, mais peuvent servir à appuyer l’intuition. L’ensemble de la partie sur les simulations synthétiques est exécutable au sens de Lasser (2020). Les codes nécessaires à la reproduction de ces simulations et des graphiques associés sont disponibles sur github.com/xtimbeau/meaps et exécutables librement."
  },
  {
    "objectID": "theorie.html#sec-synth",
    "href": "theorie.html#sec-synth",
    "title": "Modéliser les flux des navetteurs : MEAPS",
    "section": "4 Simulations synthétiques",
    "text": "4 Simulations synthétiques\n\n4.1 Trois pôles en centre et satellites\nNous construisons un territoire abstrait composé d’un « centre ville » et de « deux périphéries » (graphique 1). Cette configuration arbitraire nous permet d’évaluer MEAPS en simulant les trajets et leur distribution. Chaque individu et chaque emploi sont localisés, distinctement les uns des autres, ce qui permet de calculer des distances euclidiennes entre chaque habitant et chaque emploi et d’en déduire un classement pour chaque habitant sans ambiguïté des emplois en fonction de leur éloignement. Tous les emplois sont considérés comme substituables et on suppose une probabilité de fuite identique de 10% pour tous les individus. Les distances entre les pôles sont données dans le tableau 1 (dans une unité quelconque).\n\n\n\n\nTableau 1. Distances entre les pôles\n\n\n\n\n\n\n\n\n\n\n\ne1\ne2\ne3\n\n\n\n\nh1\n0.00\n0.75\n0.75\n\n\nh2\n0.75\n0.00\n1.50\n\n\nh3\n0.75\n1.50\n0.00\n\n\n\n\n\n\n\n\n\n\n\nPour assurer l’égalité entre demandes et offres d’emploi, on tire aléatoirement 4 500 emplois. Les trois pôles d’emplois ont les mêmes centres que les pôles d’habitation, mais ont une répartition plus resserrée que pour les habitants. Comme indiqué sur la graphique 1, les tâches d’emplois sont respectivement localisés autour des mêmes centres que les zones d’habitation. Les pôles périphériques comportent moins d’emplois (15% chacun) que le pôle central (70% de l’emploi total) pour rendre compte d’une structuration habituelle où on trouve dans les pôles périphériques avant tout des emplois liés aux services fournis aux résidents (comme des commerces ou des écoles) tandis que la zone d’activité centrale rassemble une plus large palette d’emplois, en plus grand nombre. Nous ne faisons aucune distinction de productivité ou de qualification nécessaire pour les emplois. Cette hypothèse simplifie la simulation du modèle, mais rien n’empêche de distinguer des catégories d’emplois, des catégories d’habitants ni d’introduire des éléments de choix entre distance et nature de l’emploi. Nous ne considérons pas ici le choix de la localisation et considérons toutes les localisations comme exogènes.\nDans l’analyse statistique qui suit, on procédera à une agrégation spatiale en pavant le plan où sont localisés les emplois et les habitants par des hexagones adjacents. Ceci correspond à une analyse empirique où les données de localisation sont carroyées.\n\n\n\n\n\nGraphique 1. Territoire synthétique comportant un centre ville (h1) et deux villages (h2) et (h3). Dans chaque hexagone est indiqué la densité (5 000 habitants). 4 500 emplois avec des proportions d’emplois de 80% dans le centre et de 5% dans les 2 villages (les 10% restant sont la fuite). La dispersion est plus basse pour les emplois. Les densités d’emplois sont représentées dans le panneau de droite en orange.\n\n\n\n\n\n\n\n\nLa graphique 2 simule MEAPS à partir des données de graphique 1. On obtient pour chaque hexagone de résident une valeur moyenne de distance jusqu’à leur emploi. De la même façon, on calcule pour chaque emploi la distance accomplie en moyenne pour l’atteindre.\n\n\n\n\n\nGraphique 2. On représente sur le panneau de gauche les distances moyennes parcourues par les habitants d’un héxagone. La vignette présente la densité des trajets en fonction de la distance(vert). Sur le panneau de droite on représente les distances moyennes pour atteindre chaque emploi, ainsi que la densité de ces trajets par distance dans la vignette (orange)\n\n\n\n\n\n\n\n\nCette première représentation graphique permet de voir le fonctionnement du modèle MEAPS. On peut générer une distribution de trajets (dans les vignettes de la graphique 2). Comme la majorité des emplois se trouvent dans le pôle central, les distances moyennes pour les habitants y sont plus faibles que dans les autres pôles. Le modèle génère un peu de variance à l’intérieur de chaque pôle. On retrouve l’idée que les hexagones d’habitations les plus excentrées génèrent des distances plus importantes. La distribution des distances moyennes pour atteindre un emploi est plus resserrée que celle des distances parcourues en moyenne par habitant. Les moyennes de ces deux distributions sont égales (par construction).\nOn peut construire une table des flux entre chaque pôles (tableau 2). Le premier élément est de noter que les contraintes aux marges sont parfaitement respectées, ce qui est le principe de construction de MEAPS, les approximations faites dans l’algorithme de résolution restant ici inférieures à 10^{-5} au moins. Par ailleurs, la table de flux confirme le diagnostic précédent. La plupart des habitants de h1 (78%) se rendent dans g1 (le même pôle donc). Ce taux d’emploi « intrapôle » est de 42% pour les deux autres pôles. Ceci tient au déséquilibre de localisation des emplois et est une propriété souhaitée du modèle. Cela explique en partie la distribution des distances de la mobilité professionnell pour les habitants et également sa « réciproque », lorsqu’on calcule les distances moyenne vers un hexagone d’emplois.\n\n\n\n\nTableau 2. flux entre pôles\n\n\n\n\n\n\n\n\n\n\n\ne1\ne2\ne3\ntotal\n\n\n\n\nh1\n2 481\n335\n334\n3 150\n\n\nh2\n334\n290\n51\n675\n\n\nh3\n334\n50\n290\n675\n\n\ntotal\n3 150\n675\n675\n4 500\n\n\n\n\n\n\n\n\n\n\n\nPour apprécier le comportement du modèle, on peut procéder à une expérience de pensée dans laquelle on éloigne les deux pôles satellites du centre (la distance entre 1 et 2 ou 3 passe de 0.7 à 1.2 dans cette expérience). Le tableau 3 est obtenu en simulant à nouveau le modèle sur cette géographie alternative. Le résultat est identique à la configuration précédente. Ce résultat est conforme à l’intuition et est une propriété souhaitée du modèle. Puisque les ordres de classement ne changent pas (dès lors que les pôles sont assez éloignés et que la configuration demeure symétrique), les rangs ne sont pas modifiés et donc les flux sont inchangés. Les distributions des distances (sortantes et arrivantes) sont largement modifiées, puisque 2 ou 3 sont plus loin de 1, comme l’indique la graphique 3. On est tenté de conduire d’autres expériences de pensée pour analyser le comportement du modèle. L’application Shiny accessible à ofce.shinyapps.io/rmeaps permet de conduire toutes ces expériences en utilisant le même code que celui utilisé ici.\n\n\n\n\nTableau 3. flux entre pôles (pôle 3 plus loin)\n\n\n\n\n\n\n\n\n\n\n\ne1\ne2\ne3\ntotal\n\n\n\n\nh1\n2 482\n334\n334\n3 150\n\n\nh2\n334\n290\n51\n675\n\n\nh3\n334\n51\n291\n675\n\n\ntotal\n3 150\n675\n675\n4 500\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphique 3. Le graphique est construit comme le précédent, le pôle 3 est éloigné de 0.5 (70% plus loin) par rapport à 1.\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphique 4. Densités comparées des distances parcourues par habitant entre le scénario de référence et le scénario ‹pôle 3 plus loin›. Le trait pointillé est utilisé pour le scénario alternatif.\n\n\n\n\n\n\n\n\n\n\n4.2 Comparaison avec le modèle gravitaire\nComparer MEAPS au modèle gravitaire permet d’en comprendre les avantages. Pour ce faire, nous simulons un modèle gravitaire à double contrainte équation 3, c’est-à-dire permettant le calage sur les lignes (chaque individu a un emploi) et sur les colonnes (chaque emploi est pourvu). Ce modèle est simulé au niveau désagrégé, c’est-à-dire au niveau de chaque individu et de chaque emploi à partir de la configuration géographique décrite plus haut en section 4.1. La spécification du modèle gravitaire est faite en utilisant comme fonction f l’expression suivante où \\delta est un paramètre positif :\n\nf(d) = e^{d/\\delta}\n\\tag{22}\nIl s’agit d’un choix très commun. Le modèle gravitaire est ensuite normalisé en utilisant l’algorithme de Furness (Dios Ortúzar & Willumsen, 2011) dans lequel on normalise d’abord sur les lignes (chaque individu a un emploi et un seul en probabilité, en tenant compte du paramètre de fuite), puis sur les colonnes (chaque emploi est pourvu complètement). On itère ces normalisations en ligne puis en colonne jusqu’à obtenir une matrice de flux stable. Ces normalisations suivent les équation 4 et équation 5.\nCe modèle gravitaire ainsi spécifié est ajusté sur la simulation MEAPS en prenant comme référence les flux du tableau 2, construits par agrégation sur les groupes d’habitants et d’emplois – donc une matrice 3 \\times 3. L’ajustement est réalisé en calibrant le paramètre \\delta de façon à minimiser l’entropie relative de Kullback-Leitner des distributions agrégées (cette notion d’entropie est détaillée dans le document Estimations à la Rochelle). Le résultat de l’estimation est proposé dans le tableau 4 et correspond à une valeur de \\delta \\approx 0.68.\n\n\n\n\nTableau 4. Modèle gravitaire calé sur la configuration de référence\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMEAPS\nFuite à 10%\n\nGravitaire\nNormalisé, δ = 0.68\n\n\n\ne1\ne2\ne3\ntotal\n\ne1\ne2\ne3\ntotal\n\n\n\n\nh1\n2 481\n335\n334\n3 150\n\nh1\n2 447\n352\n350\n3 150\n\n\nh2\n334\n290\n51\n675\n\nh2\n353\n286\n36\n675\n\n\nh3\n334\n50\n290\n675\n\nh3\n350\n37\n288\n675\n\n\ntotal\n3 150\n675\n675\n4 500\n\ntotal\n3 150\n675\n675\n4 500\n\n\n\n\n\n\n\n\n\n\n\nL’ajustement du modèle gravitaire donne un bon résultat. Une des raisons de ce bon résultat découle de la symétrie de la configuration géographique. Les deux satellites sont à même distance du pôle central et la fonction f qui ne dépend que de la distance permet d’assurer une répartition des flux entre chacun des pôles sans trop de difficulté. Si on prend une configuration non symétrique, en éloignant un des deux satellites, l’autre restant à sa place, on obtient un schéma différent, le modèle gravitaire amplifiant les asymétries.\n\n\n\n\nTableau 5. Modèle gravitaire pour un satellite éloigné\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMEAPS\nFuite à 10%\n\nGravitaire\nNormalisé, δ = 0.68\n\n\n\ne1\ne2\ne3\ntotal\n\ne1\ne2\ne3\ntotal\n\n\n\n\nh1\n2 482\n334\n334\n3 150\n\nh1\n2 581\n285\n284\n3 150\n\n\nh2\n334\n290\n51\n675\n\nh2\n286\n367\n22\n675\n\n\nh3\n334\n51\n291\n675\n\nh3\n284\n23\n369\n675\n\n\ntotal\n3 150\n675\n675\n4 500\n\ntotal\n3 150\n675\n675\n4 500\n\n\n\n\n\n\n\n\n\n\n\nLe modèle MEAPS conserve une configuration identique dans le cas de pôles satellitaires éloignés du centre, parce que la configuration reste symétrique et qu’aucun rang n’est modifié. En revanche, le modèle gravitaire renvoie une réponse très différente de celle du cas de référence : les habitants des satellites se tournent plus vers les emplois de leur satellite respectif et les flux entre pôles satellites et le pôle central se réduisent. Cette propriété du modèle gravitaire est attendue : la fonction f donne un poids plus faible aux emplois plus distants. A la limite où cet éloignement devient particulièrement grand, les flux entre pôles satellites et le pôle central vont se tarir presque entièrement. Le paramètre estimé sur la simulation MEAPS est de l’ordre de 0.68, ce qui est l’ordre de grandeur du rayon du pôle central (0,5). Pour une distance de quelques fois 0.68, les flux entre pôles seront quasi nul. La réponse de MEAPS parait ici plus adaptée à ce que l’on observe. Lorsque des communes sont satellites d’un pôle central à une distance de quelques dizaines de kilomètres, il existe des flux vers cette commune pour occuper des emplois, et le fait que la commune soit plus éloignée de quelques kilomètres ne tarit pas drastiquement ces flux. On s’attend à une faible sensibilité de la distance à cette échelle. Nous verrons lors de l’application à l’agglomération de la Rochelle, en utilisant des données décrivant les flux entre commune de résidence et commune d’emploi (issues de MOBPRO (2022)) que MEAPS permet une meilleure représentation de la réalité que le modèle gravitaire.\nSi l’on reconduit la procédure d’estimation du paramètre \\delta sur la configuration géographique où les pôles satellite sont éloignés on aboutit à \\delta \\approx 0.95. Cette valeur est très différente du paramètre précédent, ce qui montre à la fois la « plasticité » du modèle gravitaire et son manque de fiabilité, comme si la force « gravitationnelle » pouvait changer du tout au tout à chaque nouvelle donnée (tableau 6).\n\n\n\n\nTableau 6. Modèle gravitaire réajusté, satellite éloigné\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMEAPS\nFuite à 10%\n\nGravitaire\nNormalisé, δ = 0.95\n\n\n\ne1\ne2\ne3\ntotal\n\ne1\ne2\ne3\ntotal\n\n\n\n\nh1\n2 482\n334\n334\n3 150\n\nh1\n2 455\n348\n347\n3 150\n\n\nh2\n334\n290\n51\n675\n\nh2\n348\n288\n39\n675\n\n\nh3\n334\n51\n291\n675\n\nh3\n347\n39\n289\n675\n\n\ntotal\n3 150\n675\n675\n4 500\n\ntotal\n3 150\n675\n675\n4 500\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.3 Procédure d’estimation\nIl est possible de modifier les pondérations des probabilités d’absorption de façon à modifier la table des flux. Ceci est illustré dans la table suivante où on a doublé pour chacune des 9 paires possibles de zone d’habitation (3) et de zone d’emploi (3) la probabilité relative d’absorption successivement. La configuration géographique est celle de la graphique 1, avec un centre et deux satellites. Le centre comporte plus d’emplois que de résidents, ce qui oblige à des flux entrants dans la zone 1 comme indiqués dans la- tableau 2. On parle de doublement relatif de la probabilité, parce que les contraintes de constance de probabilité de fuite et de saturation des emplois imposent une réduction des probabilités d’absorption des autres emplois, ce qui est assuré dans l’algorithme qui implémente MEAPS.\nLe tableau 7 décrit les variations de flux par rapport à une situation de référence (celle du tableau 2), arrondi à l’entier le plus proche. Il y a donc 3 \\times 3 matrices 3 \\times 3. Chacune des sous matrices indique les variations de flux pour chaque paire origine-destination ; il y a 9 possibilités de doublement de la probabilité d’absorption, qui constituent les lignes et les colonnes de la matrice englobante. On notera que les sommes des colonnes et des lignes de chaque sous matrice sont nulles, ce qui indique le respect des contraintes en ligne et en colonne.\nConformément à l’intuition, et malgré les effets induits par le respect des contraintes en ligne et en colonne, on observe bien que la paire zone d’habitation-zone d’emploi qui se voit augmentée en probabilité relative connait des flux supérieurs. Pour compenser ces flux supérieurs, dans la même colonne, c’est-à-dire pour les flux en provenance des autres zones d’habitation, on constate systématiquement une diminution des flux en provenance des autres zones d’habitation. Symétriquement, un accroissement des flux de la zone d’habitation i vers la zone d’emploi j induit toujours une diminution des flux de i vers les autres zones d’emploi.\n\n\n\n\nTableau 7. Modification de la probabilité d’absorption\n\n\n\n\n\n\n\n\n\n\n\n\ne1\ne2\ne3\n\n\ne1\ne2\ne3\ne1\ne2\ne3\ne1\ne2\ne3\n\n\n\n\nh1\nh1\n76\n−38\n−38\n−72\n55\n17\n−72\n17\n55\n\n\nh2\n−38\n27\n11\n81\n−63\n−18\n−9\n1\n8\n\n\nh3\n−38\n11\n27\n−9\n8\n1\n81\n−18\n−63\n\n\nh2\nh1\n−59\n75\n−15\n75\n−76\n1\n2\n−26\n24\n\n\nh2\n51\n−58\n7\n−80\n87\n−7\n7\n−13\n5\n\n\nh3\n9\n−17\n8\n5\n−11\n7\n−9\n39\n−30\n\n\nh3\nh1\n−59\n−15\n75\n2\n24\n−26\n75\n0\n−76\n\n\nh2\n9\n8\n−17\n−9\n−30\n39\n5\n7\n−12\n\n\nh3\n51\n7\n−58\n7\n5\n−12\n−80\n−7\n87\n\n\n\nLe tableau représente l’écart entre les flux obtenus pour une probabilité d’absorption doublée pour la zone i d’habitation et la zone j d’emploi, pour chaque paire de zones habitation/emploi. La première matrice en haut à gauche indique donc que le flux entre la zone 1 d’habitation et la zone 1 d’emploi est accru de 76 lorsque la probabilité d’absorption relative est doublée. Pour compenser ce flux plus important entre 1 et 1, le flux en la zone d’habitation 2 et l’emploi 1 est réduit de 38, ce qui implique à son tour que ceux entre 2 et 2 et entre 2 et 3 s’accroissent.\n\n\n\n\n\n\n\n\n\n\n\n\nUne propriété intéressante des matrices du tableau 7 est que les 9 matrices 3 \\times 3 forment un espace vectoriel de dimension 48. Ceci est attendu, puisque les contraintes réduisent la dimension de 9 (=3\\times 3) à 4, puisqu’il y a 3 contraintes dans chaque dimension (lignes et colonnes) et qu’une est redondante (si les somme sur chaque ligne sont nulles, alors la somme de tous les cœfficients est nulle et donc si les sommes sur deux colonnes sont nulles, la troisième l’est nécessairement). Cela indique que, au moins localement (au voisinage de la matrice de flux calculée dans le tableau 2), il est possible de modifier les probabilités d’absorption pour atteindre n’importe quelle matrice de flux. A l’approximation linéaire près, il est donc possible de reproduire n’importe quelle structure de flux agrégés par un jeu de paramètres saturant exactement la dimension de cette structure de flux. Cette propriété permet d’envisager différentes approches d’estimations, suivant les données dont on dispose et du nombre de degrés de liberté que l’on est prêt à consacrer à la reproduction des données.\n8 Les valeurs propres de la matrice 9 \\times 9 constituée des 9 vecteurs colonnes des 9 matrices « dérivées » sont (133.3, 97.3, -28.6, 22.0, 0, 0, 0, 0, 0). Les 5 valeurs propres nulles et les 4 non nulles permettent de conclure que la dimension de l’espace vectoriel engendré par les 9 matrices est 4.Le temps de calcul peut être assez long du fait de la nécessité de répéter un grand nombre de tirages, mais la section suivante (section 4.4) montre que ce nombre peut rester raisonnable. Une estimation de ce type est mise en œuvre par une procédure itérative dans le document Estimations à la Rochelle, permettant de reproduire à l’aide de MEAPS les données issues de l’enquête mobilités professionnelles MOBPRO (2022) avec un schéma de calcul qui peut se mettre facilement en œuvre.\n\n\n4.4 Ergodicité en pratique\nL’utilisation de données synthétiques permet de tester simplement l’hypothèse d’ergodicité. On a conjecturé que les différentes grandeurs moyennes sur les permutations u étaient assimilables à des observations, éventuellement répétées. A ce stade de simulations synthétiques nous ne confrontons pas le modèle à des observations (voir Estimations à la Rochelle), mais nous allons montrer que l’estimation des valeurs moyennes ne demande pas l’examen des I! permutations possibles9 et peut se contenter d’une agrégation spatiale et de quelques tirages de permutations.\n9 Par la formule de Stirling log_{10}(I!) \\approx (n +1/2)log_{10} n +log_{10}\\sqrt{2} - n log_{10}e \\approx 5\\times10^5 pour I=10^5, ce qui fait un nombre de grande taille.Pour illustrer cette propriété, nous répétons les simulations du modèle pour plusieurs tirages de priorités (notés u dans la section section 3.3), suivant une méthode de Monte-Carlo. En prenant la moyenne sur un échantillon de u, on peut construire un estimateur des grandeurs moyennes et montrer qu’avec un échantillon petit par rapport à I!, on peut les estimer avec fiabilité et dans un temps raisonnable. Cette propriété sera montrée sur la structure géographique particulière que nous avons synthétisée, sans que cela permette de le généraliser avec certitude. Il existe sans doute des configurations spatiales pathologiques qui contredisent cette conjecture.\nLa graphique 5 illustre les processus stochastiques à l’œuvre dans le modèle et leur résolution par la moyennisation sur les tirages possibles. On applique le modèle en tirant aléatoirement des permutations de priorité entre les résidents. On représente alors pour quelques hexagones d’habitation (tirés au sort) l’ensemble des choix de destination (carroyés dans les hexagones). Le carroyage opère déjà une moyennisation puisque chacun des individus de chaque hexagone a un ordre de priorité différent. On représente alors les quantités d’emplois (la probabilité de choisir un emploi qui se trouve dans l’hexagone d’arrivée). Les lignes blanches illustrent la dépendance au tirage de priorité. Mais au bout de quelques tirages, ces probabilités convergent en moyenne. Pour simuler le modèle, il n’est pas nécessaire (en toute vraisemblance) de parcourir l’univers complet des permutations.\n\n\n\n\n\nGraphique 5. Chaque ligne blanche représente pour un carreau de départ et d’arrivée (tous les carreaux d’arrivée sont représenté par une ligne, pour une sélection aléatoire de 4 carreaux de départ) la probabilité de prendre l’emploi dans le carreau d’arrivée en fonction du tirage aléatoire. Les lignes vertes représentent cette même probabibilité prise en moyenne sur les tirages cumulés. L’échelle de l’axe des y est logarithmique.\n\n\n\n\n\n\n\n\nLe tableau 8 indique les intervalles de confiance à 90% que l’on peut construire à partir des simulations précédentes. On obtient une stabilité satisfaisante, bien que les flux agrégés soient stochastiques. Pour une centaine de tirages on peut obtenir une précision supérieure à 10^{-3}.\n\n\n\n\nTableau 8. flux entre pôles, intervalles de confiance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ne1\ne2\ne3\n\n\n\n\nh1\n2481[2472; 2490]ε≈0.1%\n335[330; 340]ε≈0.5%\n334[329; 339]ε≈0.5%\n\n\nh2\n334[327; 342]ε≈0.6%\n290[284; 295]ε≈0.6%\n51[49; 53]ε≈2%\n\n\nh3\n334[327; 341]ε≈0.6%\n50[49; 52]ε≈2%\n290[286; 295]ε≈0.5%\n\n\n\nSource: MEAPS, intervalle à 95%, 1024 tirages\n\n\n\n\n\n\n\n\n\n\n\n\nLe schéma de saturation et de priorité est illustré par la graphique 6 ci-dessous. Pour chaque carreau d’arrivée (un emploi), on représente le rang moyen (gauche) et son écart-type (droite) au moment de la saturation. La caractère stochastique découle du tirage aléatoire de l’ordre de chaque individu (les carreaux de départ). Pour la plupart des emplois, le rang moyen de saturation ergodique est atteint très rapidement. Les lignes blanches sont rapidement horizontales, indiquant une rapide convergence du rang moyen au fur et à mesure que les tirages s’accumulent. Ce graphique confirme qu’à quelques exceptions près, l’état du système est stable après quelques tirages. Le panneau de droite illustre l’écart-type observé sur les tirages cumulés. La nature stochastique du modèle induite par les tirages est ainsi illustrée.\n\n\n\n\n\nGraphique 6. Chaque ligne blanche représente pour un carreau d’arrivée (tous les carreaux d’arrivée sont représenté par une ligne) le rang moyen (panneau gauche) et l’écart type du rang (panneau de droite).\n\n\n\n\n\n\n\n\n\n\n4.5 Tension localisée par emploi\nLe rang moyen au moment de la saturation est une information qui peut être utilisé pour construire un indicateur localisé de tension comme sur la graphique 7. L’indicateur de tension donne une information distincte de la distance moyenne ou de la densité de population ou d’emploi. Les emplois les plus tendus se trouvent sur l’axe qui relie des pôles. Les emplois situés à la périphérie du pôle central ont un niveau de tension proche (mais un peu supérieur) à ceux situés dans les satellites sur la bordure pointant vers le pôle central. Ces éléments peuvent être utilisés pour identifier les zones pertinentes de développement de l’emploi.\n\n\n\n\n\nGraphique 7. Indicateur de tension relatif localisé égal au rang de saturation normalisé à 100% (0% pour l’emploi saturé le plus tard, 100% pour l’emploi saturé le plus tôt, en moyenne sur chaque hexagone d’emploi).\n\n\n\n\n\n\n\n\nL’expérimentation dans l’application Shiny permet d’étudier différentes propriétés de l’indicateur de tension, en particulier lorsque la tension globale est forte (moins d’emploi que de résidents) ou faible (excès d’emplois sur les résidents). Dans le cas où il y a un excès d’emploi sur les résidents, il est possible d’observer une tension locale sur certains emplois.\n\n\n4.6 Simulation synthétiques dans Shiny\nL’application shiny rmeaps permet de générer des géographies synthétiques et de simuler le modèle MEAPS sur ces distributions. La plupart des graphiques de ce chapitre peuvent être reproduits de cette façon. L’application permet de choisir la taille du problème (n le nombre d’actifs et k le nombre d’emploi). En choisissant plus d’emplois que d’actifs on spécifie un problème où il y a excès d’emplois et donc pas de contrainte globale. Dans le cas inverse, il y a une fuite, calculée de façon à ce que le nombre d’actifs restant sur la zone soit égal au nombre d’emplois.\nDifférents paramètres permettent de spécifier la géographie, c’est-à-dire la position relative des pôles ou leur taille. Le simulateur simule par Monte-Carlo plusieurs ordres de passages et affiche les graphiques correspondants au fur et à mesure de la convergence, en accumulant la moyenne des différentes variables du modèle. Cette fonctionnalité permet de visualiser simplement la propriété d’ergodicité évoquée plus haut."
  },
  {
    "objectID": "theorie.html#références",
    "href": "theorie.html#références",
    "title": "Modéliser les flux des navetteurs : MEAPS",
    "section": "Références",
    "text": "Références\n\n\nBen-Akiva, M. & Lerman, S.R. (2018), Discrete choice analysis: theory and application to travel demand, MIT Press (Transportation Series).\n\n\nDios Ortúzar, J. de & Willumsen, L.G. (2011), Modelling transport, John wiley & sons.\n\n\nFik, T.J. & Mulligan, G.F. (1990), « Spatial Flows and Competing Central Places: Towards a General Theory of Hierarchical Interaction », Environment and Planning A: Economy and Space, vol. 22, n°4, pp. 527‑549. https://doi.org/10.1068/a220527\n\n\nFotheringham, A.S. (1983), « A New Set of Spatial-Interaction Models: The Theory of Competing Destinations », Environment and Planning A: Economy and Space, vol. 15, n°1, pp. 15‑36. https://doi.org/10.1177/0308518X8301500103\n\n\nFotheringham, A.S. (1984), « Spatial Flows and Spatial Patterns », Environment and Planning A: Economy and Space, vol. 16, n°4, pp. 529‑543. https://doi.org/10.1068/a160529\n\n\nHeanue, K.E. & Pyers, C.E. (1966), « A Comparative Evaluation of Trip Distribution Procedures », Highway Reserach Record, n°114, pp. 20‑50.\n\n\nLasser, J. (2020), « Creating an executable paper is a journey through Open Science », Communications Physics, vol. 3, n°1. https://doi.org/10.1038/s42005-020-00403-4\n\n\nLenormand, M., Bassolas, A. & Ramasco, J.J. (2016), « Systematic comparison of trip distribution laws and models », Journal of Transport Geography, vol. 51, pp. 158‑169. https://doi.org/10.1016/j.jtrangeo.2015.12.008\n\n\nMcFadden, D. (1974), « The measurement of urban travel demand », Journal of Public Economics, vol. 3, n°4, pp. 303‑328. https://doi.org/10.1016/0047-2727(74)90003-6\n\n\nMOBPRO (2022), « Mobilités professionnelles en 2019 : déplacements domicile - lieu de travail Recensement de la population - Base flux de mobilité »,.\n\n\nPatrick Bonnel (2001), Prévision de la demande de transport, thèse de doctorat, Lyon, France.\n\n\nRuiter, E.R. (1967), « Toward a better understanding of the intervening opportunities model », Transportation Research, vol. 1, n°1, pp. 47‑56. https://doi.org/https://doi.org/10.1016/0041-1647(67)90094-9\n\n\nSimini, F., González, M.C., Maritan, A. & Barabási, A.-L. (2012), « A universal model for mobility and migration patterns », Nature, vol. 484, n°7392, pp. 96‑100. https://doi.org/10.1038/nature10856\n\n\nSimini, F., Maritan, A. & Néda, Z. (2013), « Human Mobility in a Continuum Approach », PLOS ONE, vol. 8, n°3, pp. e60069. https://doi.org/10.1371/journal.pone.0060069\n\n\nStouffer, S.A. (1940), « Intervening Opportunities: A Theory Relating Mobility and Distance », American Sociological Review, vol. 5, n°6, pp. 845. https://doi.org/10.2307/2084520\n\n\nWilson, A.G. (1967), « A statistical theory of spatial distribution models », Transportation Research, vol. 1, n°3, pp. 253‑269. https://doi.org/10.1016/0041-1647(67)90035-4\n\n\n\n\n\nGraphique 1. Territoire synthétique comportant un centre ville (h1) et deux villages (h2) et (h3). Dans chaque hexagone est indiqué la densité (5 000 habitants). 4 500 emplois avec des proportions d’emplois de 80% dans le centre et de 5% dans les 2 villages (les 10% restant sont la fuite). La dispersion est plus basse pour les emplois. Les densités d’emplois sont représentées dans le panneau de droite en orange.\nGraphique 2. On représente sur le panneau de gauche les distances moyennes parcourues par les habitants d’un héxagone. La vignette présente la densité des trajets en fonction de la distance(vert). Sur le panneau de droite on représente les distances moyennes pour atteindre chaque emploi, ainsi que la densité de ces trajets par distance dans la vignette (orange)\nGraphique 3. Le graphique est construit comme le précédent, le pôle 3 est éloigné de 0.5 (70% plus loin) par rapport à 1.\nGraphique 4. Densités comparées des distances parcourues par habitant entre le scénario de référence et le scénario ‹pôle 3 plus loin›. Le trait pointillé est utilisé pour le scénario alternatif.\nGraphique 5. Chaque ligne blanche représente pour un carreau de départ et d’arrivée (tous les carreaux d’arrivée sont représenté par une ligne, pour une sélection aléatoire de 4 carreaux de départ) la probabilité de prendre l’emploi dans le carreau d’arrivée en fonction du tirage aléatoire. Les lignes vertes représentent cette même probabibilité prise en moyenne sur les tirages cumulés. L’échelle de l’axe des y est logarithmique.\nGraphique 6. Chaque ligne blanche représente pour un carreau d’arrivée (tous les carreaux d’arrivée sont représenté par une ligne) le rang moyen (panneau gauche) et l’écart type du rang (panneau de droite).\nGraphique 7. Indicateur de tension relatif localisé égal au rang de saturation normalisé à 100% (0% pour l’emploi saturé le plus tard, 100% pour l’emploi saturé le plus tôt, en moyenne sur chaque hexagone d’emploi)."
  }
]