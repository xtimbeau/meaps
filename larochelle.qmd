```{r init, include = FALSE}
library(knitr)
opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.pos="htb", 
  out.extra="",
  dev="ragg_png",
  out.width="100%",
  fig.showtext=TRUE,
  cache=FALSE)

library(tidyverse)
library(ofce)
library(showtext)
library(markdown)
library(gt)
library(qs)
library(sf)
library(ggspatial)
library(stars)
library(glue)

library(PrettyCols)
showtext_auto()
options(ofce.background_color = "grey99")
options(ofce.base_family = "Source Sans Pro")
options(ofce.base_size = 9)
```

# Estimation à La Rochelle {#sec-rochelle}

Nous proposons ici une première application de *MEAPS* à l'agglomération de la Rochelle. Cette application est issue d'un travail de quantification de scénarios de politiques publiques visant à réduire l'empreinte carbone associée aux mobilités quotidiennes et au secteur résidentiel. La quantification demande à la fois de produire une cartographie très fine des émissions, en procédant par interpolation à partir de données plus macroscopiques mesurées par ailleurs et d'être en mesure de produire des évaluations des différences d'émissions de CO~2~ localement et à l'échelle du territoire selon les différents scénarios. Nous présentons ici deux familles de scénarios pour lesquelles *MEAPS* a été mobilisé :

-   Des scénarios de localisation de l'emploi : nous projetons la distribution des trajets en utilisant *MEAPS* sur deux structures spatiales de l'emploi différentes, tout en conservant la même quantité d'emploi globale. La différence entre les kilomètres parcourus suivant les différents modes dans les deux scénarios permet d'évaluer l'impact de la localisation, en distinguant la contribution du changement modal, la contribution des changements de distance pure (à mode et flux carreaux à carreaux inchangés) et la contribution des changements de flux.

-   Des scénarios de modification de la structure du réseau de transport. Le principe est identique à celui pour la localisation de l'emploi. C'est la matrice des distances et des temps qui est modifiée par une modification des infrastructures de transports (par exemple une ligne de bus en plus). Cette matrice de distance différente induit des temps de trajet plus petits mais uniquement pour le mode transport en commun. Elle induit un changement modal (plus de transport en commun, moins des autres modes) et enfin conduit à un changement des rangs des opportunités et donc une redistribution des flux de carreau à carreau.

Dans les deux familles de scénarios, les simulations par *MEAPS* permettent de construire un contrefactuel et des alternatives à un niveau fin, croisant la localisation au carreau 200m pour les résidences (5 456 carreaux pour la Rochelle et le périmètre du SCOT) et les opportunités (6 326 carreaux dans le périmètre de 33km autour de l'agglomération de la Rochelle), soit 34,5 millions de flux et de modes. L'agrégation de ces informations est alors possible à des niveaux plus généraux pour analyser les impacts. La conversion des kilomètres ou des minutes en émissions de CO~2~ pour la voiture est effectuée à partir de coefficients de conversion conventionnels, ce qui permet d'étendre les indicateurs au champ des émissions de gaz à effet de serre.

## Emplois, résidents au carreau Inspire 200m

La carte de la zone considérée est représentée sur la @fig-zoneslr. L'analyse est limitée aux résidents du périmètre du Schéma de COhérence Territoriale (SCOT) et considère les emplois dans un rayon 33 kilomètres autour des lieux de résidence. Cette carte est construite à partir des données carroyées de @C200 à la résolution du carreau 200m Inspire[^larochelle-1]. Nous ajoutons à ces données la localisation de l'emploi sur la même grille en utilisant les fichiers fonciers et les données d'emplois localisés de @MOBPRO. La méthode consiste à imputer par code NAF les emplois de chaque commune selon @MOBPRO aux surfaces professionnelles à la parcelle issues des fichiers fonciers. Cela permet ensuite de localiser au carreau 200m les emplois. Cette méthode est assez grossière, puisqu'en particulier la ratio personne/surface n'est pas constant d'une entreprise à l'autre, mais elle fournit une bonne première approximation d'autant que l'extrapolation ne dépasse pas l'échelle de la commune. Elle est en tout cas très supérieure à une imputation uniforme.

[^larochelle-1]: INfrastructure for SPatial InfoRmation in Europe est depuis 2007 une directive pour la production de données spatialisées. Inspire définit une grille de carroyage et son système de projection harmonisée. C'est ce qui suit l'INSEE dans la diffusion des données carroyées. Voir https://inspire-geoportal.ec.europa.eu pour la définition de la grille et des jeux de données.

```{r}
#| label: fig-zoneslr
#| fig-scap: "Localisation des résidents et des emplois"
#| fig-cap: "Localisation es emplois et des résidents, zones de la Rochelle. Le périmètre de du SCOT de la Rochelle est indiqué ainsi que les limites administratives des communes et des EPCI le composant. Sources : OSM, Mapbox, IGN, carroyage INSEE 2017, Flores et fichiers fonciers 2018"

knitr::include_graphics("output/popemp.png")
```

## Calcul des distances par mode {#sec-distancesparmode}

Un ingrédient important de l'analyse du territoire est la prise en compte des distances entre chaque paire possible résidence/emploi. Contrairement à l'analyse synthétique, nous ne nous contentons pas de la distance euclidienne.

Pour ce faire nous calculons à partir d'un calculateur d'itinéraire (R^5^ de Conveyal [@conway2017; @conway2018; @conway2019] en utilisant le package `{r5r}` [@r5r] les distances et surtout les temps de transport pour quatre modes (voiture, vélo, transport en commun, marche à pied). Les temps de transport calculés pour chaque paire de carreaux de résidence et d'emploi, en retenant le centre des carreaux, tiennent compte des différentes contraintes de circulation (vitesses limites pour la voiture, sens de circulation, pénalité pour changement de direction, accès autorisé ou restreint suivant le mode, stress à vélo). Concernant les déplacements en voiture, nous ne prenons pas en compte à ce stade la congestion. Concernant les transports en commun, le niveau de détail est assez grand, puisque les fréquences de circulations des véhicules ainsi que les correspondances sont prises en compte. Dans certaines villes, il est possible d'accéder à une information sur les temps de parcours effectifs (mesurant ainsi la congestion ou la disponibilité du réseau) en complément des horaires théoriques. Ces informations ne sont pas disponible pour l'agglomération de la Rochelle et donc cette possibilité n'est pas explorée. L'accès aux données GTFS impose quelques limites, comme par exemple la non prise en compte des réseaux scolaires ou d'autres réseaux locaux ou privés non publiés sous ce format. La modification du réseau de transport comme l'ouverture d'une ligne ou l'accroissement de fréquence est pris en compte en modifiant la matrice des distances et temps par mode entre chaque carreau de résidence et chaque carreau de destination. Dans le cas de l'agglomération de la Rochelle, le nombre de paires calculés est de l'ordre de 16 millions.

A partir des temps de trajets par mode, nous appliquons un modèle de choix discret, *Random Utility Model* (RUM) à la McFadden, estimé sur l'enquête mobilité des personnes @MOBPERS en utilisant les données de mobilités professionnelles @MOBPRO pour caler les flux commune à commune. L'estimation de ce modèle est détaillée dans un autre document (référence à insérer).

Les distances entre chaque paire de cases permettent de calculer un indicateur d'accessibilité qui joue un rôle central dans le modèle radiatif, et donc dans *MEAPS*, en remplaçant la distance par la somme des opportunités en deçà d'un seuil de temps. Les cartes des @fig-4access1k, @fig-4access5k, @fig-4access10k, @fig-4access20k représentent les temps pour accéder à entre 1 000 et 20 000 d'emplois en utilisant différents modes de transport.

```{r cartes accessibilité}
access <- qs::qread("output/acces4modes.sqs")
decor_carte <- qs::qread("output/decor_carte.sqs")

access_4modes <- 
  map(c("to1k", "to5k", "to10k", "to20k"), ~{ 
    ggplot()+
      decor_carte +
      ofce::theme_ofce_void(base_family = "Nunito", axis.text = element_blank()) +
      geom_sf(data=access, aes(fill=.data[[.x]]), col=NA)+
      #scico::scale_fill_scico(palette="hawaii", na.value=NA, direction=-1, name = "mn")+
      PrettyCols::scale_fill_pretty_c(
        "Rainbow", 
        limits = c(0,100),
        breaks = c(15, 30, 45, 60, 75, 90),
        na.value = "gray85",
        direction=-1, 
        legend_title = glue("temps pour \n{str_remove(.x, 'to')} emp."))+
      annotation_scale(line_width = 0.2, height = unit(0.1, "cm"), 
                       text_cex = 0.4, pad_y = unit(0.1, "cm"))+
      facet_wrap(vars(mode))
  })

```

::: panel-tabset
## temps pour 1k

```{r}
#| label: fig-4access1k
#| fig-scap: "Accessibilité à 1 000 emplois pour la Rochelle"
#| fig-cap: "Temps d'accès à 1 000 emplois. Pour chaque carreau de résidence, on détermine le temps minimal pour atteindre au moins 10 000 emplois suivant l'un des quatre modes considéré. Cette mesure remplace la distance dans le modèle radiatif. <br>Calcul des auteurs. <br>Source : OSM, Mapbox, IGN, Conveyal R5, carroyage INSEE 2017, Flores et fichiers fonciers 2018"
#| fig-asp: 0.9
access_4modes[[1]]
```

## temps pour 5k

```{r}
#| label: fig-4access5k
#| fig-scap: "Accessibilité à 5 000 emplois pour la Rochelle"
#| fig-cap: "Temps d'accès à 5 000 emplois. Pour chaque carreau de résidence, on détermine le temps minimal pour atteindre au moins 10 000 emplois suivant l'un des quatre modes considéré. Cette mesure remplace la distance dans le modèle radiatif. Calcul des auteurs. <br>Calcul des auteurs. <br>Source : OSM, Mapbox, IGN, Conveyal R5, carroyage INSEE 2017, Flores et fichiers fonciers 2018"
#| fig-asp: 0.9

access_4modes[[2]]
```

## temps pour 10k

```{r}
#| label: fig-4access10k
#| fig-scap: "Accessibilité à 10 000 emplois pour la Rochelle"
#| fig-cap: "Temps d'accès à 10 000 emplois. Pour chaque carreau de résidence, on détermine le temps minimal pour atteindre au moins 10 000 emplois suivant l'un des quatre modes considéré. Cette mesure remplace la distance dans le modèle radiatif. Calcul des auteurs. <br>Calcul des auteurs. <br>Source : OSM, Mapbox, IGN, Conveyal R5, carroyage INSEE 2017, Flores et fichiers fonciers 2018"
#| fig-asp: 0.9

access_4modes[[3]]
```

## temps pour 20k

```{r}
#| label: fig-4access20k
#| fig-scap: "Accessibilité à 20 000 emplois pour la Rochelle"
#| fig-cap: "Temps d'accès à 20 000 emplois. Pour chaque carreau de résidence, on détermine le temps minimal pour atteindre au moins 10 000 emplois suivant l'un des quatre modes considéré. Cette mesure remplace la distance dans le modèle radiatif. Calcul des auteurs. <br>Calcul des auteurs. <br>Source : OSM, Mapbox, IGN, Conveyal R5, carroyage INSEE 2017, Flores et fichiers fonciers 2018"
#| fig-asp: 0.9

access_4modes[[4]]
```
:::

Les courbes d'accessibilité de la @fig-comaccess sont construites en prenant la moyenne par commune de résidence des temps d'accès pour les différents seuils d'emplois. C'est cette courbe qui découle du modèle théorique présenté plus haut (@sec-meaps) et qui détermine les choix individuels de déplacement comme de localisation. Ces courbes font apparaître une propriété propre aux villes littorales : si pour des temps courts, l'accès à l'emploi est maximal à la Rochelle, en revanche d'autres communes jouissent d'une position plus "centrale" lorsqu'on accepte des temps de trajets supérieurs à 30 minutes en voiture.

```{r courbe_access, echo= FALSE}
#| label: fig-comaccess
#| fig-scap: "Accessibilité par communes pour la Rochelle"
#| fig-cap: "Courbe du temps d'accès aux emplois. Pour chaque commune, on calcule la médianne, pondérée par le nombre d'habitants par carreau, du temps d'accès à différents seuils d'emplois. Cela permet de caractériser les communes par leur accessibilité à l'emploi, une mesure plus pertinente de la 'distance à l'emploi'. Calcul des auteurs. Sources : OSM, Mapbox, IGN, Conveyal R5, carroyage INSEE 2017, Flores et fichiers fonciers 2018"

mode_l <- qs::qread("output/model_l.sqs")
library(scales)
ggplot(mode_l) +
  geom_line(aes(x=temps, y=emp, group=com21), col="gray80", linewidth=0.2) +
  geom_line(data = ~filter(.x, !str_detect(label, "^n")),
            aes(x=temps, y=emp, color=label)) +
  scale_x_continuous(breaks  = c(0, 20,40,60,80,100,120))+
  scale_y_continuous(labels = ofce::f2si2, breaks = c(25000, 50000, 75000, 100000))+
  PrettyCols::scale_color_pretty_d("Bold")+
  ofce::theme_ofce()+
  xlab("temps en minutes") +
  ylab("nombre d'emplois accessibles")+
  labs(color="Communes")+
  theme(legend.position = c(0.01, 0.99),
        legend.justification = c(0,1),
        panel.spacing = unit(12, "pt"),
        plot.margin = margin(l = 6, r= 6),
        panel.grid.major.x = element_line(color="gray80", linewidth = 0.1))+
  facet_wrap(vars(mode))

```

## Ajustement de *MEAPS* sur MOBPRO {#sec-ajust}

### Stratégies d'apprentissage

La construction de la matrice de distance permet d'utiliser *MEAPS* pour déduire les flux carreau à carreau. Mais le fichier détail du recensement et son volet mobilités professionnelles nous donnent une information supplémentaire que nous pouvons utiliser pour calibrer *MEAPS* au plus près des données. Les mobilités professionnelles décrivent pour chaque paire de commune résidence-emploi les flux de mobilités professionnelles (de nombreuses paires de communes ont des flux nuls). Cette information est équivalente à celle produite par *MEAPS* mais agrégée au niveau communal. Une première stratégie de calage de *MEAPS* est d'affecter aux probabilités d'absorption un facteur correcteur pour reproduire le plus fidèlement possible les flux agrégés de @MOBPRO.

Cette méthode conduit à saturer le modèle, d'autant plus que l'on estime un nombre de paramètres proche du nombre de degrés de liberté imposé par @MOBPRO. Poussée au maximum, elle permet une intrapolation en calibrant des paramètres pour estimer ce que sont les valeurs des flux à un niveau infra-communal, par exemple au carreau 200m. Cette stratégie d'apprentissage est analogue à ce qui se fait en *machine learning*. Une limite est le sur-ajustement (*overfitting*) qu'elle induit et qui peut être corrigé en ajoutant une pénalité à la complexité du modèle dans la fonction d'optimisation. Cela peut également se faire par *pruning*, c'est-à-dire en éliminant *a posteriori* les paramètres dont la contribution à l'explication des données est inférieure à un seuil.

Les paramètres issues de cette approche contiennent une information qui peut ensuite être exploitée. Ils s'interprètent comme des déviations exprimées sous forme de *odds-ratios* par rapport à un modèle de référence. Dans notre cas, cette hypothèse explicite découle du modèle de référence où les chances d'absorption sont égales pour tous les emplois. Si l'*odds-ratio* estimé est supérieur à 1, alors la chance d'absorption apparaît supérieure à notre référence. Et inversement si l'*odds-ratio* est inférieur à 1.

Cette approche pose généralement un problème difficile d'optimisation algorithmique. Une approche brutale, qui consiste à minimiser une fonction de perte mesurant l'écart entre les flux estimés et les flux observés, se heurte à la grande dimension de l'espace des paramètres. En outre, comme toujours dans ce type d'exercices statistique, l'enjeu consiste à extraire des données disponibles des enseignements généraux en délaissant ce qui relève de la particularité d'un jeu de données. C'est toute la difficulté du surapprentissage (overfitting) que nous avons évoquée. La stratégie consiste à calculer un grand nombre de paramètres puis, *a posteriori*, à faire une sélection de ceux qui méritent l'attention. On parlera donc de stratégie *a posteriori*.

Une seconde approche, plus parcimonieuse, consiste à définir une forme fonctionnelle pour les *odds-ratios* ou encore à regrouper les odds-ratios en quelques clusters pour ensuite n'évaluer que quelques paramètres qui résument une grande masse d'information. Ceci suppose de modéliser la structuration des *odds-ratios* à partir d'*a priori* sur les dimensions pertinentes. On parlera alors de stratégie de modélisation *a priori*.

### Estimation de la stratégie a posteriori {#sec-estnp}

Celle-ci consiste à définir pour chaque paire origine-destination (éventuellement regroupée en cluster, par exemple, les communes de départ et d'arrivée) un paramètre qui permettra de modifier le flux simulé afin de générer le flux souhaité. On note la chance d'absorption $c_a$ comme étant égale à la probabilité d'être absorbé divisé par la probabilité de ne pas être absorbé, soit $c_a = p_a/(1-p_a)$. Les modifications des probabilités d'absorption sont alors paramétrées par des *odds-ratios* (ratio de chances relatives) $\omicron_{i,j}$ de telle manière que $\tilde{c}_a = \omicron_ij * c_{a}$ . L'*odds-ratio* $\omicron_{i,j}$ est un paramètre entre $0$ et $+\infty$ et $i,j$ indexent les communes de départ et d'arrivée. On a :

$$
\tilde{p}_a = \frac{c_a \times \omicron_{i,j}} {1+c_a \times \omicron_{i,j}} 
$$ {#eq-odd}

A ce stade nous utilisons un algorithme naïf pour trouver une solution au problème posé. Nous calculons l'*odd-ratio* entre le résultat d'une simulation associée à un ensemble d'$\omicron_{i,j}$ et celui défini par les données observées de @MOBPRO en utilisant la formule suivante où $\beta$ est un paramètre d'amortissement inférieur à 1 et positif et $k$ indexe les itérations :

$$
\omicron^k_{i,j} = (\frac{\tilde{p}^k_a/(1-\tilde{p}^k_a)}{
p^{mobpro}_a/(1-p^{mobpro}_a)})^\beta \times \omicron^{k-1}_{i,j}
$$ {#eq-algest}

Nous modifions alors les $\omicron_{i,j}$ en fonction des écarts observés. Cela conduit à chercher un point fixe. Nous calculons ensuite un critère d'ajustement à partir de l'entropie relative de Kullback-Leibler [@kullback1951]. L'entropie relative est définie pour deux distributions de probabilités $p$ et $q$ comme suit (dans le cas discret, le cas continu se généralise aisément) :

$$
KL(p,q) = \sum_{i}p_i \times log(p_i/q_i)
$$ {#eq-kl}

Cette mesure ressemble à une distance, mais n'est pas symétrique et ne vérifie pas l'inégalité triangulaire. Elle s'interprète dans le cadre de la théorie de l'information comme la quantité relative d'information supplémentaire nécessaire pour exprimer $q$ à partir de $p$. En suivant @colincameron1997 on peut construire une mesure de la qualité de l'ajustement $R_{KL}^2$ de la façon suivante, où $\hat{q}$ et $q_0$ sont deux distributions respectivement estimée et de référence que l'on compare à $p$ :

$$
R_{KL}^2 = 1 - \frac{KL(p,\hat{q})}{KL(p, q_0)}
$$ {#eq-r2kl}

La distribution de référence est choisie comme une distribution uniforme, par analogie avec le calcul de la variance dans un $R^2$ habituel où l'on régresse sur une constante. On écrit :

$$
\begin{aligned}
KL(p,q_{ref}) &{}= \sum_{i}p_i \times log(p_i/unif) \\&{}= \sum_i p_i \times log(p_i) + log(N)
\end{aligned}
$$ {#eq-klent}

qui n'est autre que l'entropie de la distribution $p$ à une constante près ($N$ est le nombre de résidents actifs ou d'emplois).

L'algorithme naïf est relativement efficace. Il converge en quelques dizaines d'itérations, s'avère stable et fait diminuer l'entropie relative. Il devra être affiné dans le futur afin de permettre une descente de gradient qui permet de minimiser explicitement l'entropie relative. L'algorithme naïf permet de réduire cette entropie relative sans assurer qu'elle est minimale.

Cet algorithme naïf a été utilisé avec différentes contraintes sur les paramètres. Le @tbl-meapsR2-np indique la qualité de l'ajustement obtenu dans ces différentes configurations. La première est celle où les probabilités d'absorption sont déterminées uniquement par les fuites par commune de résidence. C'est la configuration la plus parcimonieuse en termes de paramètres et qui sert de référence. Le $R^2_{KL}$ vaut 88% ce qui est un ajustement élevé. La seconde configuration est celle où l'on ajuste des $\omicron_{i,j}$ uniquement pour les termes diagonaux ($i=j$). Cette configuration ajuste donc un *odd-ratio* pour les résidents qui travaillent dans leur commune de résidence. Dans un certain nombre de communes, cet ajustement conduit à augmenter la probabilité d'absorption interne (@fig-carteodd), ce qui indique que le choix de résidence n'est pas indépendant de celui d'activité. Pour la commune la plus importante (la Rochelle), en revanche, l'*odd-ratio* $\omicron_{17300, 17300}$ est proche de 1. Les deux configurations suivantes laissent beaucoup plus de degrés de liberté en estimant des $\omicron_{i,j}$ librement. La première de ces deux configurations limite les $\omicron_{i,j}$ estimés à ceux représentant un total cumulé des flux mesurés par @MOBPRO égal à 99.4% pour 1 854 $\omicron_{i,j}$ estimés. La seconde configuration estime tous les $\omicron_{i,j}$ sans limite (soit 2 033 paramètres pour 72 communes de résidence et 210 communes d'activité, avec un grand nombre de liaisons non considérées).

```{r meapsR2-np}
#| label: tbl-meapsR2-np
#| tbl-cap: Ajustements non paramètriques, mobilités professionelles la Rochelle

meaps_stats <- qs::qread("output/meaps_stats.sqs") |> 
  arrange(r2kl)
meaps_stats |> 
  select(-f_in, -f_out, -p1, -p2) |> 
  filter(alg %in% c("référence", "diagonale", "90%", "99%", "100%")) |> 
  mutate( 
    alg = factor(alg, c("référence", "diagonale", "90%", "99%", "100%")),
    label = case_match(alg,
             "100%" ~ "100% des flux cumulés",
             "99%" ~ "99% des flux cumulés ",
             "90%" ~ "90% des flux cumulés",
             "diagonale" ~ "Diagonale (résidence égale emploi)",
             "référence" ~ "Référence (odds unitiaires)" )) |> 
  relocate(label) |> 
  gt() |> 
  fmt_percent(columns = r2kl, decimals = 1) |>
  fmt_integer(columns = c(dl, n_est), sep_mark = " ") |>
  cols_hide(alg) |> 
  cols_label(label = "",
             r2kl = md("R<sub>KL</sub><sup>2</sup>"),
             dl = "Degrés de liberté",
             n_est = "odds estimés") |> 
  tab_footnote(md("Le nombre de degrés de liberté est le nombre de paires de flux non nuls dans MOBPRO, moins les contraintes en ligne et en colonne, plus un puisqu'elles sont redondantes moins le nombre de paramètres estimés. Le nombre de degré de liberté est nul pour les configurations 99% et 100% arce que le nombre de paramètres estimés est supérieur au produit des linges et des colonnes moins les contraintes. Il y a bien plus de paramètres estimés pour la configuration 100%  que pour 99%. En conséquence, l'algorithme conduit à un résultat légèrement différent."))
```

la @fig-actvsfit-np représente les flux observés et estimés pour les différentes configurations du @tbl-meapsR2-np. Le gain à estimer les $\omicron_{i,i}$ diagonaux, pondérant les flux allant d'une commune de résidence vers elle même est assez élevé, faisant passer le $R^2_{KL}$ de 88% à 95% et réduisant les écarts entre flux observé et flux estimé comme le montrent les deux panneaux supérieurs de la @fig-actvsfit-np. L'ajout de paramètres supplémentaires ne fait pas gagner beaucoup plus d'autant que les écarts pour les flux marginaux ne sont pas tant réduit que ça. La limite de l'algorithme naïf apparaît ici, puisque le modèle complètement saturé n'ajuste pas totalement la distribution. Différents détails de l'algorithme peuvent l'expliquer, notamment la censure des *odd-ratio* trop faibles (\<0.0001) ou trop importants (\>10000) ou la prise en compte des flux nuls. Au-delà de cet argument, il est probable que pour converger vers un ajustement plus strict, il serait nécessaire de calculer la matrice des quasi dérivées des flux par rapport aux $\omicron_{i,j}$.

Mais le coût peut être très élevé puisque cette matrice (calculée dans la partie synthétique dans un cas simple) est d'une taille considérable (1 755 $\times$ 1 755 coefficients), surtout si l'on prend en compte que le calcul de chaque terme prend autour d'une minute[^larochelle-2].

[^larochelle-2]: Autour de 6 années de vCPU...

```{r actvsfit-np, fig.asp=1}
#| label: fig-actvsfit-np
#| fig-scap: "*MEAPS* observés versus estimés"
#| fig-cap: "La figure présente pour chaque configuration d'estimation le flux observé (axe des x) et le flux estimé (axe des y) en bleu lorsque o<sub>i,j</sub> est estimé et en rouge lorsque o<sub>i,j</sub> n'est pas estimé (les fuites sont toujours utilisées). La valeur de référence est répétée dans chaque panneau en gris clair."

meaps_estimations <- qs::qread("output/meaps_est.sqs") |> 
  mutate(alg = factor(
    alg, c("référence", "diagonale", "90%", "99%", "100%",
           "gravitaire sans furness", "gravitaire avec furness",
           "un en diagonale", "2 en diagonale", 
           "un fonction distance", "distance critique")),
    grav = case_match(alg,
                      c("gravitaire sans furness", "gravitaire avec furness") ~ TRUE, 
                      .default = FALSE),
    np = case_match(alg,
                    c("diagonale", "90%", "99%", "100%") ~ TRUE,
                    .default = FALSE))

library(scales)
ref <- meaps_estimations |>
  filter(alg == "référence") |> 
  mutate(diag = COMMUNE==DCLT) |> 
  filter(flux!=0) |> 
  select(-alg)
non_param <- meaps_estimations |>
  filter(np) |> 
  mutate(diag = COMMUNE==DCLT) |> 
  filter(alg!="référence") |> 
  filter(flux!=0)
ggplot(non_param)+
  geom_point(data=ref,
             aes(x=mobpro, y=flux, shape = diag, alpha = diag, size = diag), 
             col="gray80")+
  scale_shape_manual(values=c(1, 18))+
  scale_alpha_manual(values=c(0.1, 0.5))+
  scale_size_manual(values=c(.5, 1.5))+
  geom_point(data = ~.x |> filter(!estime),
             aes(x=mobpro, y=flux, shape=diag, alpha = diag, size = diag),
             col="tomato")+
  geom_point(data = ~.x |> filter(estime),
             aes(x=mobpro, y=flux, shape=diag, alpha = diag, size = diag), 
             col="royalblue2")+
  scale_x_log10(limits=c(0.1, 20000),
                labels = label_number(accuracy = 1,
                                      big.mark = " "))+
  scale_y_log10(limits=c(0.1, 25000), 
                labels = label_number(accuracy = 1,
                                      big.mark = " "))+
  xlab("Flux observés")+ ylab("Flux estimés") +
  facet_wrap(vars(alg), ncol = 2)+
  geom_abline(slope=1, linewidth=0.25)+
  coord_equal()+
  ofce::theme_ofce(legend.position  = "none")
```

Notons que l'échantillon des mobilités donné par @MOBPRO pour l'agglomération de la Rochelle est très particulier. Une commune (la Rochelle, dont le code géographique est 17300) représente presque 29% des flux de mobilité (de la Rochelle lieu de résidence vers la Rochelle lieu d'emploi). C'est donc un schéma monocentrique, où à la fois les résidents et les emplois sont concentrés sur un territoire réduit. La résolution spatiale de @MOBPRO ne nous permet pas d'en détailler la structure plus fine.

Pour les 20 plus grandes communes de l'agglomération de la Rochelle -- qui comptent plus de 1 000 résidents en activité -- on peut représenter les *odd-ratios* estimées dans la configuration 100% des flux par rapport aux chances calculées dans le cas où tous les $\omicron_{i,j}$ sont égaux à 1 (des *odd-ratios* effectifs), en fonction de la distance de la commune de destination à la commune de résidence[^larochelle-3]. Ce diagramme, analogue à un spectre, peut aussi être construit par commune de destination, la distance $d$ étant la distance aux différentes communes de résidence @fig-spectreE. L'élément le plus frappant est que les *odd-ratios* de $i$ à $i$ sont généralement supérieur à 1 (@fig-spectreR), à l'exception de la commune de la Rochelle. Il n'émerge pas de structure particulière par rapport à la distance, si ce n'est des *odd-ratios* élevés pour des distances importantes

[^larochelle-3]: La distance est construite comme la distance moyenne pondérée entre les résidents de la commune de départ et les emplois de la commune d'arrivée. La pondération est le produit des emplois et des résidents pour chaque paire, normalisé à 1.

```{r spectreR}
#| label: fig-spectreR
#| fig-scap: "Odd-ratio par commune de résidence fonction de la distance aux communes d'emploi (spectre résidents)"
#| fig-cap: "La figure représente pour les 20 plus grandes communes de l'agglomération de la Rochelle les odd-ratios estimés (configuration 100% des flux) en fonction de la distance entre cette commune et les communes où travaillent les résidents. Les points marqués d'un petit point blancs sont les emplois situés hors du périmètre du SCoT."
knitr::include_graphics("output/spectre effectif par COMMUNE 100.png")
```

```{r spectreE}
#| label: fig-spectreE
#| fig-scap: "Odd-ratio par commune d'emploi fonction de la distance aux communes de résidence (spectre emplois)"
#| fig-cap: "La figure représente pour les 20 plus grandes communes d'emplois du périmètre géographique (33 km autour de l'agglomération de la Rochelle) les odd-ratios estimés (configuration 100% des flux) en fonction de la distance entre cette commune et les communes où résident les travailleurs de la commune."

knitr::include_graphics("output/spectre effectif par DCLT 100.png")
```

La @fig-carteodd permet de préciser la valeur élevée des *odd-ratios* pour les flux internes. Les communes où sont localisés de nombreux emplois ont un *odd-ratio* plutôt plus faible alors qu'ils sont estimés plus élevés dans les communes plus petites et moins desservies. Pour les différentes procédure d'estimation et donc différents nombres de paramètres estimés, on observe une structure similaire dans la répartition géographique des *odd-ratio*, ce qui suggère que les *odd-ratios* estimés contiennent de l'information.

Un *odd-ratio* élevé dans la diagonale indique que les flux internes sont plus importants que dans le scénario de référence. Cela indique probablement un choix de résidence en lien avec l'emploi occupé en privilégiant la commune d'activité pour la résidence (ou l'inverse). Le spectre résident en fonction de la distance indique que ce phénomène, s'il est une hypothèse à très faible distance, ne persiste pas en dehors de la commune de résidence. En revanche, la @fig-spectreE suggère que dans certaines communes, notamment Surgères, on observe des *odd-ratios* supérieurs à 1 pour des distances faibles, ce qui s'interpète comme le fait que les habitants des communes alentours privilégient Surgères comme lieu d'emploi.

A ce stade, les observations sont limitées par le faible nombre de communes modélisées, mais on peut espérer que l'analyse des *odd-ratios* estimés pourra servir à caractériser les communes en fonction des choix de résidence et d'emploi. En multipliant cette analyse pour d'autres territoires, l'information apportée par les *odd-ratio* pourra être inférée. Il sera aussi possible de confronter ces éléments à d'autres variables, comme le prix de l'immobilier, les loyers résidentiels ou commerciaux, la densité d'emploi.

```{r carteodd}
#| label: fig-carteodd
#| fig-scap: "Odd-ratio dans la diagonale"
#| fig-cap: "Chaque cercle indique les odd-ratio estimés dans la diagonale (100% des flux). Les diamètres des cercles sont proportionels aux flux internes (de i à i)."

knitr::include_graphics("output/toutes configs odds effectifs.png")
```

### Estimations paramétriques et comparaison avec le modèle gravitaire

En donnant une forme fonctionnelle paramétrisée aux *odd-ratios* correctifs $\{o_{i,j}\}$ on peut ensuite déterminer les paramètres par un algorithme standard de minimisation de l'entropie relative, qui est le critère que nous avons choisi pour comparer les distributions. De plus, il est également possible de procéder à une telle estimation paramétrique pour le modèle gravitaire.

Nous explorons ici trois formes paramétriques pour *MEAPS* :

1.  un paramètre pour les termes diagonaux, c'est-à-dire les flux allant d'une commune de résidence vers cette même commune pour l'emploi. Cette forme est proche de la forme "diagonale" estimé dans la @sec-estnp, mais un seul paramètre est estimé -- par une minimisation de l'entropie relative -- au lieu de 72 par l'algorithme itératif. Formellement, $\omicron_{i \neq j}=1$ et $\omicron_{i,i} = o$.

2.  un paramètre pour les termes diagonaux, comme pour 1., et un paramètre pour les communes voisines d'emploi, c'est-à-dire un terme correctif reliant une commune de résidence aux communes qui en sont voisines, hormis la commune elle-même. Le même paramètre est estimé pour toutes les correspondances une commune et ses voisines. Une commune est voisine d'une autre si au moins 5% des trajets pondérés par les emplois et les résidents ont une distance kilométrique inférieure à 3km. Cette définition permet d'exclure des communes limitrophes mais dont les pôles principaux sont distants. Formellement, $\omicron_{i,i} = o_d$; $\omicron_{i,j\in \mathcal{V}(i)} = o_v$ et $\omicron_{i, j \neq i, j \notin \mathcal{V}(i)} = 1$.

3.  deux paramètres qui sont d'une part un paramètre de distance et d'autre part la distance de bascule. Formellement, en dessous d'une distance donnée $d_c$ on définit un $\omicron_{i,j \in d_{i,j} \leq d_c} = o$ et $\omicron_{i,j \in d_{i,j} > d_c} = 1$. Cette forme s'approche de la 1, mais estime la notion de proximité au lieu de reposer sur le découpage administratif. La différence entre 1. et 3. illustre les possibilités de la modélisation proposée.

Chacune de ces options vise à mesurer un biais intra-communal évoqué dans la section précédente qui peut s'expliquer par un choix de localisation de résidence et d'emploi joint. *MEAPS* offre ici la possibilité de mesurer l'intensité de cette déviation par rapport à l'hypothèse où les emplois sont considérés indépendamment de la localisation et sont tous homogènes. Il sera intéressant de comparer les territoires de ce point de vue et d'en déduire des régularités qui peuvent indiquer comment les spécificités locales, qu'elles concernent la géographie du territoire -- sa structure en pôles ou en satellite--, la formation des prix de l'immobilier, le réseau de transport ou la nature de l'activité économique. On pourrait également chercher à exploiter l'information sectorielle -- disponible dans @MOBPRO au niveau de 5 secteurs -- ou l'information sociale ou démographique -- disponible au niveau communal ou de l'IRIS mais qui peut être exploitée également à un niveau plus fin avec Fidéli[^larochelle-4].

[^larochelle-4]: Fichiers démographiques sur les logements et les individus, INSEE, https://www.insee.fr/fr/metadonnees/source/serie/s1019.

A ces formes fonctionnelles pour *MEAPS*, nous ajoutons deux formes fonctionnelles pour le modèle gravitaire :

4.  un modèle gravitaire suivant la définition @eq-gravity où $f(d)= e^{-d/\delta}$. Un seul paramètre $\delta$ est estimé.
5.  un modèle gravitaire "équilibré" en utilisant l'algorithme de Furness, tel que décrit dans @sec-compgravsynth et en estimant $\delta$ comme dans le point 4.

On pourrait multiplier les modèles estimés[^larochelle-5]. Le propos est ici d'illustrer les possibilités de notre modélisation et de les comparer à celles du modèle gravitaire. Deux points émergent :

[^larochelle-5]: Par exemple, en faisant dépendre les *odd-ratios* non pas de la distance et d'une distance critique mais du rang et d'un rang critique.

-   *MEAPS* peut mieux reproduire les données, avec une qualité d'ajustement meilleure,

-   *MEAPS* ouvre des possibilités d'interprétation plus riches que celle du modèle gravitaire, parce que les fondements microscopiques de *MEAPS* sont explicites.

Le tableau @tbl-meapsR2-p résume les résultats des estimations. Le modèle de référence, dans lequel tous les emplois sont équivalents pour chaque individu, fait moins bien en termes d'ajustement que les autres modèles, à l'exception notable du modèle gravitaire non équilibré. Comme on avait pu le constater dans les estimations non paramétriques, le modèle de référence a, malgré son hypothèse simplificatrice, une bonne performance, ce qui est conformé ici par la comparaison au modèle gravitaire simple.

```{r meapsR2-p}
#| label: tbl-meapsR2-p
#| tbl-cap: Ajustements paramètriques, mobilités professionelles la Rochelle

meaps_stats_p <- qs::qread("output/meaps_stats.sqs") |> 
  arrange(r2kl) |> 
  select(-f_in, -f_out) |> 
  filter(alg %in% c("référence", "gravitaire avec furness", "gravitaire sans furness",
                    "un en diagonale", "2 en diagonale", "distance critique")) |> 
  mutate(
    labelp = case_match(alg,
             c("gravitaire avec furness", "gravitaire sans furness") ~ 
                 str_c("\u03B4\u2248", signif(p1, 2), " min"),
             "référence" ~ "",
             "un en diagonale" ~ str_c("o\u2248", signif(p1, 2)),
             "2 en diagonale" ~ str_c("o<sub>d</sub>\u2248", signif(p1, 2), "<br>",
                                               " o<sub>v</sub>\u2248", signif(p2, 2)),
             "distance critique" ~ 
               str_c("d<sub>c</sub>\u2248 ", signif(p2, 2)," min<br>",
                                               " o\u2248", signif(p1, 2))),
    label = case_match(alg,
             "gravitaire avec furness" ~ "5. Gravitaire avec Furness",
             "gravitaire sans furness" ~ "4. Gravitaire sans Furness",
             "référence" ~ " Référence",
             "un en diagonale" ~ "1. Commune vers commune",
             "2 en diagonale" ~ "2. Commune vers commune et voisines",
             "distance critique" ~ "3. Distance carreau 200m")) |> 
  arrange(label) |> 
  relocate(label) |> 
  select(-p1,-p2, -alg, -n_est)
meaps_stats_p |> 
  relocate(label) |> 
  gt() |> 
  fmt_percent(columns = r2kl, decimals = 1) |>
  fmt_integer(columns = c(dl), sep_mark = " ") |>
  fmt_markdown(columns = labelp) |> 
  tab_style(
    style = cell_borders(sides = "top", col="gray66"),
    locations = cells_body(rows = label == "4. Gravitaire sans Furness")) |> 
  cols_label(label = "",
             labelp = "Paramètres",
             r2kl = md("R<sub>KL</sub><sup>2</sup>"),
             dl = "Degrés de liberté") |>
  cols_align(columns = c(r2kl, dl, labelp), align= "center" ) |> 
  tab_footnote(md("Le nombre de degrés de liberté est le nombre de paires de flux non nuls dans MOBPRO, moins les contraintes en ligne et en colonne, plus un puisqu'elles sont redondantes moins le nombre de paramètres estimés. Les unités sont des minutes de trajet pour les paramètres homogènes à une distance et sans unité pour les *odd-ratios*."))
```

Les estimations 1 à 3, dans lesquelles on explore un terme diagonal sous différentes formes, renforcent le diagnostic de biais communal noté dans les estimations non paramétriques. Il y a en moyenne 4 fois plus de chance de choisir un emploi (@tbl-meapsR2-p, lignes 1 et 2) dans la commune de résidence. L'estimation 2. montre que les communes voisines ne connaissent pas un biais comparable, bien que la chance de choisir un emploi dans celles-ci soit supérieure à 1.

L'estimation 3. délivre une information importante. C'est probablement plus la distance que le découpage administratif qui explique ce biais communal, qu'il convient plutôt d'appeler un bais de proximité. En effet, le coefficient d'ajustement est supérieur de plus d'un point à celui obtenu en 1., en perdant uniquement 1 degré de liberté. La distance de bascule est faible, autour de 8 minutes, ce qui suggère que le périmètre communal est trop large pour capturer cet effet. La chance à plus courte distance est également nettement plus élevée puisqu'au lieu d'être approximativement de 4 elle est approximativement de 20, soit 5 fois plus.

Il convient à ce stade d'être prudent sur cette estimation, puisque la résolution des données est largement inférieure au seuil qui a été trouvé. La simulation est basée sur des distances et des localisations d'emplois au carreau 200m dont la précision est convaincante. Mais les flux dans @MOBPRO ne sont connus que pour les communes d'origine et de départ et donc avec une résolution spatiale plus faible. La multiplication des observations peut palier à cette faible résolution spatiale, mais cela demandera d'établir une analyse des distances et des localisations sur des territoires plus grands et plus nombreux. L'utilisation de données de flux plus précisément localisées, par exemple calculées à partir de Fidéli[^larochelle-6] ou, au prix d'une lourdeur de données bien plus importante par des traces numériques.

[^larochelle-6]: A partir de Fidéli, on peut préciser la localisation de chaque individu et utiliser l'information sur la commune dans laquelle il travaille. On ne peut pas en revanche localiser plus précisément la localisation de l'emploi occupé.

```{r actvsfit-p, fig.asp=1}
#| label: fig-actvsfit-p
#| fig-scap: "*MEAPS* observés versus estimés, estimations paramétriques"
#| fig-cap: "La figure présente pour chaque configuration d'estimation le flux observé (axe des x) et le flux estimé (axe des y) en bleu lorsque o<sub>i,j</sub> est estimé et en rouge lorsque o<sub>i,j</sub> n'est pas estimé (les fuites sont toujours utilisées). La valeur de référence est répétée dans chaque panneau en gris clair."

meaps_estimations <- qs::qread("output/meaps_est.sqs") |> 
  mutate(alg = factor(
    alg, c("référence", "diagonale", "90%", "99%", "100%",
           "gravitaire sans furness", "gravitaire avec furness",
           "un en diagonale", "2 en diagonale", 
           "un fonction distance", "distance critique")),
    grav = case_match(alg,
                      c("gravitaire sans furness", "gravitaire avec furness") ~ TRUE, 
                      .default = FALSE),
    np = case_match(alg,
                    c("diagonale", "90%", "99%", "100%") ~ TRUE,
                    .default = FALSE))
library(scales)
ref <- meaps_estimations |>
  filter(alg == "référence") |> 
  mutate(diag = COMMUNE==DCLT) |> 
  filter(flux!=0) |> 
  select(-alg)
param <- meaps_estimations |>
  filter(!np&!grav) |> 
  filter(alg != "un fonction distance") |> 
  mutate(diag = COMMUNE==DCLT) |> 
  filter(alg!="référence") |> 
  filter(flux!=0) |> 
  mutate(
  label = case_match(alg,
             "gravitaire avec furness" ~ "5. gravitaire avec Furness",
             "gravitaire sans furness" ~ "4. gravitaire sans Furness",
             "référence" ~ " MEAPS odds=1",
             "un en diagonale" ~ "1. Commune vers commune",
             "2 en diagonale" ~ "2. Commune vers commune et voisines",
             "distance critique" ~ "3. Distance carreau 200m")) |> 
  select(-alg)

ggplot(param)+
  geom_point(data=ref,
             aes(x=mobpro, y=flux, shape = diag, alpha = diag, size = diag), 
             col="gray80")+
  scale_shape_manual(values=c(1, 18))+
  scale_alpha_manual(values=c(0.1, 0.5))+
  scale_size_manual(values=c(.5, 1.5))+
  geom_point(data = ~.x |> filter(!estime),
             aes(x=mobpro, y=flux, shape=diag, alpha = diag, size = diag),
             col="tomato")+
  geom_point(data = ~.x |> filter(estime),
             aes(x=mobpro, y=flux, shape=diag, alpha = diag, size = diag), 
             col="royalblue2")+
  scale_x_log10(limits=c(0.1, 20000),
                labels = label_number(accuracy = 1,
                                      big.mark = " "))+
  scale_y_log10(limits=c(0.1, 25000), 
                labels = label_number(accuracy = 1,
                                      big.mark = " "))+
  xlab("Flux observés")+ ylab("Flux estimés") +
  facet_wrap(vars(label), ncol = 2)+
  geom_abline(slope=1, linewidth=0.25)+
  coord_equal()+
  ofce::theme_ofce(legend.position  = "none")
```

Les estimations paramétriques indiquent une moins bonne performance du modèle gravitaire. Sans respect des contraintes en colonne, le modèle gravitaire donne une image assez faussée des trajets. Il peine à reproduire le biais de proximité et l'influence de la distance. Le premier tend à produire un paramètre $\delta$ très élevé alors que le second devrait au contraire imposer un $\delta$ plus faible pour rendre compte de trajets plus longs. L'application d'une même valeur de la distance suivant des milieux plus ou moins denses handicape cette représentation. La procédure de Furness améliore largement la capacité du modèle gravitaire à rendre compte des données. C'est au prix de la perte du lien avec la distance telle qu'elle est formulée dans le modèle gravitaire, à savoir homogène pour tous.

La @fig-actvsfit-grav illustre ce qui est à l'œuvre dans le modèle gravitaire. La minimisation de l'entropie relative dépend beaucoup du flux entre la Rochelle et la Rochelle qui pèse 29% de l'échantillon. La prise en compte des autres communes diagonales n'est pas bonne, ce qui conduit à un $R^2_{KL}$ moins bons que la référence de *MEAPS* (tous les emplois sont identiques pour chaque individu et ne diffèrent que par leur localisation). Le respect de la contrainte en colonne par la procédure de Furness permet une meilleure prise en compte des communes diagonales (dont le poids est de 35% dans l'échantillon la Rochelle), mais moins bonne que les modèles *MEAPS* paramétriques ou non.

```{r actvsfit-grav, fig.asp=0.55}
#| label: fig-actvsfit-grav
#| fig-scap: "*MEAPS* observés versus estimés"
#| fig-cap: "La figure présente pour chaque configuration d'estimation le flux observé (axe des x) et le flux estimé (axe des y) en bleu lorsque o<sub>i,j</sub> est estimé et en rouge lorsque o<sub>i,j</sub> n'est pas estimé (les fuites sont toujours utilisées). La valeur de référence est répétée dans chaque panneau en gris clair."

meaps_estimations <- qs::qread("output/meaps_est.sqs") |> 
  mutate(alg = factor(
    alg, c("référence", "diagonale", "90%", "99%", "100%",
           "gravitaire sans furness", "gravitaire avec furness",
           "un en diagonale", "2 en diagonale", 
           "un fonction distance", "distance critique")),
    grav = case_match(alg,
                      c("gravitaire sans furness", "gravitaire avec furness") ~ TRUE, 
                      .default = FALSE),
    np = case_match(alg,
                    c("diagonale", "90%", "99%", "100%") ~ TRUE,
                    .default = FALSE))
library(scales)
ref <- meaps_estimations |>
  filter(alg == "référence") |> 
  mutate(diag = COMMUNE==DCLT) |> 
  filter(flux!=0) |> 
  select(-alg)
param <- meaps_estimations |>
  filter(grav) |> 
  filter(alg != "un fonction distance") |> 
  mutate(diag = COMMUNE==DCLT) |> 
  filter(alg!="référence") |> 
  filter(flux!=0) |> 
  mutate(
  label = case_match(alg,
             "gravitaire avec furness" ~ "5. Gravitaire avec Furness",
             "gravitaire sans furness" ~ "4. Gravitaire sans Furness",
             "référence" ~ " Référence",
             "un en diagonale" ~ "1. Un paramètre commune vers commune",
             "2 en diagonale" ~ "2. commune vers commune et voisines",
             "distance critique" ~ "3. Distance (odds et distance critique)")) |> 
  select(-alg)

ggplot(param)+
  geom_point(data=ref,
             aes(x=mobpro, y=flux, shape = diag, alpha = diag, size = diag), 
             col="gray80")+
  scale_shape_manual(values=c(1, 18))+
  scale_alpha_manual(values=c(0.1, 0.5))+
  scale_size_manual(values=c(.5, 1.5))+
  geom_point(data = ~.x |> filter(!estime),
             aes(x=mobpro, y=flux, shape=diag, alpha = diag, size = diag),
             col="tomato")+
  geom_point(data = ~.x |> filter(estime),
             aes(x=mobpro, y=flux, shape=diag, alpha = diag, size = diag), 
             col="royalblue2")+
  scale_x_log10(limits=c(0.1, 20000),
                labels = label_number(accuracy = 1,
                                      big.mark = " "))+
  scale_y_log10(limits=c(0.1, 25000), 
                labels = label_number(accuracy = 1,
                                      big.mark = " "))+
  xlab("Flux observés")+ ylab("Flux estimés") +
  facet_wrap(vars(label), ncol = 2)+
  geom_abline(slope=1, linewidth=0.25)+
  coord_equal()+
  ofce::theme_ofce(legend.position  = "none")
```

La @fig-distrdist confirme ce diagnostic. On y compare la distrbution cumulée en fonction de la distance kilométrique pondérée entre chaque commune pour différentes estimations, les flux de @MOBPRO étant utilisé comme référence. Les performances des modèles sont comparables pour les courtes distances (i.e la commune de la Rochelle vers elle-même). Le modèle gravitaire avec ou sans Furness pêche sur les distances intermédiaires et donne trop de poids aux distances très longues. Les estimations paramétriques à partir de *MEAPS* parviennent bien à reproduire la distribution cumulée des distances, notamment le modèle paramétrique 3. qui retient la distance au carreau 200m comme forme fonctionnelle.

```{r}
#| label: fig-distrdist
#| fig-scap: Distributions empiriques cumulées des distances
#| fig-cap: Distributions empiriques cumulées des flux selon la distance. MOBPRO est indiqué en trait pointillé noir. La figure du haut est la distribution cumulée, celle du bas la différence entre la distribution et celle de MOBPRO
load("output/dist.com.srda")
meaps_estimations <- qs::qread("output/meaps_est.sqs") |> 
  mutate(alg = factor(
    alg, c("référence", "diagonale", "90%", "99%", "100%",
           "gravitaire sans furness", "gravitaire avec furness",
           "un en diagonale", "2 en diagonale", 
           "un fonction distance", "distance critique")),
    grav = case_match(alg,
                      c("gravitaire sans furness", "gravitaire avec furness") ~ TRUE, 
                      .default = FALSE),
    np = case_match(alg,
                    c("diagonale", "90%", "99%", "100%") ~ TRUE,
                    .default = FALSE)) |> 
  filter(!is.na(alg)) |> 
  filter(!np, alg != "référence") 
distances <- qs::qread("output/meaps_est.sqs") |>
  group_by(COMMUNE, DCLT) |>
  summarize(d = first(d[!is.na(d)]),
            mobpro = first(mobpro[!is.na(mobpro)])) |> 
  ungroup() |> 
  drop_na(d)
algs <- distinct(meaps_estimations, alg) |> pull(alg)
param <- map_dfr(algs, ~{
  meaps_estimations |> 
    filter(alg==.x) |> 
    select(-c(d, d5, d95, mobpro)) |> 
    right_join(distances, by=c("COMMUNE", "DCLT")) |> 
    mutate(flux = replace_na(flux, 0),
           alg = .x)
}) |> 
  mutate(
    label = case_match(alg,
                       "gravitaire avec furness" ~ "5. gravitaire avec furness",
                       "gravitaire sans furness" ~ "4. gravitaire sans furness",
                       "référence" ~ " MEAPS odds=1",
                       "un en diagonale" ~ "1. Commune vers commune",
                       "2 en diagonale" ~ "2. Commune vers commune et voisines",
                       "distance critique" ~ "3. Distance carreau 200m"))

param <- param |> 
  filter(!np, !is.na(label)) |>
  group_by(label) |> 
  arrange(label, d) |> 
  mutate(
    cumflux = cumsum(flux)/sum(flux),
    cumpro  = cumsum(mobpro)/sum(mobpro)) |>
  ungroup()

bas <- ggplot(param)+
  geom_step(aes(x=d, y=cumflux-cumpro , col=label), linewidth = 0.25) +
  geom_step(
    data=~filter(.x, alg==algs[[1]]),
    aes(x=d, y=0), linetype="dashed", 
    position = "identity", na.rm=TRUE)+
  PrettyCols::scale_color_pretty_d("Bright")+
  theme_ofce(legend.position = "none",
             plot.margin = margin())+
  ylab("Ecart avec MOBPRO")+
  xlab(NULL)+
  scale_y_continuous(
    labels = scales::label_percent(1))+
  scale_x_continuous(
    limits=c(0, 30000),
    labels = scales::label_number(scale=1/1000, suffix=" km"),
    n.breaks = 8)
  
haut <- ggplot(param)+
  geom_step(
    aes(x=d, y=cumflux, col=label),
    position = "identity", na.rm=TRUE, alpha=1, linewidth = 0.25)+
  geom_step(
    data=~filter(.x, alg==algs[[1]]),
    aes(x=d, y=cumpro), linetype="dashed", 
    position = "identity", na.rm=TRUE)+
  PrettyCols::scale_color_pretty_d("Bright")+
  theme_ofce(legend.position = c(0.75, 0.3))+
  scale_x_continuous(
    limits=c(0, 30000))+
  scale_y_continuous(
    labels = scales::label_percent(1),
    name = "Distribution cumulée le long de la distance")+
  theme(axis.line.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        plot.margin = margin(b=1))+
  guides(color=guide_legend("Estimation"))+
  xlab(NULL)+ylab(NULL)

library(patchwork)
haut / bas + plot_layout(heights = c(3,1))
```

## Une cartographie des émissions de CO~2~

La construction d'un modèle et sa calibration et sa validation sur des données permet de projeter dans des dimensions non observées les prédictions du modèle. Nous utilisons ici *MEAPS*, calibré sur les données @MOBPRO sur l'agglomération de la Rochelle pour produire une carte au carreau 200m des émissions de CO~2~ liées à la mobilité professionnelle quotidienne.

Le principe est assez simple : les seuls déplacements en voiture sont considérés comme étant émetteur de CO~2~, ce qui est une approximation raisonnable. Les émissions liées aux transports en commun, particulièrement les bus peu occupés pourraient être ajoutées, mais elles pèsent relativement peu dans le bilan des mobilités quotidiennes. Pour estimer les déplacements en voiture nous utilisons un modèle de choix discret évoqué dans la @sec-distancesparmode. Ce modèle estimé sur @MOBPERS ne pose à ce stade pas de difficulté particulière, si ce n'est un problème discuté à la fin de cette section.
